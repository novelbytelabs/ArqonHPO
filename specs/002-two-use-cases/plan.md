# Implementation Plan: RPZL Algorithm Production Implementation

**Branch**: `002-two-use-cases` | **Date**: 2025-12-14 | **Spec**: [spec.md](./spec.md)
**Status**: PENDING APPROVAL

## Summary

Implement production-quality RPZL algorithms for ArqonHPO to achieve time-to-target parity with Optuna. This update addresses 5 algorithm gaps identified in the clarification session, targeting existing files in `crates/core/src/`.

**Key Changes**:
1. Replace CV classifier with Residual Decay Analysis (α < 0.5 = structured)
2. Replace fixed 10% TPE bandwidth with Scott's Rule (σ = 1.06 × stddev × n^(-1/5))
3. Complete Nelder-Mead with all 5 operations (reflection, expansion, contraction, shrink)
4. Replace uniform random probe with Prime-Index Sampling
5. Seed Nelder-Mead simplex from top-k best probe points

## Technical Context

**Language/Version**: Rust 1.75+, Python 3.10+ (bindings)  
**Primary Dependencies**: `rand_chacha` (RNG), `serde` (serialization), `pyo3` (Python bindings)  
**Storage**: N/A (in-memory optimization)  
**Testing**: `cargo test` (unit), `pytest` (integration via Python bindings)  
**Target Platform**: Linux x86_64, macOS (aarch64/x86_64), Windows x86_64  
**Performance Goals**: < 100µs optimizer overhead per evaluation  
**Constraints**: O(1) per-eval policy, deterministic given seed, no extra objective calls  
**Scale/Scope**: 5 source files modified, ~400 lines of new/changed code

## Constitution Check

*GATE: ✅ PASSED*

- [x] **Warm-start flow enforced**: Probe → Classify → Mode Select → Refine pipeline unchanged
- [x] **No bypass/override**: All changes are internal algorithm improvements
- [x] **Objective evaluation pure**: No changes to objective call patterns
- [x] **Reproducibility metadata**: Seeds, primes, and α threshold captured in artifacts
- [x] **Canonical environment**: `helios-gpu-118` for benchmarks
- [x] **Tests planned first**: Unit tests for each algorithm component
- [x] **Observability**: Phase timings and classification rationale logged

## Project Structure

### Documentation (this feature)

```text
specs/002-two-use-cases/
├── spec.md              # Feature specification (updated with clarifications)
├── plan.md              # This file
├── research.md          # Technical decisions (D1-D5)
├── data-model.md        # Data model definitions
├── quickstart.md        # Getting started guide
├── contracts/           # API contracts
└── tasks.md             # Task breakdown (generated by /speckit.tasks)
```

### Source Code (files to modify)

```text
crates/core/src/
├── probe.rs             # [MODIFY] Add PrimeIndexProbe
├── classify.rs          # [MODIFY] Replace CV with ResidualDecayClassifier
├── strategies/
│   ├── mod.rs           # [MODIFY] Update exports if needed
│   ├── tpe.rs           # [MODIFY] Implement Scott's Rule bandwidth
│   └── nelder_mead.rs   # [MODIFY] Complete all 5 operations, add probe seeding
└── machine.rs           # [MODIFY] Wire up probe seeding to NM initialization

crates/core/src/tests/   # [NEW] Add unit tests
├── mod.rs
├── test_classify.rs
├── test_tpe.rs
├── test_nelder_mead.rs
└── test_probe.rs
```

---

## Implementation Phases

### Phase 1: Residual Decay Classifier

**Target**: `crates/core/src/classify.rs`

**Changes**:
1. Add `ResidualDecayClassifier` struct with configurable α threshold
2. Implement residual decay estimation algorithm:
   - Sort probe samples by position (prime indices)
   - Compute rolling errors E_k between adjacent samples
   - Fit exponential decay: E_k ≈ C × β^k
   - Estimate α from decay rate: α = -log(β)
   - Classify: α < 0.5 → Structured, else → Chaotic
3. Keep `VarianceClassifier` as fallback (feature-flagged)
4. Update `Classify` trait usage in `machine.rs`

**Acceptance Criteria**:
- [ ] Sphere function (smooth) classified as Structured
- [ ] Rastrigin function (chaotic) classified as Chaotic
- [ ] Classification is deterministic given same probe samples

---

### Phase 2: Scott's Rule TPE Bandwidth

**Target**: `crates/core/src/strategies/tpe.rs`

**Changes**:
1. Replace fixed `sigma = range * 0.1` with Scott's Rule:
   ```rust
   fn scotts_bandwidth(values: &[f64]) -> f64 {
       let n = values.len() as f64;
       let stddev = /* compute stddev */;
       1.06 * stddev * n.powf(-0.2)  // n^(-1/5)
   }
   ```
2. Compute σ separately per dimension using good samples
3. Add minimum bandwidth clamp to prevent degenerate kernels
4. Add `bandwidth_rule` config option (Scott | Silverman | Fixed)

**Acceptance Criteria**:
- [ ] Bandwidth adapts to sample distribution (narrower for tight clusters)
- [ ] Bandwidth scales with sample count per Scott's Rule
- [ ] TPE still deterministic given seed

---

### Phase 3: Complete Nelder-Mead Operations

**Target**: `crates/core/src/strategies/nelder_mead.rs`

**Changes**:
1. Implement missing `NMState` handlers:
   - `Expansion`: If reflection better than best → expand further
   - `OutsideContraction`: If reflection between second-worst and worst
   - `InsideContraction`: If reflection worse than worst
   - `Shrink`: Contract all points toward best point
2. Add standard NM coefficients (configurable):
   - α = 1.0 (reflection)
   - γ = 2.0 (expansion)
   - ρ = 0.5 (contraction)
   - σ = 0.5 (shrink)
3. Add convergence detection (simplex diameter < ε)

**Acceptance Criteria**:
- [ ] All 5 operations execute without panic
- [ ] Simplex converges on Sphere function
- [ ] State machine transitions are logged for debugging

---

### Phase 4: Prime-Index Probe

**Target**: `crates/core/src/probe.rs`

**Changes**:
1. Add `PrimeIndexProbe` struct
2. Implement prime ratio sampling:
   ```rust
   // Sample at positions: p_k / N for primes p_k up to budget
   let primes = vec![2, 3, 5, 7, 11, 13, 17, 19, 23, 29, ...];
   for &p in primes.iter().take(num_samples) {
       let t = p as f64 / primes[num_samples-1] as f64;
       // Map t ∈ [0,1] to bounds
   }
   ```
3. Use Sieve of Eratosthenes to generate primes up to budget
4. Keep `UniformProbe` as fallback option
5. Make probe type configurable in `SolverConfig`

**Acceptance Criteria**:
- [ ] Prime-index samples are deterministic
- [ ] Samples cover multi-scale structure (verified visually on 2D grid)
- [ ] At least 50 primes available for typical budgets

---

### Phase 5: Probe-to-Refiner Seeding

**Target**: `crates/core/src/machine.rs`, `crates/core/src/strategies/nelder_mead.rs`

**Changes**:
1. After classification, pass top-k probe results to refiner
2. Modify `NelderMead::new()` to accept seed points:
   ```rust
   pub fn with_seed_points(dim: usize, seeds: Vec<(f64, Vec<f64>)>) -> Self
   ```
3. In `NMState::Init`, use seed points as first k simplex vertices
4. Generate remaining (N+1-k) vertices via perturbation of best seed
5. Add `seed_count` config option (default: min(3, dim+1))

**Acceptance Criteria**:
- [ ] NM simplex uses probe's best points (not random init)
- [ ] Convergence is faster than random-init on smooth functions
- [ ] Seeding is deterministic

---

## Verification Plan

### Automated Tests (Rust)

Run all unit tests:
```bash
cd /home/irbsurfer/Projects/arqon/ArqonHPO
cargo test --package arqonhpo-core
```

**New Test Files** (to be created in `crates/core/src/tests/`):

| Test File | Coverage |
|-----------|----------|
| `test_classify.rs` | Residual decay α estimation, Sphere→Structured, Rastrigin→Chaotic |
| `test_tpe.rs` | Scott's Rule σ calculation, bandwidth adaptation |
| `test_nelder_mead.rs` | All 5 operations, state transitions, convergence |
| `test_probe.rs` | Prime generation, deterministic sampling, coverage |

### Integration Tests (Python)

Run Python tests:
```bash
cd /home/irbsurfer/Projects/arqon/ArqonHPO
conda run -n helios-gpu-118 pytest bindings/python/tests/ -v
```

**Existing Tests**:
- `test_us1.py` - Simulation tuning use case
- `test_integration.py` - End-to-end solver tests

### Benchmark Validation

After implementation, run benchmarks to verify time-to-target improvement:
```bash
cd /home/irbsurfer/Projects/arqon/ArqonHPO
conda run -n helios-gpu-118 python benchmarks/run_benchmarks.py
```

**Success Criteria**:
- ArqonHPO reaches target threshold ≥15% faster than Optuna-TPE on Sphere/Rosenbrock
- Residual decay classifier achieves ≥90% accuracy on structured/chaotic test suite

### Manual Verification

1. **Visual Classification Check**:
   - Run solver on Sphere function → should log "Landscape: Structured"
   - Run solver on Rastrigin function → should log "Landscape: Chaotic"

2. **Simplex Seeding Check**:
   - Enable debug logging, verify NM logs show "Initialized from probe seeds"

---

## Complexity Tracking

No Constitution violations. All changes are algorithm improvements within existing architecture.

---

## Next Step

After approval, run:
```
/speckit.tasks
```
to generate the task breakdown.
