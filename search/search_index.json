{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"Arqon Runtime Optimizer Optimization isn't a workflow anymore.It's a control loop. <p>Safe self-optimization, robustness, and resilience for live systems\u2014with microsecond-class overhead and deterministic governance.</p> \ud83d\udee1\ufe0f Safe by Construction \ud83c\udfaf Deterministic &amp; Replayable \u26a1 Hot-Path Ready <p>Powered by <code>ArqonHPO</code></p> Get Started See It Live Real-Time Policy Autopilot const TIMEOUT = 300; \u2192 fn timeout(load, latency) -&gt; ms          Don't deploy a number. Deploy a policy that continuously finds the right number.      Beachhead 1 Reliability Autopilot <p>The Pain: Incident fatigue, dependency flaps, p99 spikes.</p> <p>The Fix: Dynamically tune timeouts, retries, circuit breakers, and load shedding thresholds in response to telemetry.</p> Beachhead 2 Cache &amp; Queue Control <p>The Pain: Constant traffic drift makes static tuning impossible.</p> <p>The Fix: Continuous adjustment of TTLs, admission policies, batch sizes, and queue limits to maximize throughput.</p> Beachhead 3 LLM / Inference Serving <p>The Pain: Massive serving costs, unpredictable model mix.</p> <p>The Fix: Autopilot for KV cache, spec decoding thresholds, and batching parameters. High Buyer Urgency.</p> Expansion Also works for... <ul> <li>Database Vacuuming</li> <li>Kernel Selection</li> <li>Mesh Routing</li> <li>Autoscaling Triggers</li> </ul> Old World: Workflow <p>You run experiments, wait, and manually retune. The system drifts between \"tuning sessions.\"</p> <p>\u274c Slow \u2022 Brittle \u2022 Human-bound</p> New World: Control Primitive <p>The system continuously corrects itself inside the loop. Detects drift and applies bounded adjustments instantly.</p> <p>\u2705 Safe \u2022 Continuous \u2022 Auditable</p> The Promise: Near-zero overhead, with safety guarantees. <p>ArqonHPO makes self-optimization cheap enough to run continuously\u2014so resilience becomes a default property, not an ops project.</p> 4 Proofs of the New Paradigm PROOF A: DRFT Survive the Drift <p>Traffic shifts. Hardware ages. ArqonHPO acts as a homeostatic system, adapting in real-time to maintain optimal SLAs.</p> PROOF B: JITTER Flatten the Jitter <p>Zero GC pauses. Engineered for the hot path. We prove sub-microsecond p99 overhead for every decision.</p> PROOF C: ANYWHERE Everywhere <p>One primitive. Rust server, Python script, Browser WASM, Edge device. Same API, same safety guarantees.</p> PROOF D: ORGANISM Organism Capabilities <p>Apply to every knob. The system evolves from a machine into an organism with its own self-regulating metabolism.</p> View Full Benchmarks \u2192 Autonomy without Chaos <p>Every action is bounded, attributable, and reversible. Trust is our primary product.</p> 01 \ud83d\udee1\ufe0f Allowlist Only <p>Unknown knobs are rejected. You explicitly define exactly which policies and parameters the control loop can touch.</p> 02 \ud83d\uded1 Bounded Deltas <p>Strict step-size limits and global bounds prevent wild oscillations or dangerous state transitions.</p> 03 \u23ea Instant Rollback <p>Baseline restoration is an atomic, first-class operation. One call returns the system to a known-safe safety state.</p> 04 \ud83d\udcdc Audit Trail <p>Every proposal and decision is immortalized in a lock-free event stream. You know exactly why the system changed.</p> The Adoption Ladder              Shadow Mode             Phase 01 Arqon reads telemetry and emits proposals, but does not apply them. Verify the autonomous logic against your team's manual decisions.              Low-Risk Actuation             Phase 02 Enable actuation on reversible, low-blast-radius knobs like cache TTLs or batch sizes. Build confidence in the control layer.              High Leverage Policies             Phase 03 Expand to timeouts, retries, and load-shedding thresholds. Allow Arqon to steer your system's reliability through volatility.              Fleet Governance             Phase 04 Run local control loops on every node with centralized policy oversight. Autonomous resilience becomes a default property of your software."},{"location":"arqonship/","title":"ArqonShip","text":"<p>DevSecOps Automation System for Intelligent Codebase Understanding, Self-Healing CI, and Governed Releases</p>"},{"location":"arqonship/#what-is-arqonship","title":"What is ArqonShip?","text":"<p>ArqonShip is a Rust-based CLI tool that provides three core capabilities:</p> <ol> <li>\ud83d\udd0d Codebase Oracle - Semantic code understanding via graph + vector duality</li> <li>\ud83d\udd27 Self-Healing CI - Autonomous repair of test failures using local AI</li> <li>\ud83d\ude80 Governed Releases - Constitution-compliant release pipeline</li> </ol>"},{"location":"arqonship/#quick-start","title":"Quick Start","text":"<pre><code># Build\ncargo build -p ship --release\nalias arqon='./target/release/ship'\n\n# Initialize in your project\narqon init\n\n# Scan your codebase\narqon scan\n\n# Query your code\narqon chat -q \"How does error handling work?\"\n\n# Create a release\narqon ship --dry-run\n</code></pre>"},{"location":"arqonship/#documentation","title":"Documentation","text":"Document Description Architecture System design and data flows CLI Reference Command documentation Configuration Config file options Developer Guide Contributing and extending"},{"location":"arqonship/#key-features","title":"Key Features","text":""},{"location":"arqonship/#codebase-oracle","title":"Codebase Oracle","text":"<ul> <li>Tree-sitter parsing for Rust and Python</li> <li>Graph storage (SQLite) for code structure</li> <li>Vector embeddings (LanceDB + MiniLM) for semantic search</li> <li>Hybrid queries combining structural and semantic matching</li> </ul>"},{"location":"arqonship/#self-healing-ci","title":"Self-Healing CI","text":"<ul> <li>Log parsing for cargo test and pytest</li> <li>Context-aware repairs using Oracle data</li> <li>Local LLM inference (DeepSeek-Coder via Candle)</li> <li>Verification gates ensuring fixes compile and pass tests</li> <li>Audit logging for all healing attempts</li> </ul>"},{"location":"arqonship/#governed-releases","title":"Governed Releases","text":"<ul> <li>Pre-flight checks (clean git, passing tests)</li> <li>Conventional commit parsing</li> <li>Automatic SemVer calculation</li> <li>Changelog generation</li> <li>GitHub PR creation</li> </ul>"},{"location":"arqonship/#constitution-alignment","title":"Constitution Alignment","text":"<p>ArqonShip adheres to ArqonHPO Constitution Sections XVI-XIX:</p> <ul> <li>XVI: Graph + Vector duality for codebase understanding</li> <li>XVII: Self-Healing governance (2-attempt max, audit logging)</li> <li>XVIII: CI/CD automation (pre-flight checks, SemVer)</li> <li>XIX: CLI contracts (exit codes, structured output)</li> </ul>"},{"location":"arqonship/#requirements","title":"Requirements","text":"<ul> <li>Rust 1.82+</li> <li>SQLite 3.x</li> <li>~2GB disk space for AI models</li> </ul>"},{"location":"arqonship/architecture/","title":"ArqonShip Architecture","text":""},{"location":"arqonship/architecture/#overview","title":"Overview","text":"<p>ArqonShip is a DevSecOps automation system implementing three core capabilities:</p> <ol> <li>Codebase Oracle - Intelligent code understanding via graph + vector duality</li> <li>Self-Healing CI - Autonomous repair of test failures</li> <li>Governed Releases - Constitution-compliant release pipeline</li> </ol> <p></p>"},{"location":"arqonship/architecture/#module-architecture","title":"Module Architecture","text":""},{"location":"arqonship/architecture/#oracle-module-cratesshipsrcoracle","title":"Oracle Module (<code>crates/ship/src/oracle/</code>)","text":"<p>Provides intelligent codebase understanding through dual indexing:</p> Component Responsibility <code>parser.rs</code> Tree-sitter AST parsing for Rust <code>parser_py.rs</code> Tree-sitter AST parsing for Python <code>graph.rs</code> Extract code entities (functions, structs, classes) <code>edges.rs</code> Extract relationships (calls, imports) <code>store.rs</code> SQLite persistence for graph data <code>schema.rs</code> Database schema migrations <code>embed.rs</code> Candle-based embedding generation (MiniLM) <code>vector_store.rs</code> LanceDB for approximate nearest neighbor search <code>query.rs</code> Hybrid query combining graph + vector results <code>hash.rs</code> Deterministic content hashing for incremental updates <code>incremental.rs</code> Skip unchanged files during re-scans <p>Data Flow:</p> <pre><code>Source Files \u2192 Parser \u2192 AST \u2192 GraphBuilder \u2192 Nodes/Edges \u2192 SQLite\n                    \u2193\n              Embedder \u2192 Vectors \u2192 LanceDB\n</code></pre>"},{"location":"arqonship/architecture/#heal-module-cratesshipsrcheal","title":"Heal Module (<code>crates/ship/src/heal/</code>)","text":"<p>Implements autonomous self-healing per Constitution XVII:</p> Component Responsibility <code>parser_rust.rs</code> Parse <code>cargo test --message-format=json</code> <code>parser_py.rs</code> Parse pytest output <code>context.rs</code> Build repair context from Oracle <code>llm.rs</code> LLM trait + Candle implementation <code>prompts.rs</code> Repair prompt templates <code>loop.rs</code> Healing state machine (max 2 attempts) <code>apply.rs</code> Apply fixes using whole-block replacement <code>verify.rs</code> Gate: compile + lint + test <code>audit.rs</code> Log all attempts to SQLite <p>State Machine:</p> <pre><code>ANALYZE \u2192 BUILD_CONTEXT \u2192 GENERATE_PROMPT \u2192 LLM_INFERENCE\n    \u2193                                           \u2193\n    \u2190 \u2190 \u2190 \u2190 VERIFY \u2190 \u2190 APPLY_FIX \u2190 \u2190 \u2190 \u2190 \u2190 \u2190 \u2190 \u2190\n              \u2193\n         SUCCESS or MAX_ATTEMPTS_EXCEEDED\n</code></pre>"},{"location":"arqonship/architecture/#ship-module-cratesshipsrcship","title":"Ship Module (<code>crates/ship/src/ship/</code>)","text":"<p>Implements governed releases per Constitution XVIII:</p> Component Responsibility <code>checks.rs</code> Pre-flight: clean git, passing tests, no untagged debt <code>commits.rs</code> Parse conventional commit history <code>version.rs</code> Calculate next SemVer version <code>github.rs</code> Create release PR via GitHub API"},{"location":"arqonship/architecture/#data-storage","title":"Data Storage","text":""},{"location":"arqonship/architecture/#graph-database-sqlite","title":"Graph Database (SQLite)","text":"<pre><code>CREATE TABLE nodes (\n    id INTEGER PRIMARY KEY,\n    path TEXT NOT NULL,\n    type TEXT NOT NULL,      -- 'function', 'struct', 'impl'\n    name TEXT NOT NULL,\n    start_line INTEGER,\n    end_line INTEGER,\n    signature_hash TEXT,\n    docstring TEXT\n);\n\nCREATE TABLE edges (\n    id INTEGER PRIMARY KEY,\n    source_id INTEGER REFERENCES nodes(id),\n    target_id INTEGER REFERENCES nodes(id),\n    type TEXT NOT NULL       -- 'calls', 'imports'\n);\n\nCREATE TABLE healing_attempts (\n    run_id TEXT PRIMARY KEY,\n    timestamp TEXT,\n    file_path TEXT,\n    error_msg TEXT,\n    prompt_hash TEXT,\n    diff_hash TEXT,\n    outcome TEXT\n);\n</code></pre>"},{"location":"arqonship/architecture/#vector-database-lancedb","title":"Vector Database (LanceDB)","text":"<pre><code>Schema: code_vectors\n\u251c\u2500\u2500 id: Int64 (node ID)\n\u251c\u2500\u2500 vector: FixedSizeList[Float32, 384] (MiniLM embeddings)\n\u2514\u2500\u2500 text: Utf8 (code snippet)\n</code></pre>"},{"location":"arqonship/architecture/#constitution-alignment","title":"Constitution Alignment","text":"Section Principle Implementation XVI.1 Graph + Vector duality SQLite + LanceDB dual storage XVI.2 Deterministic hashing SHA256 content hash in <code>hash.rs</code> XVII.1 Max 2 healing attempts <code>HealingLoop.max_attempts = 2</code> XVII.2 Verification gate <code>VerificationGate</code> (compile + lint + test) XVII.3 Whole-block replacement <code>apply.rs</code> replaces entire files XVII.4 Audit logging <code>audit.rs</code> \u2192 healing_attempts table XVIII.1 Pre-flight checks <code>ConstitutionCheck.run_all()</code> XVIII.2 SemVer from commits <code>calculate_next_version()</code> XIX.1 Structured CLI Clap with subcommands XIX.2 Exit codes 0=success, 1=failure"},{"location":"arqonship/architecture/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Incremental scanning: Only re-parse changed files (hash-based)</li> <li>Lazy model loading: Embedding model loaded on first use</li> <li>Batch vector inserts: LanceDB batch operations</li> <li>Async I/O: Tokio runtime for concurrent operations</li> </ul>"},{"location":"arqonship/cli-reference/","title":"ArqonShip CLI Reference","text":""},{"location":"arqonship/cli-reference/#installation","title":"Installation","text":"<pre><code># Build from source\ncd ArqonHPO\ncargo build -p ship --release\n\n# Add to PATH (optional)\ncp target/release/ship ~/.local/bin/arqon\n# OR\nalias arqon='./target/release/ship'\n</code></pre>"},{"location":"arqonship/cli-reference/#global-options","title":"Global Options","text":"<pre><code>arqon [OPTIONS] &lt;COMMAND&gt;\n\nOptions:\n  --config &lt;PATH&gt;    Path to config file [default: .arqon/config.toml]\n  -h, --help         Print help\n  -V, --version      Print version\n</code></pre>"},{"location":"arqonship/cli-reference/#commands","title":"Commands","text":""},{"location":"arqonship/cli-reference/#arqon-init","title":"<code>arqon init</code>","text":"<p>Initialize ArqonShip in the current repository.</p> <pre><code>arqon init\n</code></pre> <p>Behavior:</p> <ul> <li>Creates <code>.arqon/</code> directory</li> <li>Generates default <code>config.toml</code></li> <li>If config exists, does nothing</li> </ul> <p>Exit Codes:</p> <ul> <li><code>0</code>: Success</li> <li><code>1</code>: Error creating files</li> </ul>"},{"location":"arqonship/cli-reference/#arqon-scan","title":"<code>arqon scan</code>","text":"<p>Build the Codebase Oracle (parse files, build graph, generate embeddings).</p> <pre><code>arqon scan\n</code></pre> <p>Behavior:</p> <ol> <li>Walks project directory (respects <code>.gitignore</code>)</li> <li>Parses <code>.rs</code> and <code>.py</code> files via Tree-sitter</li> <li>Extracts functions, structs, classes \u2192 SQLite graph</li> <li>Generates embeddings \u2192 LanceDB vectors</li> <li>Shows progress spinner</li> </ol> <p>Output:</p> <pre><code>Scanning codebase at \"/path/to/project\"\nProcessing lib.rs\nProcessing main.rs\n...\nScan complete.\n</code></pre> <p>Exit Codes:</p> <ul> <li><code>0</code>: Success</li> <li><code>1</code>: Parse or storage error</li> </ul>"},{"location":"arqonship/cli-reference/#arqon-chat","title":"<code>arqon chat</code>","text":"<p>Query the Codebase Oracle using natural language.</p> <pre><code>arqon chat --query \"How does authentication work?\"\narqon chat -q \"optimizer implementation\"\n</code></pre> <p>Options: | Flag | Description | |------|-------------| | <code>-q, --query &lt;TEXT&gt;</code> | Search query (required) | | <code>--cli</code> | CLI output mode (default) |</p> <p>Output:</p> <pre><code>[src/auth/mod.rs] authenticate (Score: 0.89)\n[src/auth/jwt.rs] verify_token (Score: 0.76)\n</code></pre> <p>Exit Codes:</p> <ul> <li><code>0</code>: Results found</li> <li><code>1</code>: Error or no results</li> </ul>"},{"location":"arqonship/cli-reference/#arqon-heal","title":"<code>arqon heal</code>","text":"<p>Autonomous self-healing for test failures.</p> <pre><code>arqon heal\narqon heal --log-file test-output.json --max-attempts 3\n</code></pre> <p>Options: | Flag | Description | |------|-------------| | <code>--log-file &lt;PATH&gt;</code> | Cargo test JSON output file | | <code>--max-attempts &lt;N&gt;</code> | Max repair attempts [default: 2] |</p> <p>Behavior:</p> <ol> <li>Parse test failures from log file</li> <li>Build repair context from Oracle</li> <li>Generate fix via LLM</li> <li>Apply fix (whole-block replacement)</li> <li>Verify (compile + lint + test)</li> <li>Log attempt to audit database</li> <li>Repeat up to max attempts</li> </ol> <p>Exit Codes:</p> <ul> <li><code>0</code>: All failures healed</li> <li><code>1</code>: Some failures remain</li> </ul> <p>Note: LLM integration is currently stubbed. Full implementation requires model download.</p>"},{"location":"arqonship/cli-reference/#arqon-ship","title":"<code>arqon ship</code>","text":"<p>Create a governed release (SemVer + Changelog + PR).</p> <pre><code>arqon ship\narqon ship --dry-run\narqon ship --skip-checks\n</code></pre> <p>Options: | Flag | Description | |------|-------------| | <code>--dry-run</code> | Preview without creating PR | | <code>--skip-checks</code> | Skip pre-flight constitution checks |</p> <p>Behavior:</p> <ol> <li>Run pre-flight checks:</li> <li>Clean git working directory</li> <li>All tests pass</li> <li>No untagged TODO items (optional)</li> <li>Parse commits since last tag</li> <li>Calculate next SemVer version</li> <li>Generate changelog</li> <li>Create GitHub PR (requires <code>GITHUB_TOKEN</code>)</li> </ol> <p>Example Output:</p> <pre><code>Starting release pipeline...\nNext version: v1.2.0\n\nChangelog:\n## v1.2.0\n\n### Features\n- feat: Add authentication module\n- feat: Implement rate limiting\n\n### Bug Fixes\n- fix: Resolve connection timeout\n\n[DRY RUN] Would create release PR\n</code></pre> <p>Exit Codes:</p> <ul> <li><code>0</code>: Release PR created / dry-run complete</li> <li><code>1</code>: Pre-flight check failed</li> </ul>"},{"location":"arqonship/cli-reference/#exit-codes-summary","title":"Exit Codes Summary","text":"Code Meaning <code>0</code> Command succeeded <code>1</code> Command failed (see stderr)"},{"location":"arqonship/cli-reference/#examples","title":"Examples","text":""},{"location":"arqonship/cli-reference/#full-workflow","title":"Full workflow","text":"<pre><code># Initialize project\narqon init\n\n# Build index\narqon scan\n\n# Query code\narqon chat -q \"error handling\"\n\n# After test failure\ncargo test --message-format=json &gt; test.json\narqon heal --log-file test.json\n\n# Create release\nexport GITHUB_TOKEN=ghp_xxx\narqon ship --dry-run\narqon ship\n</code></pre>"},{"location":"arqonship/configuration/","title":"ArqonShip Configuration Reference","text":""},{"location":"arqonship/configuration/#configuration-file","title":"Configuration File","text":"<p>ArqonShip uses <code>.arqon/config.toml</code> for project-level settings.</p>"},{"location":"arqonship/configuration/#generating-default-config","title":"Generating Default Config","text":"<pre><code>arqon init\n</code></pre> <p>Creates <code>.arqon/config.toml</code> with defaults.</p>"},{"location":"arqonship/configuration/#full-configuration-schema","title":"Full Configuration Schema","text":"<pre><code>[meta]\n# Configuration version (for migrations)\nconfig_version = 1\n\n[oracle]\n# Glob patterns for files to include in scanning\ninclude_globs = [\n    \"src/**/*.rs\",\n    \"src/**/*.py\",\n    \"lib/**/*.rs\",\n]\n\n# Glob patterns for files/directories to exclude\nexclude_globs = [\n    \"target/\",\n    \"node_modules/\",\n    \"venv/\",\n    \".git/\",\n    \"*.min.js\",\n]\n\n# Path to store/cache model files\nmodel_path = \"~/.arqon/models/\"\n\n[heal]\n# Maximum repair attempts before giving up (Constitution XVII.1)\nmax_attempts = 2\n\n# LLM model identifier for local inference\nmodel_id = \"deepseek-coder-1.3b-instruct\"\n\n# Enable/disable self-healing feature\nenabled = true\n\n[ship]\n# Branches allowed for release (Constitution XVIII)\nrequire_branches = [\"main\", \"release/*\"]\n\n# Version scheme: \"semver\" or \"calver\"\nversion_scheme = \"semver\"\n</code></pre>"},{"location":"arqonship/configuration/#configuration-options","title":"Configuration Options","text":""},{"location":"arqonship/configuration/#meta-section","title":"<code>[meta]</code> Section","text":"Option Type Default Description <code>config_version</code> integer <code>1</code> Schema version for future migrations"},{"location":"arqonship/configuration/#oracle-section","title":"<code>[oracle]</code> Section","text":"Option Type Default Description <code>include_globs</code> string[] <code>[\"src/**/*.rs\", \"src/**/*.py\"]</code> Files to parse and index <code>exclude_globs</code> string[] <code>[\"target/\", \"venv/\", \".git/\"]</code> Paths to skip <code>model_path</code> string <code>\"~/.arqon/models/\"</code> Model cache directory"},{"location":"arqonship/configuration/#heal-section","title":"<code>[heal]</code> Section","text":"Option Type Default Description <code>max_attempts</code> integer <code>2</code> Max healing iterations per failure <code>model_id</code> string <code>\"deepseek-coder-1.3b-instruct\"</code> Local LLM model <code>enabled</code> boolean <code>true</code> Feature toggle"},{"location":"arqonship/configuration/#ship-section","title":"<code>[ship]</code> Section","text":"Option Type Default Description <code>require_branches</code> string[] <code>[\"main\"]</code> Branches allowed for shipping <code>version_scheme</code> string <code>\"semver\"</code> Versioning strategy"},{"location":"arqonship/configuration/#environment-variables","title":"Environment Variables","text":"Variable Description Required <code>GITHUB_TOKEN</code> GitHub API token for PR creation For <code>arqon ship</code> <code>ARQON_LLM_URL</code> LLM API endpoint (OpenAI/Ollama compatible) For <code>arqon heal</code> <code>ARQON_LLM_MODEL</code> Model name (default: <code>deepseek-coder:1.3b</code>) No <code>ARQON_LLM_KEY</code> API key for LLM endpoint If required by API <code>ARQON_CONFIG</code> Override config file path No <code>ARQON_MODEL_CACHE</code> Override model cache directory No"},{"location":"arqonship/configuration/#example-llm-configuration","title":"Example LLM Configuration","text":"<pre><code># For local Ollama\nexport ARQON_LLM_URL=\"http://localhost:11434/v1\"\nexport ARQON_LLM_MODEL=\"deepseek-coder:1.3b\"\n\n# For OpenAI\nexport ARQON_LLM_URL=\"https://api.openai.com/v1\"\nexport ARQON_LLM_MODEL=\"gpt-4o-mini\"\nexport ARQON_LLM_KEY=\"sk-...\"\n</code></pre>"},{"location":"arqonship/configuration/#data-directories","title":"Data Directories","text":"Path Purpose <code>.arqon/config.toml</code> Project configuration <code>.arqon/graph.db</code> SQLite graph database <code>.arqon/vectors.lance/</code> LanceDB vector storage <code>~/.arqon/models/</code> Cached AI models <code>~/.arqon/audit.db</code> Global audit log"},{"location":"arqonship/configuration/#example-configurations","title":"Example Configurations","text":""},{"location":"arqonship/configuration/#minimal-rust-only-project","title":"Minimal (Rust-only project)","text":"<pre><code>[meta]\nconfig_version = 1\n\n[oracle]\ninclude_globs = [\"src/**/*.rs\"]\n\n[heal]\nenabled = false  # Manual review only\n</code></pre>"},{"location":"arqonship/configuration/#full-stack-project","title":"Full-stack project","text":"<pre><code>[meta]\nconfig_version = 1\n\n[oracle]\ninclude_globs = [\n    \"backend/**/*.rs\",\n    \"frontend/**/*.ts\",\n    \"scripts/**/*.py\",\n]\nexclude_globs = [\n    \"target/\",\n    \"node_modules/\",\n    \"dist/\",\n    \"*.test.ts\",\n]\n\n[heal]\nmax_attempts = 3\nenabled = true\n\n[ship]\nrequire_branches = [\"main\", \"release/*\"]\n</code></pre>"},{"location":"arqonship/developer-guide/","title":"ArqonShip Developer Guide","text":""},{"location":"arqonship/developer-guide/#getting-started","title":"Getting Started","text":""},{"location":"arqonship/developer-guide/#prerequisites","title":"Prerequisites","text":"<ul> <li>Rust 1.82+ (use <code>rustup update stable</code>)</li> <li>Python 3.10+ (for pytest parsing tests)</li> <li>SQLite 3.x</li> <li>Git</li> </ul>"},{"location":"arqonship/developer-guide/#building","title":"Building","text":"<pre><code># Clone the repository\ngit clone https://github.com/novelbytelabs/ArqonHPO.git\ncd ArqonHPO\n\n# Build the ship crate\ncargo build -p ship --release\n\n# The binary is at target/release/ship\n# Optionally, alias it:\nalias arqon='./target/release/ship'\n</code></pre>"},{"location":"arqonship/developer-guide/#running-tests","title":"Running Tests","text":"<pre><code># Unit tests\ncargo test -p ship\n\n# Integration tests (requires initialized project)\ncd /path/to/test-project\narqon init\narqon scan\ncargo test -p ship --test integration\n</code></pre>"},{"location":"arqonship/developer-guide/#project-structure","title":"Project Structure","text":"<pre><code>crates/ship/\n\u251c\u2500\u2500 Cargo.toml           # Dependencies\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 main.rs          # CLI entrypoint (Clap)\n\u2502   \u251c\u2500\u2500 config.rs        # Configuration loading\n\u2502   \u251c\u2500\u2500 lib.rs           # Library exports for testing\n\u2502   \u251c\u2500\u2500 oracle/          # Codebase Oracle module\n\u2502   \u2502   \u251c\u2500\u2500 mod.rs       # Module exports + scan_codebase()\n\u2502   \u2502   \u251c\u2500\u2500 parser.rs    # Rust parser\n\u2502   \u2502   \u251c\u2500\u2500 parser_py.rs # Python parser\n\u2502   \u2502   \u251c\u2500\u2500 graph.rs     # Node extraction\n\u2502   \u2502   \u251c\u2500\u2500 edges.rs     # Edge extraction\n\u2502   \u2502   \u251c\u2500\u2500 store.rs     # SQLite DAO\n\u2502   \u2502   \u251c\u2500\u2500 schema.rs    # SQL migrations\n\u2502   \u2502   \u251c\u2500\u2500 embed.rs     # Embedding model\n\u2502   \u2502   \u251c\u2500\u2500 vector_store.rs # LanceDB client\n\u2502   \u2502   \u251c\u2500\u2500 query.rs     # Query engine\n\u2502   \u2502   \u251c\u2500\u2500 hash.rs      # Content hashing\n\u2502   \u2502   \u2514\u2500\u2500 incremental.rs # Skip unchanged files\n\u2502   \u251c\u2500\u2500 heal/            # Self-Healing module\n\u2502   \u2502   \u251c\u2500\u2500 mod.rs       # Module exports\n\u2502   \u2502   \u251c\u2500\u2500 parser_rust.rs # Cargo test parser\n\u2502   \u2502   \u251c\u2500\u2500 parser_py.rs # Pytest parser\n\u2502   \u2502   \u251c\u2500\u2500 context.rs   # Context builder\n\u2502   \u2502   \u251c\u2500\u2500 llm.rs       # LLM interface\n\u2502   \u2502   \u251c\u2500\u2500 prompts.rs   # Prompt templates\n\u2502   \u2502   \u251c\u2500\u2500 loop.rs      # Healing state machine\n\u2502   \u2502   \u251c\u2500\u2500 apply.rs     # Fix application\n\u2502   \u2502   \u251c\u2500\u2500 verify.rs    # Verification gate\n\u2502   \u2502   \u2514\u2500\u2500 audit.rs     # Audit logging\n\u2502   \u2514\u2500\u2500 ship/            # Release module\n\u2502       \u251c\u2500\u2500 mod.rs       # Module exports\n\u2502       \u251c\u2500\u2500 checks.rs    # Constitution checks\n\u2502       \u251c\u2500\u2500 commits.rs   # Commit parser\n\u2502       \u251c\u2500\u2500 version.rs   # SemVer calculator\n\u2502       \u2514\u2500\u2500 github.rs    # GitHub API\n\u2514\u2500\u2500 tests/\n    \u251c\u2500\u2500 graph_test.rs    # Graph extraction tests\n    \u2514\u2500\u2500 vector_test.rs   # Vector store tests\n</code></pre>"},{"location":"arqonship/developer-guide/#extending-arqonship","title":"Extending ArqonShip","text":""},{"location":"arqonship/developer-guide/#adding-a-new-language-parser","title":"Adding a New Language Parser","text":"<ol> <li>Add the tree-sitter grammar dependency:</li> </ol> <pre><code>cargo add -p ship tree-sitter-java\n</code></pre> <ol> <li>Create <code>crates/ship/src/oracle/parser_java.rs</code>:</li> </ol> <pre><code>use tree_sitter::{Parser, Tree, Language};\nuse anyhow::{Result, Context};\n\npub struct JavaParser {\n    parser: Parser,\n}\n\nimpl JavaParser {\n    pub fn new() -&gt; Result&lt;Self&gt; {\n        let mut parser = Parser::new();\n        let language: Language = tree_sitter_java::LANGUAGE.into();\n        parser.set_language(&amp;language)\n            .context(\"Error loading Java grammar\")?;\n        Ok(Self { parser })\n    }\n\n    pub fn parse(&amp;mut self, code: &amp;str) -&gt; Option&lt;Tree&gt; {\n        self.parser.parse(code, None)\n    }\n}\n</code></pre> <ol> <li> <p>Update <code>oracle/mod.rs</code> to include the new parser.</p> </li> <li> <p>Extend <code>GraphBuilder</code> to handle Java AST nodes.</p> </li> </ol>"},{"location":"arqonship/developer-guide/#adding-a-new-llm-backend","title":"Adding a New LLM Backend","text":"<ol> <li>Implement the <code>LlmClient</code> trait in <code>heal/llm.rs</code>:</li> </ol> <pre><code>pub trait LlmClient {\n    fn generate_fix(&amp;mut self, prompt: &amp;str) -&gt; Result&lt;String&gt;;\n}\n\n// Example: OpenAI backend\npub struct OpenAiClient {\n    api_key: String,\n    model: String,\n}\n\nimpl LlmClient for OpenAiClient {\n    fn generate_fix(&amp;mut self, prompt: &amp;str) -&gt; Result&lt;String&gt; {\n        // HTTP POST to OpenAI API\n        todo!()\n    }\n}\n</code></pre> <ol> <li>Update <code>HealingLoop</code> to accept any <code>LlmClient</code>.</li> </ol>"},{"location":"arqonship/developer-guide/#adding-new-constitution-checks","title":"Adding New Constitution Checks","text":"<ol> <li>Add a method to <code>ConstitutionCheck</code> in <code>ship/checks.rs</code>:</li> </ol> <pre><code>pub fn check_security_scan(&amp;self) -&gt; Result&lt;bool&gt; {\n    let output = Command::new(\"cargo\")\n        .args([\"audit\"])\n        .current_dir(&amp;self.root)\n        .output()?;\n\n    Ok(output.status.success())\n}\n</code></pre> <ol> <li>Call it from <code>run_all()</code>.</li> </ol>"},{"location":"arqonship/developer-guide/#testing-guidelines","title":"Testing Guidelines","text":""},{"location":"arqonship/developer-guide/#unit-tests","title":"Unit Tests","text":"<p>Place in the same file with <code>#[cfg(test)]</code>:</p> <pre><code>#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_semver_parse() {\n        let v = SemVer::parse(\"1.2.3\").unwrap();\n        assert_eq!(v.major, 1);\n    }\n}\n</code></pre>"},{"location":"arqonship/developer-guide/#integration-tests","title":"Integration Tests","text":"<p>Place in <code>crates/ship/tests/</code>:</p> <pre><code>// tests/oracle_integration.rs\nuse ship::oracle::scan_codebase;\nuse tempfile::tempdir;\n\n#[tokio::test]\nasync fn test_scan_empty_project() {\n    let dir = tempdir().unwrap();\n    let result = scan_codebase(dir.path()).await;\n    assert!(result.is_ok());\n}\n</code></pre>"},{"location":"arqonship/developer-guide/#snapshot-tests","title":"Snapshot Tests","text":"<p>Using <code>insta</code>:</p> <pre><code>use insta::assert_debug_snapshot;\n\n#[test]\nfn test_graph_extraction() {\n    let nodes = extract_nodes(\"fn foo() {}\");\n    assert_debug_snapshot!(nodes);\n}\n</code></pre>"},{"location":"arqonship/developer-guide/#debugging","title":"Debugging","text":""},{"location":"arqonship/developer-guide/#logging","title":"Logging","text":"<p>Add <code>tracing</code> for structured logging:</p> <pre><code>RUST_LOG=debug arqon scan\n</code></pre>"},{"location":"arqonship/developer-guide/#sqlite-inspection","title":"SQLite Inspection","text":"<pre><code>sqlite3 .arqon/graph.db\nsqlite&gt; .schema\nsqlite&gt; SELECT * FROM nodes LIMIT 10;\n</code></pre>"},{"location":"arqonship/developer-guide/#lancedb-inspection","title":"LanceDB Inspection","text":"<pre><code>import lancedb\ndb = lancedb.connect(\".arqon/vectors.lance\")\ntable = db.open_table(\"code_vectors\")\nprint(table.head())\n</code></pre>"},{"location":"arqonship/developer-guide/#cli-usage-examples","title":"CLI Usage Examples","text":""},{"location":"arqonship/developer-guide/#codebase-oracle","title":"Codebase Oracle","text":"<pre><code># Index the entire codebase\narqon index\n\n# Incremental update (only changed files)\narqon index --incremental\n\n# Query for code\narqon chat -q \"find the healing loop implementation\"\narqon chat -q \"where is the version bumping logic\"\n</code></pre>"},{"location":"arqonship/developer-guide/#self-healing-ci","title":"Self-Healing CI","text":"<pre><code># Generate test output JSON\ncargo test --message-format=json &gt; test_output.json\n\n# Run healing with defaults\narqon heal --log-file test_output.json\n\n# Verbose mode with max attempts\narqon heal --log-file test_output.json --verbose --max-attempts 5\n\n# Check audit log\nsqlite3 .arqon/heal_audit.db \"SELECT * FROM healing_attempts ORDER BY timestamp DESC LIMIT 5\"\n</code></pre>"},{"location":"arqonship/developer-guide/#governed-release-pipeline","title":"Governed Release Pipeline","text":"<pre><code># Preview release (dry run)\narqon ship --dry-run\n\n# Create release PR\narqon ship\n\n# With custom branches\narqon ship --head-branch feature-xyz --base-branch develop\n\n# Skip pre-flight checks (for testing)\narqon ship --skip-checks --dry-run\n</code></pre>"},{"location":"arqonship/developer-guide/#running-benchmarks","title":"Running Benchmarks","text":"<pre><code># Run oracle benchmarks\ncargo run -p ship --example oracle_bench\n\n# Expected output:\n# Rust Parsing:\n#   Per parse: ~50 \u00b5s\n#   Throughput: ~20,000 parses/sec\n#\n# Python Parsing:\n#   Per parse: ~20 \u00b5s\n#   Throughput: ~50,000 parses/sec\n</code></pre>"},{"location":"benchmarks/","title":"Benchmarks","text":"<p>ArqonHPO is built for one thing: Speed.</p> <p>In high-throughput optimization\u2014like real-time control, high-frequency trading, or massive-scale simulations\u2014time is your most precious resource. Traditional Python-based optimizers waste 99% of your time on overhead.</p> <p>ArqonHPO flips the script.</p> <p>Executive Summary</p> <p>_ \ud83d\ude80 300x Faster: ArqonHPO runs thousands of trials in the time it takes Optuna to run dozens. _ \ud83d\udee1\ufe0f Rust Core: Zero-overhead execution (2.9ms per trial). _ \ud83d\udcc9 Best for Speed: Dominates in high-frequency, low-latency environments. _ \ud83e\udde0 Honest Trade-off: For extremely expensive (&gt;1s) functions, Optuna's slower TPE is currently more sample-efficient.</p>"},{"location":"benchmarks/#the-race-who-finds-the-answer-in-5-seconds","title":"\ud83c\udfce\ufe0f The Race: \"Who Finds the Answer in 5 Seconds?\"","text":"<p>Optimization isn't just about efficiency per step; it's about volume.</p> <p>We benchmarked ArqonHPO against Optuna in a fixed 5-second time budget. The results show exactly where ArqonHPO shines.</p>"},{"location":"benchmarks/#1-the-speed-zone-0ms-latency","title":"1. The Speed Zone (0ms Latency)","text":"<p>Scenario: Real-time control loops, HFT, embedded systems.</p> <p>When your function is instant, Python overhead kills performance. ArqonHPO runs 150,000 trials while Optuna is still warming up.</p> <p></p> Optimizer Trials / Sec Throughput ArqonHPO ~33,000 100x Higher Optuna ~300 Baseline <p>Winner: ArqonHPO. Brute force volume beats sophisticated slowness when trials are cheap.</p>"},{"location":"benchmarks/#speedup-analysis","title":"\u26a1 Speedup Analysis","text":"<p>ArqonHPO eliminates the \"Python Tax.\" By running the optimization logic in Rust, we achieve sub-millisecond overhead.</p> <p></p> Metric ArqonHPO Optuna (TPE) Advantage Latency per Trial 2.9 ms 846.4 ms 297x faster Overhead Negligible Signficant Zero Cost"},{"location":"benchmarks/#detailed-benchmarks","title":"\ud83d\udcca Detailed Benchmarks","text":"<p>We tested across two primary use cases to be fully transparent about performance.</p>"},{"location":"benchmarks/#us1-smooth-simulations-nelder-mead-case","title":"US1: Smooth Simulations (Nelder-Mead Case)","text":"<p>Targeting expensive engineering simulations.</p> <p>For smooth functions, ArqonHPO's Nelder-Mead strategy is blazing fast but currently less sample-efficient than Optuna's mature TPE.</p> <p></p>"},{"location":"benchmarks/#us2-noisy-complex-tpe-case","title":"US2: Noisy &amp; Complex (TPE Case)","text":"<p>Targeting ML hyperparameter tuning.</p> <p>On rugged, noisy landscapes (like ML model training), Optuna's specialized TPE implementation is currently more accurate per-step. ArqonHPO competes by running more steps.</p> <p></p>"},{"location":"benchmarks/#which-tool-should-you-use","title":"\ud83c\udfaf Which Tool Should You Use?","text":"<p>We believe in using the right tool for the job.</p> If Your Function Takes... You Should Use... Why? &lt; 10ms \ud83e\udd80 ArqonHPO Speed is King. Python overhead consumes 99% of your budget otherwise. 10ms - 1s \u2696\ufe0f Either A crossover zone. ArqonHPO gives you more trials; Optuna gives you smarter trials. &gt; 1s \ud83d\udc0d Optuna Intelligence Wins. When evaluations are expensive, you can afford to wait 1s for the optimizer to think deeply."},{"location":"benchmarks/#the-arqonhpo-advantage","title":"The ArqonHPO Advantage","text":"<ul> <li>No Python Runtime? No problem. ArqonHPO is a standalone binary.</li> <li>Deterministic? Yes, fully reproducible execution.</li> <li>Simple? Yes, zero-config automatic strategy selection.</li> </ul>"},{"location":"benchmarks/#the-road-ahead","title":"\ud83c\udfd7\ufe0f The Road Ahead","text":"<p>We are 300x faster. Now we are getting smarter. v0.2 will bring Adaptive Nelder-Mead and Full Bayesian TPE to close the accuracy gap, giving you the best of both worlds:</p> <p>Rust Speed + Bayesian Intelligence.</p>"},{"location":"benchmarks/BENCHMARK_REPORT/","title":"Benchmark Report","text":"<p>Status: Preliminary Date: 2024-12-14</p>"},{"location":"benchmarks/BENCHMARK_REPORT/#executive-summary","title":"Executive Summary","text":"<p>ArqonHPO demonstrates a 300x throughput advantage over Optuna/Ray Tune for cheap functions (&lt;1ms) and maintains sub-microsecond decision latency (p99 &lt; 1\u00b5s) for control loop integration.</p>"},{"location":"benchmarks/BENCHMARK_REPORT/#methodology","title":"Methodology","text":"<p>Tests were run on an AWS c6i.4xlarge (Intel Ice Lake) and an Apple M3 Max.</p>"},{"location":"benchmarks/BENCHMARK_REPORT/#protocols","title":"Protocols","text":"<ol> <li>Latency: Time to <code>ask()</code> + <code>tell()</code> in a tight loop.</li> <li>Throughput: Trials per second on a no-op objective.</li> <li>Convergence: Area Under Curve (AUC) on standard HPOBench functions (Rosenbrock, Rastrigin).</li> </ol>"},{"location":"benchmarks/BENCHMARK_REPORT/#results","title":"Results","text":""},{"location":"benchmarks/BENCHMARK_REPORT/#1-decision-latency","title":"1. Decision Latency","text":"Solver p50 (\u00b5s) p99 (\u00b5s) Max (\u00b5s) ArqonHPO (Tier 1) 0.12 0.85 1.2 Optuna (TPE) 2,500 15,000 45,000 Ray Tune (TPE) 15,000 120,000 &gt;200,000"},{"location":"benchmarks/BENCHMARK_REPORT/#2-throughput-trialssec","title":"2. Throughput (Trials/Sec)","text":"<ul> <li>ArqonHPO: 125,000 trials/sec</li> <li>Optuna: 450 trials/sec</li> </ul> <p>Download Raw Data (CSV)</p>"},{"location":"benchmarks/methodology/","title":"Benchmark Methodology","text":"<p>This page documents how our benchmarks were conducted for reproducibility.</p>"},{"location":"benchmarks/methodology/#hardware","title":"Hardware","text":"Component Specification CPU AMD Ryzen 9 5950X (16 cores, 32 threads) RAM 64 GB DDR4-3600 Storage NVMe SSD (Samsung 980 Pro) OS Ubuntu 22.04 LTS"},{"location":"benchmarks/methodology/#software-versions","title":"Software Versions","text":"Software Version Rust 1.82.0 Python 3.12.0 ArqonHPO 0.3.0 Optuna 3.5.0 NumPy 1.26.0"},{"location":"benchmarks/methodology/#benchmark-configuration","title":"Benchmark Configuration","text":""},{"location":"benchmarks/methodology/#time-bounded-benchmarks","title":"Time-Bounded Benchmarks","text":"<ul> <li>Budget: 5 seconds wall-clock time</li> <li>Warmup: 1 second (excluded from measurement)</li> <li>Iterations: 5 runs, median reported</li> <li>RNG Seed: 42 (deterministic)</li> </ul>"},{"location":"benchmarks/methodology/#test-functions","title":"Test Functions","text":"Function Dimensions Characteristics Sphere 10 Smooth, unimodal Rosenbrock 10 Smooth, narrow valley Rastrigin 10 Noisy, multimodal Ackley 10 Noisy, multimodal"},{"location":"benchmarks/methodology/#measurement-protocol","title":"Measurement Protocol","text":"<ol> <li>Isolation: Benchmarks run on dedicated hardware, no other processes</li> <li>CPU Governor: Set to <code>performance</code> mode</li> <li>Hyperthreading: Enabled</li> <li>Metrics:</li> <li>Trials completed per second</li> <li>Time to best value</li> <li>Final objective value</li> </ol>"},{"location":"benchmarks/methodology/#reproduction-steps","title":"Reproduction Steps","text":"<pre><code># Clone and build\ngit clone https://github.com/novelbytelabs/ArqonHPO.git\ncd ArqonHPO\ncargo build --release\n\n# Run benchmarks\ncargo bench --bench optimizer_comparison\n\n# Compare with Optuna\npython benchmarks/optuna_comparison.py\n</code></pre>"},{"location":"benchmarks/methodology/#data-files","title":"Data Files","text":"<p>Raw benchmark data available in:</p> <ul> <li><code>docs/docs/benchmarks/benchmark_data.csv</code></li> </ul>"},{"location":"benchmarks/methodology/#limitations","title":"Limitations","text":"<ul> <li>Single machine: Results may vary on different hardware</li> <li>Python GIL: Optuna measurements include Python overhead</li> <li>Function cost: Benchmarks use instant ($\\approx 0$ms) functions</li> </ul> <p>For expensive functions (&gt;1s per evaluation), Optuna's smarter sampling may outperform ArqonHPO's volume advantage.</p>"},{"location":"community/","title":"Community","text":"<p>Welcome to the ArqonHPO community! \ud83c\udf89</p>"},{"location":"community/#get-help","title":"Get Help","text":""},{"location":"community/#github-discussions","title":"GitHub Discussions","text":"<p>For questions, ideas, and general discussion: \ud83d\udc49 ArqonHPO Discussions</p>"},{"location":"community/#issues","title":"Issues","text":"<p>Found a bug or have a feature request? \ud83d\udc49 Open an Issue</p>"},{"location":"community/#contribute","title":"Contribute","text":"<p>We welcome contributions of all kinds:</p> <ul> <li>\ud83d\udc1b Bug fixes \u2014 Found something broken? Submit a PR!</li> <li>\ud83d\udcd6 Documentation \u2014 Typos, clarifications, examples</li> <li>\u2728 Features \u2014 New strategies, integrations, tooling</li> <li>\ud83e\uddea Tests \u2014 Increase coverage, add edge cases</li> </ul> <p>\ud83d\udc49 Contributing Guide</p>"},{"location":"community/#code-of-conduct","title":"Code of Conduct","text":"<p>We are committed to providing a welcoming and inspiring community for all.</p> <p>\ud83d\udc49 Code of Conduct</p>"},{"location":"community/#security","title":"Security","text":"<p>Found a security vulnerability? Please report it responsibly.</p> <p>\ud83d\udc49 Security Policy</p>"},{"location":"community/#stay-updated","title":"Stay Updated","text":"<ul> <li>\u2b50 Star the repo to follow updates</li> <li>\ud83d\udc40 Watch releases for new versions</li> </ul>"},{"location":"demos/","title":"Solutions Overview","text":"<p>ArqonHPO is designed for systems where latency and safety are non-negotiable.</p>"},{"location":"demos/#by-use-case","title":"By Use Case","text":""},{"location":"demos/#inference-serving","title":"\ud83e\udd16 Inference Serving","text":"<p>Dynamic batch sizes, KV-cache eviction policies, and router weights. Optimize throughput under p99 latency constraints.</p>"},{"location":"demos/#systems-sre","title":"\ud83c\udfed Systems &amp; SRE","text":"<p>Database connection pools, JVM garbage collection tuning, and admission control queues. Keep systems stable under load.</p>"},{"location":"demos/#edge-robotics","title":"\ud83d\ude81 Edge &amp; Robotics","text":"<p>Control loops on constrained hardware. 100ns execution time means you can optimize inside a 1kHz control loop.</p>"},{"location":"demos/edge/","title":"Edge &amp; Robotics","text":"<p>ArqonHPO is designed for real-time control loops where latency is measured in microseconds.</p>"},{"location":"demos/edge/#the-challenge","title":"The Challenge","text":"<p>Traditional HPO libraries have 100-1000ms overhead per trial. In a 1kHz control loop (1ms budget), this is impossible.</p> <p>ArqonHPO overhead: ~3ms for batch, ~100ns per cached lookup.</p>"},{"location":"demos/edge/#use-cases","title":"Use Cases","text":""},{"location":"demos/edge/#pid-controller-tuning","title":"PID Controller Tuning","text":"<p>Continuously adjust Kp, Ki, Kd gains based on tracking error.</p> <pre><code>import json\nfrom arqonhpo import ArqonSolver\n\nconfig = {\n    \"seed\": 42,\n    \"budget\": 1000,\n    \"bounds\": {\n        \"kp\": {\"min\": 0.1, \"max\": 10.0},\n        \"ki\": {\"min\": 0.0, \"max\": 1.0},\n        \"kd\": {\"min\": 0.0, \"max\": 5.0}\n    }\n}\n\nsolver = ArqonSolver(json.dumps(config))\n\n# In your control loop\nwhile running:\n    candidate = solver.ask_one()\n    if candidate is None:\n        break\n\n    # Apply gains\n    controller.set_gains(candidate[\"kp\"], candidate[\"ki\"], candidate[\"kd\"])\n\n    # Measure tracking error over N timesteps\n    error = measure_tracking_error(duration_ms=100)\n\n    # Feedback\n    solver.seed(json.dumps([{\n        \"params\": candidate,\n        \"value\": error,  # Minimize error\n        \"cost\": 1.0\n    }]))\n</code></pre>"},{"location":"demos/edge/#sensor-fusion-weights","title":"Sensor Fusion Weights","text":"<p>Optimize weights for Kalman filter sensor fusion in real-time.</p>"},{"location":"demos/edge/#motor-control-parameters","title":"Motor Control Parameters","text":"<p>Tune acceleration curves, jerk limits, and response damping.</p>"},{"location":"demos/edge/#embedded-deployment","title":"Embedded Deployment","text":"<p>ArqonHPO compiles to a static binary with no runtime dependencies:</p> <pre><code># Cross-compile for ARM64\ncargo build --release --target aarch64-unknown-linux-gnu -p arqonhpo-cli\n</code></pre> <p>Memory footprint: ~5MB binary, ~2MB runtime heap.</p>"},{"location":"demos/edge/#determinism","title":"Determinism","text":"<p>For safety-critical applications, ArqonHPO guarantees:</p> <ul> <li>Reproducible sequences with fixed seed</li> <li>Bounded deltas via Guardrails</li> <li>Rollback if performance regresses</li> <li>Audit trail of all parameter changes</li> </ul>"},{"location":"demos/edge/#next-steps","title":"Next Steps","text":"<ul> <li>Safety Deep Dive \u2014 Guardrails for safety-critical systems</li> </ul>"},{"location":"demos/inference/","title":"Inference Serving","text":"<p>ArqonHPO optimizes LLM serving infrastructure in real-time, adapting to traffic patterns and model behavior.</p>"},{"location":"demos/inference/#the-challenge","title":"The Challenge","text":"<p>LLM inference costs dominate AI budgets. Static configurations leave performance on the table:</p> <ul> <li>Batch size too small = GPU underutilized</li> <li>Batch size too large = p99 latency blows SLA</li> <li>KV-cache miss = expensive recomputation</li> </ul> <p>ArqonHPO continuously tunes these parameters as traffic shifts.</p>"},{"location":"demos/inference/#what-to-optimize","title":"What to Optimize","text":"Parameter Impact <code>batch_size</code> Throughput vs. latency <code>max_tokens</code> Memory vs. completion length <code>kv_cache_size</code> Hit rate vs. memory <code>speculative_decoding_k</code> Speed vs. accuracy <code>router_weights</code> Model selection (small vs. large)"},{"location":"demos/inference/#example-dynamic-batch-sizing","title":"Example: Dynamic Batch Sizing","text":"<pre><code>import json\nfrom arqonhpo import ArqonSolver\n\nconfig = {\n    \"seed\": 42,\n    \"budget\": 10000,\n    \"bounds\": {\n        \"batch_size\": {\"min\": 1, \"max\": 64, \"scale\": \"Log\"},\n        \"max_wait_ms\": {\"min\": 10, \"max\": 500}\n    }\n}\n\nsolver = ArqonSolver(json.dumps(config))\n\nwhile True:\n    candidate = solver.ask_one()\n    if candidate is None:\n        break\n\n    # Apply new batch config\n    serving_engine.set_batch_config(\n        batch_size=int(candidate[\"batch_size\"]),\n        max_wait_ms=candidate[\"max_wait_ms\"]\n    )\n\n    # Measure over 60 seconds\n    metrics = serving_engine.collect_metrics(duration_s=60)\n\n    # Objective: maximize throughput while keeping p99 &lt; SLA\n    if metrics.p99_latency_ms &gt; SLA_MS:\n        reward = -1000  # Penalty for SLA violation\n    else:\n        reward = -metrics.cost_per_token  # Minimize cost\n\n    solver.seed(json.dumps([{\n        \"params\": candidate,\n        \"value\": reward,\n        \"cost\": 60.0  # Cost = seconds spent\n    }]))\n</code></pre>"},{"location":"demos/inference/#integration-points","title":"Integration Points","text":""},{"location":"demos/inference/#vllm","title":"vLLM","text":"<pre><code># Tune PagedAttention parameters\nconfig[\"bounds\"][\"block_size\"] = {\"min\": 8, \"max\": 32}\nconfig[\"bounds\"][\"gpu_memory_utilization\"] = {\"min\": 0.7, \"max\": 0.95}\n</code></pre>"},{"location":"demos/inference/#tensorrt-llm","title":"TensorRT-LLM","text":"<pre><code># Tune inflight batching\nconfig[\"bounds\"][\"max_batch_size\"] = {\"min\": 1, \"max\": 256}\nconfig[\"bounds\"][\"max_queue_delay_ms\"] = {\"min\": 1, \"max\": 100}\n</code></pre>"},{"location":"demos/inference/#triton-inference-server","title":"Triton Inference Server","text":"<pre><code># Tune dynamic batching\nconfig[\"bounds\"][\"preferred_batch_size\"] = {\"min\": 1, \"max\": 128}\nconfig[\"bounds\"][\"max_queue_delay_microseconds\"] = {\"min\": 100, \"max\": 10000}\n</code></pre>"},{"location":"demos/inference/#safety-for-production","title":"Safety for Production","text":"<p>Use Guardrails to prevent catastrophic configurations:</p> <pre><code>{\n  \"bounds\": [\n    [1, 64],\n    [10, 500]\n  ],\n  \"max_delta\": [8, 100],\n  \"max_updates_per_second\": 1.0\n}\n</code></pre> <ul> <li>max_delta prevents wild swings in batch size</li> <li>rate limit prevents oscillation</li> </ul>"},{"location":"demos/inference/#next-steps","title":"Next Steps","text":"<ul> <li>Batch vs Online Mode</li> <li>Safety Deep Dive</li> <li>Observability</li> </ul>"},{"location":"demos/systems/","title":"Systems &amp; SRE","text":"<p>ArqonHPO keeps infrastructure systems stable by continuously tuning operational parameters as conditions change.</p>"},{"location":"demos/systems/#the-challenge","title":"The Challenge","text":"<p>Static configuration drifts from optimal as:</p> <ul> <li>Traffic patterns shift (day/night, seasonal)</li> <li>Hardware ages (slower disks, thermal throttling)</li> <li>Dependencies change (upstream latency, API limits)</li> </ul> <p>Manual tuning can't keep up. ArqonHPO automates it.</p>"},{"location":"demos/systems/#what-to-optimize","title":"What to Optimize","text":""},{"location":"demos/systems/#database-connections","title":"Database Connections","text":"Parameter Impact <code>pool_size</code> Throughput vs. connection overhead <code>max_idle_time</code> Resource usage vs. cold start <code>connection_timeout</code> Resilience vs. latency"},{"location":"demos/systems/#caching","title":"Caching","text":"Parameter Impact <code>ttl_seconds</code> Freshness vs. hit rate <code>max_memory_mb</code> Hit rate vs. eviction <code>eviction_policy</code> Workload-specific optimization"},{"location":"demos/systems/#queue-management","title":"Queue Management","text":"Parameter Impact <code>batch_size</code> Throughput vs. latency <code>prefetch_count</code> Throughput vs. memory <code>visibility_timeout</code> Reliability vs. reprocessing"},{"location":"demos/systems/#example-connection-pool-tuning","title":"Example: Connection Pool Tuning","text":"<pre><code>import json\nfrom arqonhpo import ArqonSolver\n\nconfig = {\n    \"seed\": 42,\n    \"budget\": 500,\n    \"bounds\": {\n        \"pool_size\": {\"min\": 5, \"max\": 100},\n        \"max_idle_time_s\": {\"min\": 30, \"max\": 600},\n        \"connection_timeout_ms\": {\"min\": 100, \"max\": 5000}\n    }\n}\n\nsolver = ArqonSolver(json.dumps(config))\n\nwhile True:\n    candidate = solver.ask_one()\n    if candidate is None:\n        break\n\n    # Apply new pool config (hot reload)\n    db_pool.reconfigure(\n        pool_size=int(candidate[\"pool_size\"]),\n        max_idle_time=candidate[\"max_idle_time_s\"],\n        timeout=candidate[\"connection_timeout_ms\"]\n    )\n\n    # Observe for 5 minutes\n    metrics = observe_db_metrics(duration_s=300)\n\n    # Multi-objective: high throughput, low p99, low errors\n    score = (\n        metrics.queries_per_second * 10\n        - metrics.p99_latency_ms\n        - metrics.error_rate * 1000\n    )\n\n    solver.seed(json.dumps([{\n        \"params\": candidate,\n        \"value\": -score,  # Minimize negative score = maximize\n        \"cost\": 300.0\n    }]))\n</code></pre>"},{"location":"demos/systems/#example-jvm-gc-tuning","title":"Example: JVM GC Tuning","text":"<pre><code>config = {\n    \"seed\": 42,\n    \"budget\": 100,\n    \"bounds\": {\n        \"heap_size_gb\": {\"min\": 4, \"max\": 32},\n        \"new_ratio\": {\"min\": 1, \"max\": 8},\n        \"survivor_ratio\": {\"min\": 2, \"max\": 32},\n        \"max_gc_pause_ms\": {\"min\": 50, \"max\": 500}\n    }\n}\n\n# Apply via JVM flags:\n# -Xmx{heap_size}g -XX:NewRatio={new_ratio} ...\n</code></pre>"},{"location":"demos/systems/#observability-integration","title":"Observability Integration","text":"<p>ArqonHPO exports Prometheus metrics:</p> <pre><code># Track optimization progress\narqon_history_len\narqon_ask_total\narqon_tell_total\n\n# Monitor for regressions\nrate(arqon_eval_duration_seconds_sum[5m]) / rate(arqon_eval_duration_seconds_count[5m])\n</code></pre>"},{"location":"demos/systems/#safety-for-production","title":"Safety for Production","text":"<p>Guardrails prevent runaway configurations:</p> <pre><code>{\n  \"max_delta\": [10, 60, 500],\n  \"max_updates_per_second\": 0.1,\n  \"rollback_on_regression\": true\n}\n</code></pre> <ul> <li>10 connections max change per update</li> <li>1 update per 10 seconds max</li> <li>Auto-rollback if p99 spikes</li> </ul>"},{"location":"demos/systems/#next-steps","title":"Next Steps","text":"<ul> <li>Safety Deep Dive</li> <li>Observability</li> <li>CLI Reference</li> </ul>"},{"location":"documentation/","title":"Index","text":"Arqon Runtime Optimizer Optimization isn't a workflow anymore.It's a control loop. <p>Safe self-optimization, robustness, and resilience for live systems\u2014with microsecond-class overhead and deterministic governance.</p> \ud83d\udee1\ufe0f Safe by Construction \ud83c\udfaf Deterministic &amp; Replayable \u26a1 Hot-Path Ready <p>Powered by <code>ArqonHPO</code></p> Get Started See It Live Real-Time Policy Autopilot const TIMEOUT = 300; \u2192 fn timeout(load, latency) -&gt; ms          Don't deploy a number. Deploy a policy that continuously finds the right number.      Beachhead 1 Reliability Autopilot <p>The Pain: Incident fatigue, dependency flaps, p99 spikes.</p> <p>The Fix: Dynamically tune timeouts, retries, circuit breakers, and load shedding thresholds in response to telemetry.</p> Beachhead 2 Cache &amp; Queue Control <p>The Pain: Constant traffic drift makes static tuning impossible.</p> <p>The Fix: Continuous adjustment of TTLs, admission policies, batch sizes, and queue limits to maximize throughput.</p> Beachhead 3 LLM / Inference Serving <p>The Pain: Massive serving costs, unpredictable model mix.</p> <p>The Fix: Autopilot for KV cache, spec decoding thresholds, and batching parameters. High Buyer Urgency.</p> Expansion Also works for... <ul> <li>Database Vacuuming</li> <li>Kernel Selection</li> <li>Mesh Routing</li> <li>Autoscaling Triggers</li> </ul> Old World: Workflow <p>You run experiments, wait, and manually retune. The system drifts between \"tuning sessions.\"</p> <p>\u274c Slow \u2022 Brittle \u2022 Human-bound</p> New World: Control Primitive <p>The system continuously corrects itself inside the loop. Detects drift and applies bounded adjustments instantly.</p> <p>\u2705 Safe \u2022 Continuous \u2022 Auditable</p> The Promise: Near-zero overhead, with safety guarantees. <p>ArqonHPO makes self-optimization cheap enough to run continuously\u2014so resilience becomes a default property, not an ops project.</p> 4 Proofs of the New Paradigm PROOF A: DRFT Survive the Drift <p>Traffic shifts. Hardware ages. ArqonHPO acts as a homeostatic system, adapting in real-time to maintain optimal SLAs.</p> PROOF B: JITTER Flatten the Jitter <p>Zero GC pauses. Engineered for the hot path. We prove sub-microsecond p99 overhead for every decision.</p> PROOF C: ANYWHERE Everywhere <p>One primitive. Rust server, Python script, Browser WASM, Edge device. Same API, same safety guarantees.</p> PROOF D: ORGANISM Organism Capabilities <p>Apply to every knob. The system evolves from a machine into an organism with its own self-regulating metabolism.</p> View Full Benchmarks \u2192 Autonomy without Chaos <p>Every action is bounded, attributable, and reversible. Trust is our primary product.</p> 01 \ud83d\udee1\ufe0f Allowlist Only <p>Unknown knobs are rejected. You explicitly define exactly which policies and parameters the control loop can touch.</p> 02 \ud83d\uded1 Bounded Deltas <p>Strict step-size limits and global bounds prevent wild oscillations or dangerous state transitions.</p> 03 \u23ea Instant Rollback <p>Baseline restoration is an atomic, first-class operation. One call returns the system to a known-safe safety state.</p> 04 \ud83d\udcdc Audit Trail <p>Every proposal and decision is immortalized in a lock-free event stream. You know exactly why the system changed.</p> The Adoption Ladder              Shadow Mode             Phase 01 Arqon reads telemetry and emits proposals, but does not apply them. Verify the autonomous logic against your team's manual decisions.              Low-Risk Actuation             Phase 02 Enable actuation on reversible, low-blast-radius knobs like cache TTLs or batch sizes. Build confidence in the control layer.              High Leverage Policies             Phase 03 Expand to timeouts, retries, and load-shedding thresholds. Allow Arqon to steer your system's reliability through volatility.              Fleet Governance             Phase 04 Run local control loops on every node with centralized policy oversight. Autonomous resilience becomes a default property of your software."},{"location":"documentation/faq/","title":"FAQ","text":"<p>Frequently asked questions about ArqonHPO.</p>"},{"location":"documentation/faq/#general","title":"General","text":""},{"location":"documentation/faq/#what-is-arqonhpo","title":"What is ArqonHPO?","text":"<p>ArqonHPO is a microsecond-budget hyperparameter optimizer written in Rust with Python bindings. It's designed for systems where optimization happens as a continuous control loop, not a one-time search.</p>"},{"location":"documentation/faq/#when-should-i-use-arqonhpo-vs-optuna","title":"When should I use ArqonHPO vs Optuna?","text":"Use ArqonHPO when... Use Optuna when... Evaluations are &lt;10ms Evaluations are &gt;1s Need real-time tuning Running offline experiments Want deterministic replay Need advanced samplers Embedded/constrained systems Rich visualization needed"},{"location":"documentation/faq/#is-it-production-ready","title":"Is it production-ready?","text":"<p>Yes. ArqonHPO is used in production for:</p> <ul> <li>LLM inference batch sizing</li> <li>Real-time control loops</li> <li>SRE automation</li> </ul> <p>We have 91% test coverage and a strict Constitution.</p>"},{"location":"documentation/faq/#algorithm","title":"Algorithm","text":""},{"location":"documentation/faq/#what-optimization-algorithms-does-it-use","title":"What optimization algorithms does it use?","text":"<ol> <li>Nelder-Mead \u2014 Simplex method for smooth functions</li> <li>Multi-Start Nelder-Mead \u2014 Parallel restarts for multimodal</li> <li>TPE \u2014 Bayesian optimization for noisy landscapes</li> </ol> <p>The Classify phase automatically selects the best strategy.</p>"},{"location":"documentation/faq/#is-it-deterministic","title":"Is it deterministic?","text":"<p>Yes! With a fixed seed, ArqonHPO produces identical results:</p> <pre><code># Same seed = same sequence\nsolver1 = ArqonSolver('{\"seed\": 42, ...}')\nsolver2 = ArqonSolver('{\"seed\": 42, ...}')\n# solver1.ask() == solver2.ask()  \u2713\n</code></pre>"},{"location":"documentation/faq/#how-does-arqonprobe-work","title":"How does ArqonProbe work?","text":"<p><code>ArqonProbe</code> generates Low-Discrepancy Sequences for uniform parameter space coverage:</p> <pre><code>probe = ArqonProbe(config_json, seed=42)\npoint = probe.sample_at(0)    # First point\npoints = probe.sample_range(0, 100)  # Points 0-99\n</code></pre> <p>It's stateless and shardable \u2014 worker N can generate points [N100, (N+1)100) without coordination.</p>"},{"location":"documentation/faq/#performance","title":"Performance","text":""},{"location":"documentation/faq/#how-fast-is-it","title":"How fast is it?","text":"Metric Value Overhead per trial ~3ms Throughput ~33,000 trials/sec Memory O(history_size)"},{"location":"documentation/faq/#why-is-it-faster-than-optuna","title":"Why is it faster than Optuna?","text":"<ol> <li>Rust core \u2014 No Python GIL, no interpreter overhead</li> <li>Batch processing \u2014 Amortize overhead across many candidates</li> <li>Stateless probing \u2014 No synchronization between workers</li> </ol>"},{"location":"documentation/faq/#can-it-run-on-embedded-systems","title":"Can it run on embedded systems?","text":"<p>Yes. The CLI compiles to a ~5MB static binary with no runtime dependencies.</p>"},{"location":"documentation/faq/#safety","title":"Safety","text":""},{"location":"documentation/faq/#what-are-guardrails","title":"What are Guardrails?","text":"<p>Guardrails prevent dangerous configurations:</p> <ul> <li>Bounds \u2014 Absolute limits on values</li> <li>Delta limits \u2014 Max change per update</li> <li>Rate limits \u2014 Max updates per second</li> </ul> <p>See Safety for details.</p>"},{"location":"documentation/faq/#does-it-support-rollback","title":"Does it support rollback?","text":"<p>Yes. Configure a rollback policy:</p> <pre><code>{\n  \"rollback_policy\": {\n    \"max_consecutive_regressions\": 3\n  }\n}\n</code></pre> <p>After 3 worse results, it reverts to the last good config.</p>"},{"location":"documentation/faq/#integration","title":"Integration","text":""},{"location":"documentation/faq/#how-do-i-monitor-it","title":"How do I monitor it?","text":"<ul> <li>TUI \u2014 <code>arqonhpo tui --state state.json</code></li> <li>Dashboard \u2014 <code>arqonhpo dashboard --state state.json</code></li> <li>Prometheus \u2014 <code>--metrics-addr 127.0.0.1:9898</code></li> </ul>"},{"location":"documentation/faq/#can-i-use-it-with-kubernetes","title":"Can I use it with Kubernetes?","text":"<p>Yes, via:</p> <ol> <li>CLI in a sidecar container</li> <li>Python bindings in your app</li> <li>Dashboard for monitoring</li> </ol> <p>Helm chart planned for v0.4.</p>"},{"location":"documentation/faq/#does-it-work-with-raydask","title":"Does it work with Ray/Dask?","text":"<p><code>ArqonProbe</code> is designed for distributed workers \u2014 each worker can sample independent ranges without coordination.</p>"},{"location":"documentation/faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"documentation/faq/#see-troubleshooting-guide","title":"See Troubleshooting Guide","text":""},{"location":"documentation/faq/#more-questions","title":"More Questions?","text":"<ul> <li>GitHub Discussions</li> <li>Issue Tracker</li> </ul>"},{"location":"documentation/installation/","title":"Installation","text":"Installation Get ArqonHPO running on your system in minutes. <p>Whether you're optimizing your first hyperparameter or building production-grade ML pipelines, this guide has you covered.</p>"},{"location":"documentation/installation/#choose-your-path","title":"Choose Your Path","text":"Method Best For Time to Start Python (pip) Most users, ML workflows 30 seconds Python (conda) Reproducible environments 1 minute Rust (from source) Contributors, custom builds 5 minutes Python bindings (from source) Binding development 3 minutes Docker Isolated environments, CI/CD 2 minutes"},{"location":"documentation/installation/#python-recommended","title":"Python (Recommended)","text":"<p>The fastest way to get started with ArqonHPO:</p> <pre><code>pip install arqonhpo\n</code></pre> <p>That's it. You're ready to optimize.</p> <p>No Rust Required</p> <p>The pip package includes pre-built binaries for all major platforms. You only need Rust if building from source.</p>"},{"location":"documentation/installation/#requirements","title":"Requirements","text":"Requirement Version How to Check Python 3.10+ <code>python --version</code> pip 21.0+ <code>pip --version</code> OS 64-bit Linux, macOS, or Windows \u2014"},{"location":"documentation/installation/#verify-installation","title":"Verify Installation","text":"<pre><code>python -c \"from arqonhpo import ArqonSolver; print('\u2713 ArqonHPO installed successfully')\"\n</code></pre>"},{"location":"documentation/installation/#upgrade-to-latest","title":"Upgrade to Latest","text":"<pre><code>pip install --upgrade arqonhpo\n</code></pre>"},{"location":"documentation/installation/#install-specific-version","title":"Install Specific Version","text":"<pre><code>pip install arqonhpo==0.3.0\n</code></pre>"},{"location":"documentation/installation/#conda","title":"Conda","text":"<p>For reproducible environments and scientific workflows:</p> <pre><code>conda install -c conda-forge arqonhpo\n</code></pre>"},{"location":"documentation/installation/#create-a-dedicated-environment","title":"Create a Dedicated Environment","text":"<pre><code># Create environment with ArqonHPO\nconda create -n hpo python=3.11 arqonhpo -c conda-forge\n\n# Activate it\nconda activate hpo\n\n# Verify\npython -c \"from arqonhpo import ArqonSolver; print('\u2713 Ready')\"\n</code></pre>"},{"location":"documentation/installation/#with-other-ml-libraries","title":"With Other ML Libraries","text":"<pre><code>conda create -n ml-tuning python=3.11 arqonhpo pytorch scikit-learn -c conda-forge -c pytorch\n</code></pre>"},{"location":"documentation/installation/#from-source-rust","title":"From Source (Rust)","text":"<p>Build ArqonHPO from source for development, customization, or to use the bleeding-edge version.</p> <p>Rust 1.82 Required</p> <p>Building from source requires exactly Rust 1.82. This version is frozen due to specific language features and API dependencies used in the codebase.</p>"},{"location":"documentation/installation/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following installed:</p>"},{"location":"documentation/installation/#1-rust-toolchain-182-pinned","title":"1. Rust Toolchain (1.82 \u2014 Pinned)","text":"<pre><code># Install Rust via rustup (recommended)\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n\n# Update to latest stable\nrustup update stable\n\n# Verify version\nrustc --version  # Must show exactly 1.82.x\n</code></pre> Windows Users <p>On Windows, download and run rustup-init.exe instead. You may also need to install the Visual Studio Build Tools.</p>"},{"location":"documentation/installation/#2-protobuf-compiler","title":"2. Protobuf Compiler","text":"<p>ArqonHPO uses Protocol Buffers for efficient serialization.</p> Ubuntu/Debian <p><code>bash     sudo apt update &amp;&amp; sudo apt install -y protobuf-compiler</code></p> macOS <p><code>bash     brew install protobuf</code></p> Fedora/RHEL <p><code>bash     sudo dnf install -y protobuf-compiler</code></p> Arch Linux <p><code>bash     sudo pacman -S protobuf</code></p> Windows <p>```powershell # Using Chocolatey choco install protoc</p> <pre><code># Or using Scoop\nscoop install protobuf\n```\n</code></pre> <p>Verify protobuf installation:</p> <pre><code>protoc --version  # Should show libprotoc 3.x or higher\n</code></pre>"},{"location":"documentation/installation/#3-just-task-runner","title":"3. Just (Task Runner)","text":"<p>We use Just as our task runner for consistent developer experience.</p> Cargo (Any Platform) <p><code>bash     cargo install just</code></p> macOS <p><code>bash     brew install just</code></p> Ubuntu/Debian <p><code>bash     sudo apt install just     # Or use cargo install just if not available</code></p> Windows <p>```powershell # Using Chocolatey choco install just</p> <pre><code># Using Scoop\nscoop install just\n```\n</code></pre>"},{"location":"documentation/installation/#4-git","title":"4. Git","text":"<pre><code>git --version  # Should show 2.x or higher\n</code></pre>"},{"location":"documentation/installation/#build-steps","title":"Build Steps","text":"<pre><code># 1. Clone the repository\ngit clone https://github.com/novelbytelabs/ArqonHPO.git\ncd ArqonHPO\n\n# 2. Build all crates in release mode\ncargo build --workspace --release\n\n# 3. Run the test suite to verify everything works\ncargo test --workspace\n</code></pre> <p>Build Complete</p> <p>If all tests pass, you've successfully built ArqonHPO from source!</p>"},{"location":"documentation/installation/#install-the-cli","title":"Install the CLI","text":"<p>The ArqonHPO CLI provides interactive optimization via the terminal:</p> <pre><code># Install the CLI binary\ncargo install --path crates/cli --bin arqonhpo-cli\n\n# Verify installation\narqonhpo-cli --version\n</code></pre> <p>The binary will be installed to <code>~/.cargo/bin/</code>. Ensure this is in your <code>PATH</code>.</p>"},{"location":"documentation/installation/#development-build-debug-mode","title":"Development Build (Debug Mode)","text":"<p>For faster compilation during development:</p> <pre><code>cargo build --workspace\ncargo test --workspace\n</code></pre>"},{"location":"documentation/installation/#python-bindings-maturin","title":"Python Bindings (Maturin)","text":"<p>Build Python bindings from source when contributing to the Python API or testing unreleased features.</p>"},{"location":"documentation/installation/#prerequisites_1","title":"Prerequisites","text":"<ul> <li>Rust 1.82 (see above)</li> <li>Python 3.10+ with a virtual environment</li> <li>maturin (Python-Rust build tool)</li> </ul>"},{"location":"documentation/installation/#setup","title":"Setup","text":"<pre><code># 1. Clone the repository\ngit clone https://github.com/novelbytelabs/ArqonHPO.git\ncd ArqonHPO\n\n# 2. Create a virtual environment\npython -m venv venv\nsource venv/bin/activate  # Linux/macOS\n# Or: venv\\Scripts\\activate  # Windows\n\n# 3. Install maturin\npip install maturin\n\n# 4. Build and install the bindings in development mode\ncd bindings/python\nmaturin develop --release\n</code></pre>"},{"location":"documentation/installation/#verify","title":"Verify","text":"<pre><code>python -c \"from arqonhpo import ArqonSolver, ArqonProbe; print('\u2713 Bindings installed')\"\n</code></pre>"},{"location":"documentation/installation/#build-distributable-wheels","title":"Build Distributable Wheels","text":"<p>To create wheel files for distribution:</p> <pre><code># Build wheels for your platform\nmaturin build --release -m bindings/python/Cargo.toml\n\n# Wheels are output to target/wheels/\nls target/wheels/\n</code></pre>"},{"location":"documentation/installation/#docker","title":"Docker","text":"<p>Containerized ArqonHPO for isolated environments and CI/CD pipelines.</p>"},{"location":"documentation/installation/#quick-start","title":"Quick Start","text":"<pre><code># Pull the official image\ndocker pull novelbytelabs/arqonhpo:latest\n\n# Run interactively\ndocker run -it novelbytelabs/arqonhpo:latest python\n&gt;&gt;&gt; from arqonhpo import ArqonSolver\n&gt;&gt;&gt; print(\"Ready!\")\n</code></pre>"},{"location":"documentation/installation/#mount-your-project","title":"Mount Your Project","text":"<pre><code>docker run -it -v $(pwd):/workspace novelbytelabs/arqonhpo:latest bash\n</code></pre>"},{"location":"documentation/installation/#docker-compose","title":"Docker Compose","text":"<p>For complex setups:</p> <pre><code># docker-compose.yml\nversion: \"3.8\"\nservices:\n  optimizer:\n    image: novelbytelabs/arqonhpo:latest\n    volumes:\n      - ./experiments:/workspace\n    command: python /workspace/run_hpo.py\n</code></pre>"},{"location":"documentation/installation/#build-custom-image","title":"Build Custom Image","text":"<pre><code>FROM novelbytelabs/arqonhpo:latest\n\n# Add your dependencies\nRUN pip install torch transformers\n\n# Copy your code\nCOPY . /app\nWORKDIR /app\n\nCMD [\"python\", \"optimize.py\"]\n</code></pre> <p>Docker Image Availability</p> <p>Docker images are published starting from v0.4. For earlier versions, build from source using the Dockerfile in the repository.</p>"},{"location":"documentation/installation/#platform-support","title":"Platform Support","text":""},{"location":"documentation/installation/#officially-supported","title":"Officially Supported","text":"Platform Python CLI Notes Linux x86_64 \u2705 \u2705 Full support, primary development platform Linux ARM64 \u2705 \u2705 Full support (AWS Graviton, Raspberry Pi 4+) macOS x86_64 \u2705 \u2705 Full support macOS ARM64 (Apple Silicon) \u2705 \u2705 Full support, native M1/M2/M3 binaries Windows x86_64 \u2705 \u2705 Full support, tested on Windows 10/11"},{"location":"documentation/installation/#community-supported","title":"Community Supported","text":"<p>These platforms may work but are not actively tested:</p> Platform Status Notes FreeBSD \ud83d\udd27 Build from source, may require patches Windows ARM64 \ud83d\udd27 Untested, requires building from source musl Linux (Alpine) \ud83d\udd27 Use <code>--target x86_64-unknown-linux-musl</code>"},{"location":"documentation/installation/#virtual-environment-best-practices","title":"Virtual Environment Best Practices","text":"<p>We strongly recommend using virtual environments to isolate ArqonHPO from other projects.</p>"},{"location":"documentation/installation/#option-1-venv-built-in","title":"Option 1: venv (Built-in)","text":"<pre><code># Create environment\npython -m venv arqon-env\n\n# Activate\nsource arqon-env/bin/activate  # Linux/macOS\narqon-env\\Scripts\\activate     # Windows\n\n# Install\npip install arqonhpo\n</code></pre>"},{"location":"documentation/installation/#option-2-conda","title":"Option 2: conda","text":"<pre><code>conda create -n arqon python=3.11\nconda activate arqon\npip install arqonhpo\n</code></pre>"},{"location":"documentation/installation/#option-3-uv-fast-modern","title":"Option 3: uv (Fast &amp; Modern)","text":"<p>uv is a blazing-fast Python package manager:</p> <pre><code># Install uv\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Create environment and install\nuv venv\nsource .venv/bin/activate\nuv pip install arqonhpo\n</code></pre>"},{"location":"documentation/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"documentation/installation/#installation-issues","title":"Installation Issues","text":"<code>pip install</code> fails with 'no matching distribution' <p>Cause: Your Python version or platform is not supported.</p> <pre><code>**Solution**:\n```bash\n# Check Python version (need 3.10+)\npython --version\n\n# Check architecture\npython -c \"import platform; print(platform.machine())\"\n```\n\nIf you're on an unsupported platform, [build from source](#from-source-rust).\n</code></pre> Rust build fails with protobuf error <p>Error: <code>Could not find protoc installation</code></p> <pre><code>**Solution**: Install protobuf compiler for your platform:\n```bash\n# Ubuntu/Debian\nsudo apt install protobuf-compiler\n\n# macOS\nbrew install protobuf\n\n# Verify\nprotoc --version\n```\n</code></pre> Import error: 'symbol not found' <p>Cause: Python version mismatch between build and runtime.</p> <pre><code>**Solution**:\n```bash\n# Ensure you're using the same Python that built the bindings\nwhich python\n\n# Rebuild in a clean environment\npip uninstall arqonhpo\npip install arqonhpo --no-cache-dir\n```\n</code></pre> Permission denied during install <p>Solution: Use a virtual environment instead of system Python: <code>bash     python -m venv venv     source venv/bin/activate     pip install arqonhpo</code></p> Windows: 'cargo' is not recognized <p>Cause: Rust not in PATH after installation.</p> <pre><code>**Solution**:\n1. Close and reopen your terminal\n2. Or manually add `%USERPROFILE%\\.cargo\\bin` to your PATH\n</code></pre>"},{"location":"documentation/installation/#runtime-issues","title":"Runtime Issues","text":"Performance is slower than expected <p>Checklist:</p> <pre><code>- [ ] Using release build? (`cargo build --release`)\n- [ ] Not running under debugger?\n- [ ] CPU not throttled? (check power settings on laptops)\n- [ ] No other heavy processes competing for resources?\n</code></pre> Out of memory during optimization <p>Solutions:</p> <pre><code>1. Reduce population size in strategies\n2. Use streaming evaluation for large datasets\n3. Increase system swap space\n4. Consider using chunked optimization\n</code></pre>"},{"location":"documentation/installation/#getting-more-help","title":"Getting More Help","text":"<p>If your issue isn't listed above:</p> <ol> <li>Search existing issues: GitHub Issues</li> <li>Ask in discussions: GitHub Discussions</li> <li>Open a new issue with:</li> <li>Your OS and version</li> <li>Python version</li> <li>ArqonHPO version</li> <li>Full error message/stack trace</li> </ol>"},{"location":"documentation/installation/#uninstalling","title":"Uninstalling","text":""},{"location":"documentation/installation/#python-package","title":"Python Package","text":"<pre><code>pip uninstall arqonhpo\n</code></pre>"},{"location":"documentation/installation/#rust-cli","title":"Rust CLI","text":"<pre><code>cargo uninstall arqonhpo-cli\n\n# Or manually remove\nrm ~/.cargo/bin/arqonhpo-cli\n</code></pre>"},{"location":"documentation/installation/#complete-cleanup","title":"Complete Cleanup","text":"<pre><code># Remove pip cache\npip cache purge\n\n# Remove cargo artifacts (if built from source)\ncd ArqonHPO &amp;&amp; cargo clean\n</code></pre>"},{"location":"documentation/installation/#next-steps","title":"Next Steps","text":"<p>You're all set! Here's where to go next:</p> <ul> <li> Quickstart Guide</li> </ul> <p>Get running in 5 minutes with your first optimization</p> <ul> <li> Python API Reference</li> </ul> <p>Complete API documentation</p> <ul> <li> Examples &amp; Tutorials</li> </ul> <p>Learn by example with real-world use cases</p> <ul> <li> Contributing</li> </ul> <p>Help make ArqonHPO even better</p> <p>Having trouble? Open an issue or ask in discussions.</p> <p>Found ArqonHPO useful? Consider starring the repo </p>"},{"location":"documentation/migration/","title":"Migration Guide","text":"<p>This guide helps you upgrade between ArqonHPO versions.</p>"},{"location":"documentation/migration/#v02-v03-current","title":"v0.2 \u2192 v0.3 (Current)","text":""},{"location":"documentation/migration/#breaking-changes","title":"Breaking Changes","text":"<ol> <li>Config field rename: <code>probe_budget</code> \u2192 <code>probe_ratio</code></li> </ol> <pre><code>{\n  \"seed\": 42,\n  \"budget\": 100,\n- \"probe_budget\": 20,\n+ \"probe_ratio\": 0.2,\n}\n</code></pre> <ol> <li>Python import path change:</li> </ol> <pre><code>- from arqonhpo._internal import ArqonSolver\n+ from arqonhpo import ArqonSolver\n</code></pre> <ol> <li>Artifact schema: <code>history</code> field now includes <code>cost</code>:</li> </ol> <pre><code>{\n  \"eval_id\": 0,\n  \"params\": {\"x\": 1.0},\n  \"value\": 0.5,\n+ \"cost\": 1.0\n}\n</code></pre>"},{"location":"documentation/migration/#migration-steps","title":"Migration Steps","text":"<ol> <li>Update config files (rename <code>probe_budget</code> to <code>probe_ratio</code>)</li> <li>Update imports in Python code</li> <li>Re-export artifacts from v0.2 state files:</li> </ol> <pre><code># With v0.2\narqonhpo export --state old_state.json --output artifact.json\n\n# Manually add \"cost\": 1.0 to each history entry\n\n# With v0.3\narqonhpo import --artifact artifact.json --state new_state.json\n</code></pre>"},{"location":"documentation/migration/#v01-v02","title":"v0.1 \u2192 v0.2","text":""},{"location":"documentation/migration/#breaking-changes_1","title":"Breaking Changes","text":"<ol> <li>CLI renamed: <code>arqon</code> \u2192 <code>arqonhpo</code></li> </ol> <pre><code>- arqon run --config config.json\n+ arqonhpo run --config config.json\n</code></pre> <ol> <li>Python package renamed:</li> </ol> <pre><code>- pip install arqon\n+ pip install arqonhpo\n</code></pre> <ol> <li>Config schema overhaul: Complete rewrite</li> <li>v0.1 configs are not compatible</li> <li>Re-create configs using v0.2 schema</li> </ol>"},{"location":"documentation/migration/#version-compatibility-matrix","title":"Version Compatibility Matrix","text":"ArqonHPO Python Rust State Format v0.3.x 3.10+ 1.82+ v3 v0.2.x 3.9+ 1.75+ v2 v0.1.x 3.8+ 1.70+ v1 (incompatible)"},{"location":"documentation/migration/#state-file-migration","title":"State File Migration","text":"<p>State files are not forward compatible. To migrate state:</p> <ol> <li>Export from old version:</li> </ol> <pre><code># Using OLD arqonhpo version\narqonhpo export --state state.json --output artifact.json\n</code></pre> <ol> <li> <p>Review artifact for schema changes</p> </li> <li> <p>Import with new version:    <pre><code># Using NEW arqonhpo version\narqonhpo import --artifact artifact.json --state new_state.json\n</code></pre></p> </li> </ol> <p>[!WARNING] If import fails due to schema changes, you may need to manually edit the artifact JSON.</p>"},{"location":"documentation/migration/#deprecation-notices","title":"Deprecation Notices","text":""},{"location":"documentation/migration/#v03-current","title":"v0.3 (Current)","text":"Feature Status Replacement <code>probe_budget</code> config Removed Use <code>probe_ratio</code> <code>arqonhpo._internal</code> imports Removed Use <code>arqonhpo</code>"},{"location":"documentation/migration/#v04-upcoming","title":"v0.4 (Upcoming)","text":"Feature Status Replacement <code>strategy_params.alpha</code> Deprecated Use <code>strategy_params.reflection_coeff</code> <code>--log-level debug</code> Deprecated Use <code>--log-level=debug</code> (with <code>=</code>)"},{"location":"documentation/migration/#getting-help","title":"Getting Help","text":"<p>If you encounter migration issues:</p> <ol> <li>Check Troubleshooting</li> <li>Open a GitHub Issue</li> <li>Ask in Discussions</li> </ol>"},{"location":"documentation/migration/#next-steps","title":"Next Steps","text":"<ul> <li>Installation \u2014 Install latest version</li> <li>Quickstart \u2014 Get running with v0.3</li> <li>Changelog \u2014 Full version history</li> </ul>"},{"location":"documentation/quickstart/","title":"Quickstart","text":""},{"location":"documentation/quickstart/#from-zero-to-optimized-in-5-minutes","title":"From zero to optimized in 5 minutes.","text":"<p>ArqonHPO is a high-performance hyperparameter optimization library that adapts to your problem automatically.</p>"},{"location":"documentation/quickstart/#installation","title":"Installation","text":"<pre><code>pip install arqonhpo\n</code></pre> <p>Verify installation:</p> <pre><code>python -c \"from arqonhpo import ArqonSolver; print('\u2713 Ready')\"\n</code></pre> <p>Need other options? See the full Installation Guide.</p>"},{"location":"documentation/quickstart/#core-concepts","title":"Core Concepts","text":"<p>Before diving in, here's what you need to know:</p> Concept Description Objective Function The function you want to minimize (e.g., loss, error, cost) Parameters The variables you want to optimize (e.g., learning_rate, batch_size) Bounds The min/max range for each parameter Budget Total number of evaluations allowed PCR Algorithm ArqonHPO's adaptive algorithm: Probe \u2192 Classify \u2192 Refine <p>ArqonHPO automatically detects whether your problem is smooth (uses Nelder-Mead) or noisy (uses TPE), so you don't have to choose.</p>"},{"location":"documentation/quickstart/#your-first-optimization","title":"Your First Optimization","text":"<p>Let's optimize a simple 2D function. The minimum is at <code>(2, -1)</code> \u2014 let's see if ArqonHPO finds it.</p>"},{"location":"documentation/quickstart/#step-1-define-your-objective-function","title":"Step 1: Define Your Objective Function","text":"<p>The objective function is what you want to minimize. It takes a dictionary of parameters and returns a single number (the \"loss\" or \"cost\").</p> <pre><code>def objective(params: dict) -&gt; float:\n    \"\"\"Simple quadratic bowl with minimum at (2, -1).\"\"\"\n    x = params[\"x\"]\n    y = params[\"y\"]\n    return (x - 2)**2 + (y + 1)**2\n</code></pre> <p>Minimize, Not Maximize</p> <p>ArqonHPO always minimizes. To maximize something (like accuracy), return its negative: <code>return -accuracy</code>.</p>"},{"location":"documentation/quickstart/#step-2-configure-the-solver","title":"Step 2: Configure the Solver","text":"<p>Create a configuration dictionary specifying your search space:</p> <pre><code>import json\nfrom arqonhpo import ArqonSolver\n\nconfig = {\n    \"seed\": 42,                    # Reproducibility\n    \"budget\": 50,                  # Total evaluations\n    \"bounds\": {\n        \"x\": {\"min\": -10.0, \"max\": 10.0},\n        \"y\": {\"min\": -10.0, \"max\": 10.0}\n    }\n}\n\nsolver = ArqonSolver(json.dumps(config))\n</code></pre>"},{"location":"documentation/quickstart/#step-3-run-the-optimization-loop","title":"Step 3: Run the Optimization Loop","text":"<p>The ArqonHPO API uses an ask-tell interface:</p> <ol> <li><code>ask()</code> \u2014 Get a batch of parameter configurations to evaluate</li> <li>Evaluate \u2014 Run your objective function on each configuration</li> <li><code>tell()</code> \u2014 Report the results back to the solver</li> </ol> <pre><code>best_value = float('inf')\nbest_params = None\n\nwhile True:\n    # 1. Ask for candidates\n    batch = solver.ask()\n    if batch is None:\n        break  # Budget exhausted\n\n    # 2. Evaluate each candidate\n    results = []\n    for i, params in enumerate(batch):\n        value = objective(params)\n\n        # Track the best\n        if value &lt; best_value:\n            best_value = value\n            best_params = params\n\n        # Record this evaluation\n        results.append({\n            \"eval_id\": i,\n            \"params\": params,\n            \"value\": value,\n            \"cost\": 1.0  # Relative cost of this evaluation\n        })\n\n    # 3. Tell the solver what happened\n    solver.tell(json.dumps(results))\n\nprint(f\"\u2713 Best parameters: {best_params}\")\nprint(f\"\u2713 Best value: {best_value:.6f}\")\n</code></pre> <p>Expected output:</p> <pre><code>[Machine] Classified as Structured (Score: 1.0172)\n[Machine] Structured Fail-Safe Triggered! Restarting with CP Shift at param count 36\n\u2713 Best parameters: {'x': 1.1, 'y': -0.6066}\n\u2713 Best value: 0.964791\n</code></pre> <p>Results May Vary</p> <p>The exact values depend on the solver's internal state. With only 50 evaluations, the solver is still exploring. Increase <code>budget</code> to 200+ for convergence closer to the true minimum at (2, -1).</p> <p>\ud83c\udf89 ArqonHPO is working! The solver classified the landscape as \"Structured\" and is refining toward the optimum.</p>"},{"location":"documentation/quickstart/#complete-example","title":"Complete Example","text":"<p>Here's everything together as a copy-paste script:</p> <pre><code>\"\"\"ArqonHPO Quickstart - Complete Example\"\"\"\nimport json\nfrom arqonhpo import ArqonSolver\n\n# 1. Define objective function (minimize this)\ndef objective(params: dict) -&gt; float:\n    x, y = params[\"x\"], params[\"y\"]\n    return (x - 2)**2 + (y + 1)**2  # Minimum at (2, -1)\n\n# 2. Configure solver\nconfig = {\n    \"seed\": 42,\n    \"budget\": 50,\n    \"bounds\": {\n        \"x\": {\"min\": -10.0, \"max\": 10.0},\n        \"y\": {\"min\": -10.0, \"max\": 10.0}\n    }\n}\n\nsolver = ArqonSolver(json.dumps(config))\nbest = {\"value\": float('inf'), \"params\": None}\n\n# 3. Optimization loop\nwhile True:\n    batch = solver.ask()\n    if batch is None:\n        break\n\n    results = []\n    for i, params in enumerate(batch):\n        value = objective(params)\n        if value &lt; best[\"value\"]:\n            best = {\"value\": value, \"params\": params}\n        results.append({\n            \"eval_id\": i,\n            \"params\": params,\n            \"value\": value,\n            \"cost\": 1.0\n        })\n\n    solver.tell(json.dumps(results))\n\n# 4. Results\nprint(f\"Evaluations used: {solver.get_history_len()}\")\nprint(f\"Best x: {best['params']['x']:.4f}\")\nprint(f\"Best y: {best['params']['y']:.4f}\")\nprint(f\"Best value: {best['value']:.6f}\")\n</code></pre> <p>Expected output:</p> <pre><code>[Machine] Classified as Structured (Score: 1.0172)\n[Machine] Structured Fail-Safe Triggered! Restarting with CP Shift at param count 36\nEvaluations used: 50\nBest x: 1.1000\nBest y: -0.6066\nBest value: 0.964791\n</code></pre>"},{"location":"documentation/quickstart/#understanding-the-configuration","title":"Understanding the Configuration","text":""},{"location":"documentation/quickstart/#required-fields","title":"Required Fields","text":"<pre><code>config = {\n    \"seed\": 42,       # Random seed for reproducibility\n    \"budget\": 100,    # Maximum number of evaluations\n    \"bounds\": {       # Parameter search space\n        \"param_name\": {\"min\": 0.0, \"max\": 1.0}\n    }\n}\n</code></pre>"},{"location":"documentation/quickstart/#optional-fields","title":"Optional Fields","text":"<pre><code>config = {\n    # ... required fields ...\n\n    \"probe_ratio\": 0.2,  # Fraction of budget for initial exploration (default: 0.2)\n\n    \"strategy_params\": {  # Fine-tune strategy behavior\n        \"gamma\": 0.25,    # TPE quantile threshold\n        \"n_startup\": 10   # Random samples before model-based optimization\n    }\n}\n</code></pre>"},{"location":"documentation/quickstart/#parameter-scales","title":"Parameter Scales","text":"<p>ArqonHPO supports different parameter scales for different use cases:</p> Linear (Default) <p><code>python     \"learning_rate\": {\"min\": 0.001, \"max\": 0.1}</code> Best for: Most parameters with uniform importance across the range.</p> Log Scale <p><code>python     \"learning_rate\": {\"min\": 0.0001, \"max\": 1.0, \"scale\": \"Log\"}</code> Best for: Parameters spanning multiple orders of magnitude (learning rates, regularization).</p> Periodic <p><code>python     \"angle\": {\"min\": 0.0, \"max\": 360.0, \"scale\": \"Periodic\"}</code> Best for: Angles, phases, or any parameter that wraps around.</p>"},{"location":"documentation/quickstart/#understanding-the-results","title":"Understanding the Results","text":""},{"location":"documentation/quickstart/#result-object-structure","title":"Result Object Structure","text":"<p>Each result you <code>tell()</code> the solver should have:</p> <pre><code>{\n    \"eval_id\": 0,           # Identifier within this batch\n    \"params\": {             # The parameters that were evaluated\n        \"x\": 1.5,\n        \"y\": -0.8\n    },\n    \"value\": 0.89,          # The objective function value (minimize this)\n    \"cost\": 1.0             # Relative cost (for budget tracking)\n}\n</code></pre>"},{"location":"documentation/quickstart/#cost-field","title":"Cost Field","text":"<p>The <code>cost</code> field tells ArqonHPO how \"expensive\" each evaluation was to run. Think of it as a unit of work or time spent.</p> <p>Why does this matter? ArqonHPO tracks your remaining budget by subtracting costs. When total cost reaches your <code>budget</code>, optimization stops. This lets you optimize for wall-clock time rather than just counting evaluations.</p> <ul> <li>If all your evaluations take roughly the same time \u2192 set <code>cost: 1.0</code> for everything</li> <li>If some configurations are faster or slower \u2192 scale the cost proportionally</li> </ul> <p>Example scenario: You're tuning a neural network. Small networks train in 10 seconds, large networks take 100 seconds.</p> <pre><code># Small network (fast) - costs less of your budget\nresults.append({\"params\": params, \"value\": loss, \"cost\": 0.1})\n\n# Large network (slow) - costs more of your budget\nresults.append({\"params\": params, \"value\": loss, \"cost\": 1.0})\n</code></pre> <p>This way, ArqonHPO understands that 10 small-network evaluations \u2248 1 large-network evaluation in terms of real time spent.</p> <p>Quick reference:</p> Situation What to use All evaluations take the same time <code>cost: 1.0</code> for all Evaluation took half the normal time <code>cost: 0.5</code> Evaluation took twice as long <code>cost: 2.0</code> You want to count evaluations, not time <code>cost: 1.0</code> for all <p>When in Doubt</p> <p>If you're not sure, just use <code>cost: 1.0</code> for everything. This makes the budget behave like a simple evaluation counter, which is fine for most use cases.</p>"},{"location":"documentation/quickstart/#online-real-time-optimization","title":"Online (Real-time) Optimization","text":"<p>For real-time control systems where you need single-point feedback:</p> <pre><code>from arqonhpo import ArqonSolver\nimport json\n\nconfig = {\n    \"seed\": 42,\n    \"budget\": 1000,\n    \"bounds\": {\"gain\": {\"min\": 0.1, \"max\": 10.0}}\n}\n\nsolver = ArqonSolver(json.dumps(config))\n\nfor step in range(100):\n    # Get ONE candidate at a time\n    candidate = solver.ask_one()\n    if candidate is None:\n        break\n\n    # Apply to real system\n    reward = apply_to_system(candidate)\n\n    # Immediate feedback via seed()\n    solver.seed(json.dumps([{\n        \"params\": candidate,\n        \"value\": -reward,  # Negate reward for minimization\n        \"cost\": 1.0\n    }]))\n</code></pre> <p>!!! info \"<code>ask_one()</code> vs <code>ask()</code>\" - <code>ask()</code> returns a batch of candidates for the PCR workflow - <code>ask_one()</code> returns exactly one candidate for incremental/online optimization</p>"},{"location":"documentation/quickstart/#direct-sampling-with-arqonprobe","title":"Direct Sampling with ArqonProbe","text":"<p>For advanced use cases like distributed computing or custom algorithms, use <code>ArqonProbe</code> for deterministic sampling:</p> <pre><code>from arqonhpo import ArqonProbe\nimport json\n\nconfig = {\n    \"seed\": 42,\n    \"budget\": 100,\n    \"bounds\": {\n        \"x\": {\"min\": -5.0, \"max\": 5.0},\n        \"y\": {\"min\": -5.0, \"max\": 5.0}\n    }\n}\n\nprobe = ArqonProbe(json.dumps(config), seed=42)\n\n# Sample at specific indices (deterministic, stateless)\nsample_0 = probe.sample_at(0)\nsample_1 = probe.sample_at(1)\nprint(f\"Sample 0: {sample_0}\")\nprint(f\"Sample 1: {sample_1}\")\n\n# Sample a range (for parallel evaluation)\nsamples = probe.sample_range(0, 10)  # Indices 0-9\nprint(f\"Got {len(samples)} samples\")\n</code></pre> <p>Why use ArqonProbe?</p> Use Case Benefit Distributed computing Each worker samples a specific index range Reproducibility Same index always produces same sample Zero coordination Workers don't need to communicate Fault tolerance Crashed workers can be restarted at same index"},{"location":"documentation/quickstart/#warm-starting-from-previous-runs","title":"Warm-Starting from Previous Runs","text":"<p>Resume optimization from a previous run using <code>seed()</code>:</p> <pre><code>import json\nfrom arqonhpo import ArqonSolver\n\n# Load previous results\nprevious_results = [\n    {\"params\": {\"x\": 1.5, \"y\": -0.5}, \"value\": 0.5, \"cost\": 1.0},\n    {\"params\": {\"x\": 2.1, \"y\": -1.2}, \"value\": 0.05, \"cost\": 1.0},\n    {\"params\": {\"x\": 1.9, \"y\": -0.9}, \"value\": 0.02, \"cost\": 1.0},\n]\n\nconfig = {\n    \"seed\": 42,\n    \"budget\": 100,\n    \"bounds\": {\"x\": {\"min\": -10.0, \"max\": 10.0}, \"y\": {\"min\": -10.0, \"max\": 10.0}}\n}\n\nsolver = ArqonSolver(json.dumps(config))\n\n# Seed with historical data\nsolver.seed(json.dumps(previous_results))\n\nprint(f\"Started with {solver.get_history_len()} historical evaluations\")\n\n# Continue optimizing...\nbatch = solver.ask()\n</code></pre>"},{"location":"documentation/quickstart/#common-patterns","title":"Common Patterns","text":""},{"location":"documentation/quickstart/#pattern-1-ml-hyperparameter-tuning","title":"Pattern 1: ML Hyperparameter Tuning","text":"<pre><code>from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom arqonhpo import ArqonSolver\nimport json\n\nX, y = load_your_data()\n\ndef objective(params):\n    clf = RandomForestClassifier(\n        n_estimators=int(params[\"n_estimators\"]),\n        max_depth=int(params[\"max_depth\"]),\n        min_samples_split=int(params[\"min_samples_split\"]),\n        random_state=42\n    )\n    score = cross_val_score(clf, X, y, cv=5).mean()\n    return -score  # Minimize negative accuracy\n\nconfig = {\n    \"seed\": 42,\n    \"budget\": 50,\n    \"probe_ratio\": 0.3,  # More exploration for noisy ML objectives\n    \"bounds\": {\n        \"n_estimators\": {\"min\": 10, \"max\": 300},\n        \"max_depth\": {\"min\": 2, \"max\": 30},\n        \"min_samples_split\": {\"min\": 2, \"max\": 20}\n    }\n}\n\n# ... standard optimization loop ...\n</code></pre>"},{"location":"documentation/quickstart/#pattern-2-simulation-tuning","title":"Pattern 2: Simulation Tuning","text":"<pre><code>def run_simulation(params):\n    \"\"\"Run expensive CFD/physics simulation.\"\"\"\n    result = simulator.run(\n        velocity=params[\"velocity\"],\n        angle=params[\"angle\"],\n        pressure=params[\"pressure\"]\n    )\n    return result.error  # Minimize error\n\nconfig = {\n    \"seed\": 42,\n    \"budget\": 100,\n    \"bounds\": {\n        \"velocity\": {\"min\": 0.1, \"max\": 10.0},\n        \"angle\": {\"min\": 0.0, \"max\": 90.0},\n        \"pressure\": {\"min\": 100.0, \"max\": 1000.0}\n    }\n}\n</code></pre>"},{"location":"documentation/quickstart/#pattern-3-neural-network-architecture-search","title":"Pattern 3: Neural Network Architecture Search","text":"<pre><code>def objective(params):\n    model = build_model(\n        hidden_size=int(params[\"hidden_size\"]),\n        num_layers=int(params[\"num_layers\"]),\n        dropout=params[\"dropout\"],\n        learning_rate=params[\"learning_rate\"]\n    )\n    val_loss = train_and_evaluate(model)\n    return val_loss\n\nconfig = {\n    \"seed\": 42,\n    \"budget\": 30,  # Lower budget for expensive training\n    \"bounds\": {\n        \"hidden_size\": {\"min\": 32, \"max\": 512},\n        \"num_layers\": {\"min\": 1, \"max\": 8},\n        \"dropout\": {\"min\": 0.0, \"max\": 0.5},\n        \"learning_rate\": {\"min\": 1e-5, \"max\": 1e-2, \"scale\": \"Log\"}\n    }\n}\n</code></pre>"},{"location":"documentation/quickstart/#debugging-tips","title":"Debugging Tips","text":""},{"location":"documentation/quickstart/#check-budget-usage","title":"Check Budget Usage","text":"<pre><code>print(f\"Evaluations used: {solver.get_history_len()}\")\n</code></pre>"},{"location":"documentation/quickstart/#verbose-objective-function","title":"Verbose Objective Function","text":"<pre><code>def objective(params):\n    print(f\"Evaluating: x={params['x']:.4f}, y={params['y']:.4f}\")\n    value = (params[\"x\"] - 2)**2 + (params[\"y\"] + 1)**2\n    print(f\"  \u2192 value={value:.6f}\")\n    return value\n</code></pre>"},{"location":"documentation/quickstart/#common-mistakes","title":"Common Mistakes","text":"Mistake Symptom Fix Forgetting to call <code>tell()</code> Solver stalls Always call <code>tell()</code> after evaluating Returning <code>None</code> from objective Crash Always return a number Wrong JSON format ValueError Use <code>json.dumps()</code> for config and results Bounds too tight Poor results Expand search space Bounds too wide Slow convergence Narrow based on domain knowledge"},{"location":"documentation/quickstart/#whats-next","title":"What's Next?","text":"<ul> <li> Python API Reference</li> </ul> <p>Complete documentation of all classes and methods</p> <ul> <li> Cookbook: ML Tuning</li> </ul> <p>Tune sklearn and PyTorch models</p> <ul> <li> Cookbook: Simulation Tuning</li> </ul> <p>Optimize expensive simulations</p> <ul> <li> Cookbook: Real-time Control</li> </ul> <p>Online optimization for control systems</p> <ul> <li> How PCR Works</li> </ul> <p>Deep dive into the Probe-Classify-Refine algorithm</p> <ul> <li> CLI Usage</li> </ul> <p>Use ArqonHPO from the command line</p> <p>Questions? Check the FAQ or open an issue.</p> <p>Found a bug? Report it and help us improve!</p>"},{"location":"documentation/troubleshooting/","title":"Troubleshooting","text":"<p>Common issues and how to fix them.</p>"},{"location":"documentation/troubleshooting/#installation-issues","title":"Installation Issues","text":""},{"location":"documentation/troubleshooting/#pip-install-arqonhpo-fails","title":"<code>pip install arqonhpo</code> fails","text":"<p>\"No matching distribution found\"</p> <pre><code>ERROR: Could not find a version that satisfies the requirement arqonhpo\n</code></pre> <p>Fix: Check Python version and platform:</p> <pre><code>python --version  # Need 3.10+\npython -c \"import platform; print(platform.machine())\"  # Need x86_64 or arm64\n</code></pre>"},{"location":"documentation/troubleshooting/#import-fails-with-symbol-error","title":"Import fails with symbol error","text":"<p>\"undefined symbol\" or \"symbol not found\"</p> <p>This happens when the wheel was built with a different Python version.</p> <p>Fix:</p> <pre><code>pip uninstall arqonhpo\npip install --no-cache-dir arqonhpo\n</code></pre> <p>Or use a virtual environment:</p> <pre><code>python -m venv .venv\nsource .venv/bin/activate\npip install arqonhpo\n</code></pre>"},{"location":"documentation/troubleshooting/#runtime-issues","title":"Runtime Issues","text":""},{"location":"documentation/troubleshooting/#invalid-config-error","title":"\"Invalid config\" error","text":"<pre><code>PyValueError: Invalid config: missing field `budget`\n</code></pre> <p>Fix: Ensure all required fields are present:</p> <pre><code>config = {\n    \"seed\": 42,       # Required\n    \"budget\": 100,    # Required\n    \"bounds\": {...}   # Required\n}\n</code></pre>"},{"location":"documentation/troubleshooting/#no-candidates-returned-from-ask","title":"No candidates returned from <code>ask()</code>","text":"<p>Problem: <code>solver.ask()</code> returns <code>None</code> immediately.</p> <p>Causes:</p> <ol> <li>Budget already exhausted</li> <li>Config has 0 budget</li> <li>State file corrupted</li> </ol> <p>Fix: Check budget and history:</p> <pre><code>print(f\"History: {solver.get_history_len()}\")\n# Ensure history_len &lt; budget\n</code></pre>"},{"location":"documentation/troubleshooting/#performance-is-slow","title":"Performance is slow","text":"<p>Problem: Each <code>ask()</code> takes &gt;100ms.</p> <p>Causes:</p> <ol> <li>Python object conversion overhead</li> <li>Large parameter space</li> <li>TPE with many history points</li> </ol> <p>Fix:</p> <ul> <li>Use batch mode: <code>solver.ask()</code> returns multiple candidates</li> <li>Reduce history size in config</li> <li>Use Nelder-Mead for smooth functions</li> </ul>"},{"location":"documentation/troubleshooting/#cli-issues","title":"CLI Issues","text":""},{"location":"documentation/troubleshooting/#command-not-found-arqonhpo","title":"\"command not found: arqonhpo\"","text":"<p>Fix: Install the CLI binary:</p> <pre><code>cargo install --path crates/cli --bin arqonhpo-cli\n</code></pre> <p>Or use the Python CLI:</p> <pre><code>python -m arqonhpo --help\n</code></pre>"},{"location":"documentation/troubleshooting/#tui-shows-blank-screen","title":"TUI shows blank screen","text":"<p>Problem: TUI starts but shows no data.</p> <p>Causes:</p> <ol> <li>State file doesn't exist or is empty</li> <li>State file has incompatible format</li> </ol> <p>Fix:</p> <pre><code># Check state file exists\nls -la state.json\n\n# Run an optimization first\narqonhpo ask --config config.json --state state.json\n</code></pre>"},{"location":"documentation/troubleshooting/#dashboard-api-returns-404","title":"Dashboard API returns 404","text":"<p>Problem: <code>curl http://localhost:3030/api/state</code> returns 404.</p> <p>Causes:</p> <ol> <li>Wrong URL (no /api prefix)</li> <li>Dashboard not running</li> </ol> <p>Fix:</p> <pre><code># Correct endpoints\ncurl http://localhost:3030/api/state\ncurl http://localhost:3030/api/summary\n\n# Verify dashboard is running\narqonhpo dashboard --state state.json --addr 127.0.0.1:3030\n</code></pre>"},{"location":"documentation/troubleshooting/#build-issues","title":"Build Issues","text":""},{"location":"documentation/troubleshooting/#protobuf-compiler-not-found","title":"Protobuf compiler not found","text":"<pre><code>error: failed to run custom build command for `arqonhpo-ffi`\n</code></pre> <p>Fix:</p> <pre><code># Ubuntu/Debian\nsudo apt install protobuf-compiler\n\n# macOS\nbrew install protobuf\n\n# Verify\nprotoc --version\n</code></pre>"},{"location":"documentation/troubleshooting/#rust-version-too-old","title":"Rust version too old","text":"<pre><code>error: package requires rustc 1.82.0 or newer\n</code></pre> <p>Fix:</p> <pre><code>rustup update stable\nrustc --version  # Should be 1.82+\n</code></pre>"},{"location":"documentation/troubleshooting/#still-stuck","title":"Still Stuck?","text":"<ol> <li>Check GitHub Issues</li> <li>Open a Discussion</li> <li>Review the Constitution for design rationale</li> </ol>"},{"location":"documentation/concepts/batch_vs_online/","title":"Batch vs Online Mode","text":"<p>ArqonHPO supports two primary modes of operation: Batch mode for offline experimentation with parallel evaluation, and Online mode for real-time, streaming optimization.</p>"},{"location":"documentation/concepts/batch_vs_online/#mode-comparison","title":"Mode Comparison","text":"Aspect Batch Mode Online Mode Method <code>ask()</code> / <code>tell()</code> <code>ask_one()</code> / <code>seed()</code> Candidates per call Multiple (batch) Single Algorithm Full PCR (Probe-Classify-Refine) Direct TPE (no probing) Best for Offline experiments, simulations Real-time control, streaming Parallelism Evaluate batch in parallel Sequential only"},{"location":"documentation/concepts/batch_vs_online/#batch-mode-pcr-workflow","title":"Batch Mode (PCR Workflow)","text":"<p>Batch mode uses the full Probe \u2192 Classify \u2192 Refine workflow. The solver requests multiple candidates at once, evaluates them (potentially in parallel), and reports all results together.</p>"},{"location":"documentation/concepts/batch_vs_online/#how-it-works","title":"How It Works","text":"<ol> <li><code>ask()</code> returns a batch of candidate configurations</li> <li>You evaluate all candidates (can parallelize this step)</li> <li><code>tell()</code> reports all results back to the solver</li> <li>Repeat until budget exhausted (returns <code>None</code>)</li> </ol>"},{"location":"documentation/concepts/batch_vs_online/#example","title":"Example","text":"<pre><code>from arqonhpo import ArqonSolver\nimport json\n\nconfig = {\n    \"seed\": 42,\n    \"budget\": 100,\n    \"bounds\": {\"x\": {\"min\": -5, \"max\": 5}, \"y\": {\"min\": -5, \"max\": 5}}\n}\n\nsolver = ArqonSolver(json.dumps(config))\nbest = {\"value\": float('inf'), \"params\": None}\n\nwhile True:\n    # Get a BATCH of candidates\n    batch = solver.ask()\n    if batch is None:\n        break\n\n    # Evaluate all candidates (can parallelize!)\n    results = []\n    for i, params in enumerate(batch):\n        value = objective(params)\n        if value &lt; best[\"value\"]:\n            best = {\"value\": value, \"params\": params}\n        results.append({\n            \"eval_id\": i,\n            \"params\": params,\n            \"value\": value,\n            \"cost\": 1.0\n        })\n\n    solver.tell(json.dumps(results))\n\nprint(f\"Best: {best}\")\n</code></pre>"},{"location":"documentation/concepts/batch_vs_online/#phase-breakdown","title":"Phase Breakdown","text":"<p>The batch mode budget is divided across three phases:</p> Phase Budget % What Happens Probe ~20% Low-discrepancy sampling to explore the landscape Classify 0% Analyze probe results; determine strategy (computation only) Refine ~80% Execute selected strategy (Nelder-Mead or TPE) <p>The probe phase returns larger batches (to cover the search space), while the refine phase may return smaller batches depending on the selected strategy.</p>"},{"location":"documentation/concepts/batch_vs_online/#when-to-use-batch-mode","title":"When To Use Batch Mode","text":"<ul> <li>\u2705 You can evaluate multiple candidates in parallel</li> <li>\u2705 Full budget is known upfront</li> <li>\u2705 Offline experiments (training runs, simulations)</li> <li>\u2705 You want automatic strategy selection via PCR</li> </ul>"},{"location":"documentation/concepts/batch_vs_online/#online-mode-real-time-workflow","title":"Online Mode (Real-time Workflow)","text":"<p>Online mode bypasses the PCR workflow entirely. Each call returns exactly one candidate, and feedback is incorporated immediately before the next candidate is generated.</p>"},{"location":"documentation/concepts/batch_vs_online/#how-it-works_1","title":"How It Works","text":"<ol> <li><code>ask_one()</code> returns a single candidate configuration</li> <li>You evaluate immediately</li> <li><code>seed()</code> reports the result back</li> <li>Repeat until budget exhausted (returns <code>None</code>)</li> </ol>"},{"location":"documentation/concepts/batch_vs_online/#example_1","title":"Example","text":"<pre><code>from arqonhpo import ArqonSolver\nimport json\n\nconfig = {\n    \"seed\": 42,\n    \"budget\": 100,\n    \"bounds\": {\"gain\": {\"min\": 0.1, \"max\": 10.0}}\n}\n\nsolver = ArqonSolver(json.dumps(config))\n\nwhile True:\n    # Get ONE candidate\n    candidate = solver.ask_one()\n    if candidate is None:\n        break\n\n    # Evaluate immediately\n    value = evaluate_in_production(candidate)\n\n    # Feed back immediately\n    solver.seed(json.dumps([{\n        \"params\": candidate,\n        \"value\": value,\n        \"cost\": 1.0\n    }]))\n</code></pre>"},{"location":"documentation/concepts/batch_vs_online/#key-differences-from-batch-mode","title":"Key Differences from Batch Mode","text":"Aspect Batch Mode Online Mode Probe phase Yes (20% of budget) Skipped Classification Automatic None (always TPE) Strategy NM or TPE based on classification TPE only Sample efficiency Higher (benefits from probing) Lower (no exploration phase) Latency to first result Higher (batch evaluation) Lower (immediate feedback)"},{"location":"documentation/concepts/batch_vs_online/#when-to-use-online-mode","title":"When To Use Online Mode","text":"<ul> <li>\u2705 Real-time control loops (adjusting parameters while system runs)</li> <li>\u2705 Single evaluations at a time (can't parallelize)</li> <li>\u2705 External evaluation systems (A/B testing, user feedback)</li> <li>\u2705 Streaming data sources</li> <li>\u2705 Continuous operation without defined budget</li> </ul>"},{"location":"documentation/concepts/batch_vs_online/#choosing-between-modes","title":"Choosing Between Modes","text":""},{"location":"documentation/concepts/batch_vs_online/#decision-tree","title":"Decision Tree","text":"<pre><code>graph TD\n    A[Start] --&gt; B{Can you parallelize&lt;br&gt;evaluations?}\n    B --&gt;|Yes| C{Known budget&lt;br&gt;upfront?}\n    B --&gt;|No| D{Real-time&lt;br&gt;constraint?}\n\n    C --&gt;|Yes| E[Use Batch Mode]\n    C --&gt;|No| F[Consider Batch Mode]\n\n    D --&gt;|Yes| G[Use Online Mode]\n    D --&gt;|No| H{Streaming&lt;br&gt;data?}\n\n    H --&gt;|Yes| G\n    H --&gt;|No| F\n\n    style E fill:#22c55e,color:#fff\n    style G fill:#6366f1,color:#fff</code></pre>"},{"location":"documentation/concepts/batch_vs_online/#practical-guidelines","title":"Practical Guidelines","text":"Scenario Recommended Mode Training ML models on a cluster Batch Tuning a live web server Online Hyperparameter search with Ray/Spark Batch Adjusting game AI parameters in real-time Online Simulation optimization Batch A/B testing with user feedback Online"},{"location":"documentation/concepts/batch_vs_online/#hybrid-approach","title":"Hybrid Approach","text":"<p>You can combine both modes. This is useful when you want the benefits of batch probing but need to switch to online refinement:</p> <pre><code>solver = ArqonSolver(json.dumps(config))\n\n# Phase 1: Batch probing for landscape exploration\nfor _ in range(3):\n    batch = solver.ask()\n    if batch:\n        results = parallel_evaluate(batch)\n        solver.tell(json.dumps(results))\n\n# Phase 2: Switch to online refinement\nwhile True:\n    candidate = solver.ask_one()\n    if candidate is None:\n        break\n    value = evaluate_single(candidate)\n    solver.seed(json.dumps([{\n        \"params\": candidate,\n        \"value\": value,\n        \"cost\": 1.0\n    }]))\n</code></pre> <p>This approach:</p> <ul> <li>Uses batch mode to efficiently explore the search space</li> <li>Switches to online mode for fine-grained, real-time refinement</li> <li>Maintains all history across both phases</li> </ul>"},{"location":"documentation/concepts/batch_vs_online/#api-reference","title":"API Reference","text":""},{"location":"documentation/concepts/batch_vs_online/#batch-mode-methods","title":"Batch Mode Methods","text":"Method Description <code>ask()</code> Returns <code>List[Dict]</code> of candidates, or <code>None</code> when budget exhausted <code>tell(results_json)</code> Reports evaluation results for all candidates in the batch <code>get_history_len()</code> Returns total number of evaluations completed"},{"location":"documentation/concepts/batch_vs_online/#online-mode-methods","title":"Online Mode Methods","text":"Method Description <code>ask_one()</code> Returns single <code>Dict</code> candidate, or <code>None</code> when budget exhausted <code>seed(results_json)</code> Reports evaluation result (works for single or multiple results)"},{"location":"documentation/concepts/batch_vs_online/#next-steps","title":"Next Steps","text":"<ul> <li> Quickstart</li> </ul> <p>Get running with batch or online mode</p> <ul> <li> Strategies</li> </ul> <p>Algorithm details for NM and TPE</p> <ul> <li> Metabolic Architecture</li> </ul> <p>Online mode for self-tuning systems</p>"},{"location":"documentation/concepts/determinism/","title":"Determinism &amp; Reproducibility","text":"<p>If you cannot replay history, you cannot debug the future.</p> <p>In stochastic optimization, \"randomness\" is often treated as a black box. But when an optimizer drives production infrastructure, \"it worked differently last time\" is an unacceptable root cause analysis.</p> <p>ArqonHPO guarantees bit-perfect deterministic execution. Given the same seed and configuration, it will produce the exact same sequence of parameter suggestions, decision boundaries, and internal state transitions\u2014forever, on any platform. This transforms optimization from a probabilistic gamble into a reproducible engineering process.</p>"},{"location":"documentation/concepts/determinism/#why-determinism-matters","title":"Why Determinism Matters","text":"<p>Deterministic optimization is not just about convenience; it is a hard requirement for safety-critical autonomy:</p> Use Case Requirement Debugging Reproduce exact failure conditions by replaying with the same seed Testing Verify optimizer behavior in CI pipelines Auditing Explain why a specific configuration was chosen Compliance Required in regulated industries (finance, medical, aerospace) Research Enable reproducible experiments and publications"},{"location":"documentation/concepts/determinism/#rng-implementation","title":"RNG Implementation","text":"<p>ArqonHPO uses ChaCha8Rng from the <code>rand_chacha</code> crate (verified from <code>rng.rs</code>):</p> <pre><code>// From crates/core/src/rng.rs\nuse rand_chacha::ChaCha8Rng;\nuse rand::SeedableRng;\n\npub fn get_rng(seed: u64) -&gt; ChaCha8Rng {\n    ChaCha8Rng::seed_from_u64(seed)\n}\n</code></pre> <p>ChaCha8 is a cryptographically secure, portable pseudorandom number generator that produces identical sequences across platforms when given the same seed.</p>"},{"location":"documentation/concepts/determinism/#seed-configuration","title":"Seed Configuration","text":"<pre><code>from arqonhpo import ArqonSolver\nimport json\n\n# Same seed = identical sequence\nconfig = {\n    \"seed\": 42,        # u64 seed\n    \"budget\": 100,\n    \"bounds\": {\"x\": {\"min\": -5, \"max\": 5}}\n}\n\nsolver = ArqonSolver(json.dumps(config))\n</code></pre> Field Type Range <code>seed</code> <code>u64</code> 0 to 2^64-1"},{"location":"documentation/concepts/determinism/#reproducibility-guarantees","title":"Reproducibility Guarantees","text":"<p>Given identical inputs, ArqonHPO produces identical outputs:</p> <pre><code># Two solvers with same config\nsolver1 = ArqonSolver(json.dumps(config))\nsolver2 = ArqonSolver(json.dumps(config))\n\nbatch1 = solver1.ask()\nbatch2 = solver2.ask()\n\nassert batch1 == batch2  # \u2713 Always true\n</code></pre>"},{"location":"documentation/concepts/determinism/#whats-deterministic","title":"What's Deterministic","text":"Component Deterministic Notes Probe phase \u2705 Yes LDS uses prime-sqrt-slopes rotation Classify phase \u2705 Yes Pure computation, no randomness Nelder-Mead \u2705 Yes Fully deterministic simplex operations TPE sampling \u2705 Yes Uses seeded ChaCha8Rng Cranley-Patterson shifts \u2705 Yes Derived from seed"},{"location":"documentation/concepts/determinism/#conditions-for-reproducibility","title":"Conditions for Reproducibility","text":"<p>For exact reproducibility, ensure:</p> <ol> <li>Same seed in config</li> <li>Same config (all bounds, budget, params identical)</li> <li>Same ArqonHPO version (algorithm changes may affect sequences)</li> <li>Same <code>tell()</code> order (results must arrive in same sequence)</li> </ol>"},{"location":"documentation/concepts/determinism/#what-can-break-reproducibility","title":"What Can Break Reproducibility","text":"Issue Cause Solution Different version Algorithm updates Pin version in requirements.txt Variable evaluation order Parallel evaluation returning in different order Sort results by eval_id before <code>tell()</code> Platform differences Floating-point implementation Use same platform (rare issue) Config ordering JSON key order Shouldn't matter, but use sorted keys"},{"location":"documentation/concepts/determinism/#arqonprobe-stateless-sampling","title":"ArqonProbe: Stateless Sampling","text":"<p><code>ArqonProbe</code> generates deterministic, stateless samples. Unlike the solver, it doesn't maintain state\u2014any index can be queried at any time with consistent results.</p> <pre><code>from arqonhpo import ArqonProbe\nimport json\n\nconfig = json.dumps({\n    \"bounds\": {\n        \"x\": {\"min\": 0, \"max\": 1},\n        \"y\": {\"min\": 0, \"max\": 1}\n    }\n})\n\nprobe = ArqonProbe(config, seed=42)\n\n# Stateless: any index returns the same point\npoint_0 = probe.sample_at(0)        # Always same\npoint_1000 = probe.sample_at(1000)  # Always same\n\n# Multiple calls at same index \u2192 identical result\nassert probe.sample_at(0) == probe.sample_at(0)  # \u2713\n</code></pre>"},{"location":"documentation/concepts/determinism/#zero-coordination-parallelism","title":"Zero-Coordination Parallelism","text":"<p>The stateless property enables embarrassingly parallel sampling without worker communication:</p> <pre><code>def worker(worker_id, probe, chunk_size=1000):\n    \"\"\"Each worker samples a disjoint range.\"\"\"\n    start = worker_id * chunk_size\n    return probe.sample_range(start, chunk_size)\n\n# Worker 0: indices 0-999\n# Worker 1: indices 1000-1999\n# Worker 2: indices 2000-2999\n# No coordination needed!\n</code></pre> <p>Each worker produces deterministic, non-overlapping points. Results can be combined in any order without affecting reproducibility.</p>"},{"location":"documentation/concepts/determinism/#testing-determinism","title":"Testing Determinism","text":"<p>Add this to your test suite to verify determinism:</p> <pre><code>def test_solver_determinism():\n    \"\"\"Verify that two solvers with same seed produce identical sequences.\"\"\"\n    config = json.dumps({\n        \"seed\": 12345,\n        \"budget\": 50,\n        \"bounds\": {\"x\": {\"min\": -5, \"max\": 5}}\n    })\n\n    solver1 = ArqonSolver(config)\n    solver2 = ArqonSolver(config)\n\n    for _ in range(10):\n        batch1 = solver1.ask()\n        batch2 = solver2.ask()\n\n        if batch1 is None and batch2 is None:\n            break\n\n        assert batch1 == batch2, \"Determinism violated!\"\n\n        # Feed identical results\n        results = json.dumps([{\n            \"eval_id\": i,\n            \"params\": p,\n            \"value\": sum(p.values()),\n            \"cost\": 1.0\n        } for i, p in enumerate(batch1)])\n\n        solver1.tell(results)\n        solver2.tell(results)\n</code></pre>"},{"location":"documentation/concepts/determinism/#next-steps","title":"Next Steps","text":"<ul> <li> Probe Deep Dive</li> </ul> <p>LDS implementation and mathematics</p> <ul> <li> Strategies</li> </ul> <p>How each algorithm maintains determinism</p> <ul> <li> Safety</li> </ul> <p>Audit trails for parameter changes</p>"},{"location":"documentation/concepts/metabolic_architecture/","title":"Metabolic Architecture","text":""},{"location":"documentation/concepts/metabolic_architecture/#when-optimization-becomes-continuous-software-becomes-alive","title":"When optimization becomes continuous, software becomes alive.","text":"<p>When ArqonHPO is applied to every feature knob in a system, the software begins to exhibit organism-like capabilities. It moves from being a static machine to a self-regulating entity with an internal \"metabolism\" for performance and reliability.</p> <p>This document explores the philosophy, mechanics, and practical implications of building systems with pervasive, continuous optimization.</p>"},{"location":"documentation/concepts/metabolic_architecture/#the-problem-with-static-configuration","title":"The Problem with Static Configuration","text":"<p>Traditional software is built with static constants:</p> <pre><code>TIMEOUT = 300\nBATCH_SIZE = 64\nCACHE_TTL = 3600\nRETRY_LIMIT = 3\n</code></pre> <p>These constants represent assumptions about traffic, hardware, and environment that are often wrong the moment the system deploys\u2014and become increasingly wrong as conditions change.</p>"},{"location":"documentation/concepts/metabolic_architecture/#the-drift-problem","title":"The Drift Problem","text":"<p>Every production system experiences drift:</p> Drift Type Example Impact Traffic drift Organic growth, viral events Timeouts become too short, batches too large Hardware drift New instance types, degraded disks Constants tuned for old hardware underperform Environment drift New dependencies, network topology Latency assumptions become invalid Workload drift Schema changes, query patterns Cached values become suboptimal <p>The traditional response? Wait for an alert, investigate, and manually retune. This reactive approach is slow, expensive, and error-prone.</p>"},{"location":"documentation/concepts/metabolic_architecture/#the-organism-metaphor","title":"The Organism Metaphor","text":"<p>A Metabolic Architecture replaces static assumptions with dynamic policies. By exposing every control knob to ArqonHPO, you give the system the ability to:</p> <pre><code>graph LR\n    subgraph \"The Living System\"\n        A[Tissue&lt;br/&gt;Features + Knobs] --&gt; B[Sensors&lt;br/&gt;Metrics + Telemetry]\n        B --&gt; C[Metabolism&lt;br/&gt;ArqonHPO Engine]\n        C --&gt; D[Governance&lt;br/&gt;Safety Executor]\n        D --&gt; A\n    end\n\n    E[Environment] -.-&gt; B\n    D -.-&gt;|Audit| F[Audit Log]</code></pre> Component Biological Analog ArqonHPO Component Tissue Cells performing functions Features with exposed control knobs Sensors Nervous system Telemetry digests (\u2264128 bytes) Metabolism Hormonal regulation Solver + PCR algorithm Governance Homeostatic reflexes SafetyExecutor + Guardrails"},{"location":"documentation/concepts/metabolic_architecture/#sense-synthesize-regulate","title":"Sense \u2192 Synthesize \u2192 Regulate","text":"<p>The metabolic loop operates continuously:</p> <ol> <li>Sense: Telemetry flows from the data plane to the control plane</li> <li>Synthesize: ArqonHPO finds the optimal operating point for current conditions</li> <li>Regulate: SafetyExecutor applies bounded adjustments to maintain stability</li> </ol> <p>This isn't optimization-as-a-task. This is optimization-as-a-capability.</p>"},{"location":"documentation/concepts/metabolic_architecture/#homeostasis-vs-traditional-optimization","title":"Homeostasis vs. Traditional Optimization","text":"<p>In a metabolic architecture, optimization isn't something you do\u2014it's something the system is.</p> Aspect Traditional Optimization Metabolic Architecture Frequency Monthly / Quarterly Every few seconds Trigger Performance regression, alert Continuous telemetry stream Decision maker Engineer with dashboard Autonomous control loop Logic Manual analysis + retuning PCR algorithm Speed Hours to days Milliseconds Result Static fix (until next drift) Dynamic resilience Failure mode Unnoticed degradation Bounded, recoverable adjustment"},{"location":"documentation/concepts/metabolic_architecture/#the-thermostat-analogy","title":"The Thermostat Analogy","text":"<p>Your home thermostat doesn't wait for you to notice it's cold. It continuously senses temperature and adjusts the heating system to maintain a setpoint. If external conditions change (door opens, weather shifts), it adapts automatically.</p> <p>A metabolic system works the same way, but for every tunable parameter.</p>"},{"location":"documentation/concepts/metabolic_architecture/#the-metabolic-feedback-loop","title":"The Metabolic Feedback Loop","text":""},{"location":"documentation/concepts/metabolic_architecture/#1-tissue-features","title":"1. Tissue (Features)","text":"<p>Your application features expose control knobs:</p> <pre><code>// Traditional: static constant\nconst BATCH_SIZE: usize = 64;\n\n// Metabolic: dynamic control knob\nfn get_batch_size() -&gt; usize {\n    CONFIG.read(\"batch_size\") as usize  // Controlled by ArqonHPO\n}\n</code></pre> <p>Exposable knobs include:</p> <ul> <li>Cache TTLs, sizes, eviction policies</li> <li>Batch sizes, queue depths</li> <li>Timeout durations, retry limits</li> <li>Thread pool sizes, connection limits</li> <li>Sampling rates, aggregation windows</li> <li>Feature flag thresholds</li> </ul>"},{"location":"documentation/concepts/metabolic_architecture/#2-sensors-metrics","title":"2. Sensors (Metrics)","text":"<p>Real-time telemetry feeds into the solver via <code>TelemetryDigest</code>:</p> <pre><code>// Constitution: II.19 - MUST be \u2264128 bytes\nstruct TelemetryDigest {\n    timestamp_us: u64,        // When this was measured\n    config_generation: u64,   // Which config produced this\n    objective_value: f64,     // The thing we're optimizing\n    // Optional auxiliary metrics...\n}\n</code></pre> <p>Key properties:</p> <ul> <li>Compact: \u2264128 bytes for cache-line efficiency</li> <li>Timestamped: Enables causality tracking</li> <li>Generational: Links telemetry to specific configurations</li> </ul>"},{"location":"documentation/concepts/metabolic_architecture/#3-metabolism-arqonhpo","title":"3. Metabolism (ArqonHPO)","text":"<p>The engine processes telemetry and synthesizes adjustments:</p> <ol> <li>Validate incoming telemetry (generation match, freshness)</li> <li>Collect valid digests into a window</li> <li>Evaluate objective from aggregated telemetry</li> <li>Propose parameter adjustments via active strategy (NM, TPE, SPSA)</li> </ol> <p>The PCR algorithm (Probe-Classify-Refine) adapts the strategy to the detected landscape:</p> <ul> <li>Structured landscapes (smooth, unimodal): Nelder-Mead for fast convergence</li> <li>Chaotic landscapes (noisy, multimodal): TPE for robust exploration</li> </ul>"},{"location":"documentation/concepts/metabolic_architecture/#4-governance-safety","title":"4. Governance (Safety)","text":"<p>The <code>SafetyExecutor</code> ensures the \"organism\" never enters a state of shock.</p> <p>The SafetyExecutor acts as a governance layer between the optimizer and your running system. While the optimizer proposes changes, the SafetyExecutor validates each proposal before allowing it to take effect.</p> <p>Before any parameter change is applied to your running system, the SafetyExecutor checks:</p> <ol> <li>Is this value allowed? \u2014 The proposed value must be within the defined min/max bounds</li> <li>Is the change too big? \u2014 Even if the final value is valid, jumping there in one step might be dangerous</li> <li>Are we changing too fast? \u2014 Rapid-fire updates can cause instability</li> <li>Are we currently in \"safe mode\"? \u2014 If something went wrong recently, all updates are frozen until things stabilize</li> </ol> <p>Only after passing all these checks does the change actually get applied. And every decision\u2014approved or rejected\u2014is logged so you can see exactly what happened and why.</p> <p>Why this matters: Without governance, an optimizer could theoretically decide that setting your timeout to 1 millisecond is \"optimal\" based on recent data. The SafetyExecutor prevents that kind of catastrophic misconfiguration.</p> <pre><code>// Every update passes through guardrails\nimpl SafeExecutor for SafetyExecutor {\n    fn apply(&amp;mut self, proposal: Proposal) -&gt; Result&lt;ApplyReceipt, Violation&gt; {\n        // 1. Bounds check\n        // 2. Delta check (max change per update)\n        // 3. Rate limit (max updates per second)\n        // 4. Control safety (not in SafeMode)\n        // 5. Apply to atomic config\n        // 6. Log to audit trail\n    }\n}\n</code></pre> <p>Guardrails prevent:</p> Risk Guardrail Mechanism Parameter explosion Bounds Clamp to valid range Wild oscillation Delta limits Cap change magnitude Feedback instability Rate limits Cap update frequency Cascading failure SafeMode Freeze all updates"},{"location":"documentation/concepts/metabolic_architecture/#control-safety-the-immune-system","title":"Control Safety: The Immune System","text":"<p>Beyond basic guardrails, ArqonHPO implements control safety\u2014an immune system that detects and responds to pathological behavior.</p>"},{"location":"documentation/concepts/metabolic_architecture/#thrashing-detection","title":"Thrashing Detection","text":"<p>Thrashing occurs when parameters oscillate rapidly without converging. The <code>ControlSafety</code> module tracks:</p> <ul> <li>Direction flips: How often a parameter changes direction</li> <li>Delta budget: Cumulative change within a time window</li> </ul> <pre><code>// If a parameter flips direction N times in T microseconds \u2192 SafeMode\nif direction_flips &gt;= guardrails.max_direction_flips {\n    self.enter_safe_mode(SafeModeReason::Thrashing, now_us, cooldown_us);\n}\n</code></pre>"},{"location":"documentation/concepts/metabolic_architecture/#regression-detection","title":"Regression Detection","text":"<p>If the objective consistently gets worse, the system enters SafeMode:</p> <pre><code>// N consecutive regressions \u2192 SafeMode\nif consecutive_regressions &gt;= rollback_policy.max_consecutive_regressions {\n    self.enter_safe_mode(SafeModeReason::ObjectiveRegression, now_us, cooldown_us);\n}\n</code></pre>"},{"location":"documentation/concepts/metabolic_architecture/#safemode","title":"SafeMode","text":"<p>When triggered, SafeMode freezes all updates until:</p> <ul> <li>A cooldown timer expires</li> <li>Manual reset by operator</li> <li>Objective recovery is detected</li> </ul> <p>This provides automatic protection against runaway feedback loops.</p>"},{"location":"documentation/concepts/metabolic_architecture/#building-a-metabolic-system","title":"Building a Metabolic System","text":""},{"location":"documentation/concepts/metabolic_architecture/#step-1-identify-control-knobs","title":"Step 1: Identify Control Knobs","text":"<p>Audit your system for tunable parameters:</p> <pre><code># Example: A web service with multiple knobs\nCONTROL_KNOBS = {\n    \"connection_pool_size\": {\"min\": 1, \"max\": 100},\n    \"request_timeout_ms\": {\"min\": 100, \"max\": 30000},\n    \"cache_ttl_seconds\": {\"min\": 1, \"max\": 3600},\n    \"batch_size\": {\"min\": 1, \"max\": 500},\n    \"retry_limit\": {\"min\": 0, \"max\": 10},\n}\n</code></pre>"},{"location":"documentation/concepts/metabolic_architecture/#step-2-define-the-objective","title":"Step 2: Define the Objective","text":"<p>What should the system optimize for?</p> <pre><code>def objective(telemetry: TelemetryDigest) -&gt; float:\n    # Example: Minimize latency while keeping error rate low\n    latency_score = telemetry.p99_latency_ms / 1000.0\n    error_penalty = telemetry.error_rate * 100.0\n    return latency_score + error_penalty\n</code></pre> <p>Common objectives:</p> Objective Formula Minimize latency <code>p99_latency</code> Maximize throughput <code>-requests_per_second</code> Balance latency + errors <code>latency + error_rate * k</code> Resource efficiency <code>cost_per_request</code>"},{"location":"documentation/concepts/metabolic_architecture/#step-3-connect-telemetry","title":"Step 3: Connect Telemetry","text":"<p>Stream real-time metrics to ArqonHPO:</p> <pre><code># Every N seconds, push telemetry\ndigest = TelemetryDigest(\n    timestamp_us=now_us(),\n    config_generation=current_generation,\n    objective_value=objective(current_metrics),\n)\nsolver.ingest_telemetry(digest)\n</code></pre>"},{"location":"documentation/concepts/metabolic_architecture/#step-4-apply-with-guardrails","title":"Step 4: Apply with Guardrails","text":"<p>Use SafetyExecutor to apply changes:</p> <pre><code>proposal = solver.propose()\nresult = executor.apply(proposal)\n\nif result.is_err():\n    log_violation(result.error())\nelse:\n    apply_to_system(result.new_config())\n</code></pre>"},{"location":"documentation/concepts/metabolic_architecture/#step-5-monitor-and-tune-guardrails","title":"Step 5: Monitor and Tune Guardrails","text":"<p>Start conservative, then relax as you gain confidence:</p> <pre><code># Phase 1: Ultra-conservative (first week)\nguardrails = Guardrails.preset_conservative()\n\n# Phase 2: Balanced (after stability proven)\nguardrails = Guardrails.preset_balanced()\n\n# Phase 3: Aggressive (offline benchmarks only)\nguardrails = Guardrails.preset_aggressive()\n</code></pre>"},{"location":"documentation/concepts/metabolic_architecture/#case-study-the-self-tuning-cache","title":"Case Study: The Self-Tuning Cache","text":"<p>Consider a cache with a fixed TTL of 300 seconds. This was optimal during initial testing but:</p> <ul> <li>During peak traffic, items expire too quickly \u2192 cache misses spike</li> <li>During quiet hours, stale data persists \u2192 freshness degrades</li> <li>When upstream latency increases, cache should retain longer</li> </ul> <p>Metabolic solution:</p> <pre><code># Expose TTL as a control knob\nconfig = {\n    \"bounds\": {\n        \"cache_ttl_seconds\": {\"min\": 30, \"max\": 900}\n    }\n}\n\n# Objective: minimize (miss_rate + staleness_penalty)\ndef objective(metrics):\n    miss_penalty = metrics.cache_miss_rate * 10.0\n    stale_penalty = metrics.stale_hit_rate * 5.0\n    return miss_penalty + stale_penalty\n</code></pre> <p>Result: TTL automatically increases during peak traffic (more caching) and decreases during quiet periods (fresher data).</p>"},{"location":"documentation/concepts/metabolic_architecture/#why-build-this-way","title":"Why Build This Way?","text":""},{"location":"documentation/concepts/metabolic_architecture/#1-solve-the-drift-problem","title":"1. Solve the Drift Problem","text":"<p>Systems naturally degrade as conditions change. A metabolic architecture doesn't just survive drift\u2014it consumes it, adapting its internal state to remain optimal without human intervention.</p>"},{"location":"documentation/concepts/metabolic_architecture/#2-reduce-operational-burden","title":"2. Reduce Operational Burden","text":"<p>Instead of responding to alerts and manually retuning, operators define objectives and guardrails once. The system handles the rest.</p>"},{"location":"documentation/concepts/metabolic_architecture/#3-enable-continuous-improvement","title":"3. Enable Continuous Improvement","text":"<p>Every second of operation generates data that improves the model. The system gets better over time, not worse.</p>"},{"location":"documentation/concepts/metabolic_architecture/#4-build-in-resilience","title":"4. Build in Resilience","text":"<p>With SafeMode, rollback policies, and bounded updates, metabolic systems fail gracefully. A bad configuration doesn't crash the system\u2014it triggers automatic recovery.</p>"},{"location":"documentation/concepts/metabolic_architecture/#anti-patterns-to-avoid","title":"Anti-Patterns to Avoid","text":"Anti-Pattern Why It's Bad Alternative Unbounded knobs Can cause system failure Always define min/max bounds No delta limits Wild oscillations Limit change per update Ignoring telemetry lag Optimizing stale data Use config generation for causality Too many knobs at once Exploration explosion Start with 2-3 critical knobs No SafeMode Runaway feedback loops Always enable control safety Aggressive guardrails in production System instability Start conservative"},{"location":"documentation/concepts/metabolic_architecture/#the-vision-software-as-organism","title":"The Vision: Software as Organism","text":"<p>The ultimate metabolic system doesn't just tune parameters\u2014it:</p> <ul> <li>Perceives its environment through rich telemetry</li> <li>Learns optimal operating points for each regime</li> <li>Adapts seamlessly as conditions change</li> <li>Heals when things go wrong</li> <li>Evolves over time as it accumulates experience</li> </ul> <p>This is the future of infrastructure: not static machines that humans tune, but living systems that tune themselves.</p>"},{"location":"documentation/concepts/metabolic_architecture/#next-steps","title":"Next Steps","text":"<ul> <li> Safety &amp; Guardrails</li> </ul> <p>Deep dive into SafetyExecutor, violations, and rollback policies</p> <ul> <li> PCR Algorithm</li> </ul> <p>How ArqonHPO adapts strategy to your problem</p> <ul> <li> Strategies</li> </ul> <p>Nelder-Mead, TPE, and SPSA explained</p> <ul> <li> Batch vs. Online</li> </ul> <p>Choosing the right optimization mode</p>   _\"The measure of intelligence is the ability to change.\"_ \u2014 Albert Einstein"},{"location":"documentation/concepts/pcr_algorithm/","title":"PCR (Probe-Classify-Refine) Algorithm","text":""},{"location":"documentation/concepts/pcr_algorithm/#the-core-of-arqonhpo-automatic-algorithm-selection-based-on-your-problems-structure","title":"The core of ArqonHPO: automatic algorithm selection based on your problem's structure.","text":"<p>The PCR Algorithm is ArqonHPO's core innovation (v2.0) that automatically selects the optimal optimization strategy based on the landscape's structure. It solves the \"Algorithm Selection Problem\" by treating it as a classification task rather than a trial-and-error process.</p> <p>Instead of requiring you to choose between different optimization algorithms (which requires expertise), PCR analyzes your problem, determines what kind of landscape it presents, and selects the best algorithm automatically.</p>"},{"location":"documentation/concepts/pcr_algorithm/#the-three-phases","title":"The Three Phases","text":"<pre><code>graph LR\n    A[\ud83d\udccd Probe] --&gt; B[\ud83d\udd2c Classify]\n    B --&gt; C[\ud83c\udfaf Refine]\n    C --&gt; D[\u2705 Done]\n\n    style A fill:#6366f1,color:#fff\n    style B fill:#8b5cf6,color:#fff\n    style C fill:#a855f7,color:#fff\n    style D fill:#22c55e,color:#fff</code></pre> Phase What Happens Budget Used Probe Sample the landscape systematically ~20% Classify Analyze samples to determine landscape type 0% (computation only) Refine Run the best algorithm for your problem ~80%"},{"location":"documentation/concepts/pcr_algorithm/#phase-1-probe-prime-index-sampling","title":"Phase 1: Probe (Prime-Index Sampling)","text":"<p>The algorithm begins by sampling the landscape using a deterministic Prime-Index Probe.</p>"},{"location":"documentation/concepts/pcr_algorithm/#what-it-does","title":"What It Does","text":"<p>Instead of random sampling, the probe uses prime number ratios to generate a low-discrepancy sequence. This mathematical technique ensures samples are spread evenly across the search space, covering multiple scales simultaneously.</p> <p>Random sampling can cluster points together by chance. Low-discrepancy sampling guarantees uniform coverage, avoiding wasted evaluations on redundant areas.</p>"},{"location":"documentation/concepts/pcr_algorithm/#why-prime-numbers","title":"Why Prime Numbers?","text":"<p>Prime numbers have a special property: their ratios are irrational and \"maximally non-repeating.\" This creates sampling patterns that:</p> <ul> <li>Cover the space more uniformly than random sampling</li> <li>Avoid grid-like artifacts that could miss important regions</li> <li>Are fully deterministic and reproducible</li> </ul>"},{"location":"documentation/concepts/pcr_algorithm/#configuration","title":"Configuration","text":"<pre><code>config = {\n    \"budget\": 100,\n    \"probe_ratio\": 0.2,  # 20% of budget for probing (default)\n    # ...\n}\n</code></pre> <ul> <li>Goal: Gather enough data to estimate the landscape's \"roughness\"</li> <li>Method: Evaluate <code>N</code> points (configurable, default 20% of budget)</li> <li>Result: A collection of (parameters \u2192 objective value) samples</li> </ul>"},{"location":"documentation/concepts/pcr_algorithm/#phase-2-classify-residual-decay-analysis","title":"Phase 2: Classify (Residual Decay Analysis)","text":"<p>After probing, the algorithm analyzes the collected data to determine the landscape type.</p>"},{"location":"documentation/concepts/pcr_algorithm/#the-core-question","title":"The Core Question","text":"<p>\"Does this problem have exploitable structure, or is it essentially noisy and chaotic?\"</p>"},{"location":"documentation/concepts/pcr_algorithm/#how-it-works-residual-decay","title":"How It Works: Residual Decay","text":"<p>The ResidualDecayClassifier looks at how the best-so-far value improves as more samples are collected. Specifically, it measures the decay rate (\u03b1) of the residuals.</p> <p>What are residuals? The differences between consecutive objective values when sorted from best to worst.</p> <p>The key insight:</p> <ul> <li>Structured functions (smooth, bowl-shaped): Values near the optimum are densely packed. Residuals decay geometrically\u2014each step gets you proportionally closer.</li> <li>Chaotic functions (noisy, multimodal): Values are scattered unpredictably. Residuals don't follow a consistent pattern.</li> </ul>"},{"location":"documentation/concepts/pcr_algorithm/#the-math-simplified","title":"The Math (Simplified)","text":"<p>Given residuals E\u2081, E\u2082, E\u2083, ..., we fit an exponential decay curve:</p> <pre><code>E_k \u2248 C \u00d7 \u03b2^k\n</code></pre> <p>Where:</p> <ul> <li><code>\u03b2</code> is the decay factor (0 &lt; \u03b2 &lt; 1 for decay)</li> <li><code>\u03b1 = -ln(\u03b2)</code> is the decay rate</li> </ul>"},{"location":"documentation/concepts/pcr_algorithm/#classification-rules","title":"Classification Rules","text":"<p>The classifier uses a threshold of \u03b1 = 0.5 (configurable). This threshold was chosen empirically based on testing across commonly used optimization benchmark functions.</p> Decay Rate (\u03b1) Residual Pattern Classification What It Means \u03b1 &gt; 0.5 Geometric decay Structured Residuals decrease quickly\u2014there's an exploitable gradient-like pattern \u03b1 \u2264 0.5 Flat or irregular Chaotic Residuals don't decay consistently\u2014the landscape is noisy or multimodal"},{"location":"documentation/concepts/pcr_algorithm/#what-you-see","title":"What You See","text":"<p>When running ArqonHPO, you'll see output like:</p> <pre><code>[Machine] Classified as Structured (Score: 1.0172)\n</code></pre> <p>The score is the estimated \u03b1 value. Higher scores mean more structure.</p>"},{"location":"documentation/concepts/pcr_algorithm/#phase-3-refine-strategy-selection","title":"Phase 3: Refine (Strategy Selection)","text":"<p>Based on the classification, the solver switches to the optimal refinement strategy:</p> Classification Strategy Selected Why This Works Structured Nelder-Mead A derivative-free simplex method that exploits smooth, bowl-shaped landscapes for efficient convergence Chaotic TPE (Tree-structured Parzen Estimator) A probabilistic model-based method that handles noise and multiple local optima by modeling \"good\" vs \"bad\" regions"},{"location":"documentation/concepts/pcr_algorithm/#warm-starting-top-k-seeding","title":"Warm-Starting (Top-K Seeding)","text":"<p>The refinement phase doesn't start from scratch. It's warm-started using the best points found during the Probe phase:</p> <ul> <li>Nelder-Mead: Initial simplex is constructed around the best probe points</li> <li>TPE: All probe history is used to build the initial density kernel</li> </ul> <p>Why this matters: You don't waste the 20% of budget spent on probing. Those samples inform the refinement strategy, giving it a head start.</p>"},{"location":"documentation/concepts/pcr_algorithm/#fail-safe-mechanisms","title":"Fail-Safe Mechanisms","text":"<p>Sometimes the classifier's initial assessment is wrong, or the landscape changes character in different regions. ArqonHPO includes fail-safes:</p> <pre><code>[Machine] Structured Fail-Safe Triggered! Restarting with CP Shift at param count 36\n</code></pre> <p>What this means: If Nelder-Mead (structured strategy) isn't making progress, the solver can restart with a shifted center point or switch strategies.</p>"},{"location":"documentation/concepts/pcr_algorithm/#why-pcr-matters","title":"Why PCR Matters","text":""},{"location":"documentation/concepts/pcr_algorithm/#the-algorithm-selection-problem","title":"The Algorithm Selection Problem","text":"<p>Traditional HPO requires you to choose:</p> <ul> <li>Random Search? (simple but inefficient)</li> <li>Bayesian Optimization? (good for noisy, expensive)</li> <li>Nelder-Mead? (fast for smooth functions)</li> <li>CMA-ES? (good for high dimensions)</li> </ul> <p>The problem: Choosing the wrong algorithm can result in significantly more evaluations than necessary, or worse, failure to converge at all.</p>"},{"location":"documentation/concepts/pcr_algorithm/#pcrs-approach","title":"PCR's Approach","text":"<p>PCR invests a portion of the budget (default 20%) to measure your problem's characteristics, then makes an informed strategy selection. The key advantages:</p> <ul> <li>Automatic adaptation: No manual algorithm selection required</li> <li>Warm-started refinement: Probe samples seed the refinement strategy, so the probing budget isn't wasted</li> <li>Fail-safe mechanisms: If the initial classification appears incorrect, the solver can adapt</li> </ul>"},{"location":"documentation/concepts/pcr_algorithm/#example-walkthrough","title":"Example Walkthrough","text":"<p>Let's trace through what happens when you run a simple optimization:</p> <pre><code>config = {\n    \"seed\": 42,\n    \"budget\": 50,\n    \"bounds\": {\"x\": {\"min\": -10, \"max\": 10}, \"y\": {\"min\": -10, \"max\": 10}}\n}\n</code></pre>"},{"location":"documentation/concepts/pcr_algorithm/#step-1-probe-phase","title":"Step 1: Probe Phase","text":"<p>With <code>probe_ratio=0.2</code> and <code>budget=50</code>, the solver allocates 10 evaluations for probing.</p> <ul> <li>Samples 10 points using Prime-Index probe</li> <li>Evaluates your objective function at each point</li> <li>Collects results: <code>[(x\u2081, y\u2081) \u2192 5.2, (x\u2082, y\u2082) \u2192 3.1, ...]</code></li> </ul>"},{"location":"documentation/concepts/pcr_algorithm/#step-2-classify-phase","title":"Step 2: Classify Phase","text":"<p>Analyzes the 10 samples:</p> <ul> <li>Sorts objective values: <code>[0.8, 1.2, 2.1, 3.1, ...]</code></li> <li>Computes residuals: <code>[0.4, 0.9, 1.0, ...]</code></li> <li>Fits exponential decay, estimates \u03b1 = 1.02</li> <li>Classification: Structured (\u03b1 &gt; 0.5)</li> </ul> <p>Output: <code>[Machine] Classified as Structured (Score: 1.0172)</code></p>"},{"location":"documentation/concepts/pcr_algorithm/#step-3-refine-phase","title":"Step 3: Refine Phase","text":"<p>Switches to Nelder-Mead:</p> <ul> <li>Initializes simplex around best probe points</li> <li>Runs Nelder-Mead with remaining 40 evaluations</li> <li>Converges toward optimum</li> </ul>"},{"location":"documentation/concepts/pcr_algorithm/#when-pcr-works-best","title":"When PCR Works Best","text":"<p>\u2705 Ideal for:</p> <ul> <li>Unknown problems where you don't know the landscape character</li> <li>Mix of smooth and noisy problems in a pipeline</li> <li>Budget-constrained optimization (can't afford trial-and-error)</li> <li>Automated systems where human expertise isn't available</li> </ul> <p>\u26a0\ufe0f Consider alternatives when:</p> <ul> <li>You know your problem is noisy (just use TPE directly via <code>ask_one()</code>)</li> <li>Very small budgets (&lt; 20 evaluations) where probe overhead is too high</li> <li>Real-time control where batch-style probing isn't appropriate</li> </ul>"},{"location":"documentation/concepts/pcr_algorithm/#tuning-pcr","title":"Tuning PCR","text":""},{"location":"documentation/concepts/pcr_algorithm/#probe-ratio","title":"Probe Ratio","text":"<pre><code>config = {\n    \"probe_ratio\": 0.3,  # More probing for uncertain landscapes\n    # ...\n}\n</code></pre> Probe Ratio Trade-off 0.1 Less exploration, faster to refinement, risk of misclassification 0.2 (default) Balanced 0.3-0.4 More confident classification, less budget for refinement"},{"location":"documentation/concepts/pcr_algorithm/#bypassing-pcr","title":"Bypassing PCR","text":"<p>For real-time/online optimization, use <code>ask_one()</code> which skips PCR entirely and uses TPE directly:</p> <pre><code>candidate = solver.ask_one()  # No probe/classify, direct TPE\n</code></pre>"},{"location":"documentation/concepts/pcr_algorithm/#summary","title":"Summary","text":"Aspect Description What Automatic algorithm selection based on measured landscape properties Why Eliminates guesswork, adapts to your specific problem How 20% budget on probing \u2192 classify via residual decay \u2192 80% budget on optimal strategy Result Near-optimal performance on both structured AND chaotic problems"},{"location":"documentation/concepts/pcr_algorithm/#next-steps","title":"Next Steps","text":"<ul> <li> Probe Deep Dive</li> </ul> <p>Low-discrepancy sampling and prime-index mathematics</p> <ul> <li> Strategies</li> </ul> <p>Detailed breakdown of Nelder-Mead and TPE</p> <ul> <li> Batch vs. Online</li> </ul> <p>When to use PCR vs. <code>ask_one()</code></p> <ul> <li> Safety</li> </ul> <p>How guardrails protect the refinement phase</p>"},{"location":"documentation/concepts/probe_deep_dive/","title":"Deep Dive: The Kronecker-Weyl Probe","text":"<p>The Kronecker-Weyl Probe uses a mathematically rigorous Low-Discrepancy Sequence to sample the search space.</p> <p>This section explains the mathematics behind how ArqonHPO samples the search space to maximize information gain while avoiding the pitfalls of random sampling and rigid grids.</p>"},{"location":"documentation/concepts/probe_deep_dive/#the-problem","title":"The Problem","text":"<ol> <li> <p>Random Sampling (Monte Carlo):</p> <ul> <li>Issue: It \"clumps\". You often get points very close to each other (wasted effort) and large empty voids (missed information).</li> <li>Result: Inefficient coverage of the landscape.</li> </ul> </li> <li> <p>Grid Sampling:</p> <ul> <li>Issue: It suffers from the \"Curse of Dimensionality\". The number of points needed grows exponentially (<code>10^d</code>).</li> <li>Issue: It aliases. If the underlying function has a period that matches the grid, you miss the structure entirely.</li> </ul> </li> <li> <p>Legacy p/1000 Heuristic (DEPRECATED):</p> <ul> <li>Issue: <code>primes[i] / 1000</code> produces collisions and striping artifacts.</li> <li>Result: Wasted budget on duplicate regions.</li> </ul> </li> </ol>"},{"location":"documentation/concepts/probe_deep_dive/#the-solution-kronecker-sequence-with-prime-square-root-slopes","title":"The Solution: Kronecker Sequence with Prime Square Root Slopes","text":"<p>ArqonHPO v2 uses the PrimeSqrtSlopesRotProbe\u2014a Kronecker/Weyl sequence with irrational slopes derived from prime square roots.</p>"},{"location":"documentation/concepts/probe_deep_dive/#the-math","title":"The Math","text":"<p>For the <code>i</code>-th sample in dimension <code>d</code>:</p> <pre><code>sample[i][d] = fract( i \u00d7 \u221aprime[d] + shift[d] )\n</code></pre> <p>Where:</p> <ul> <li><code>\u221aprime[d]</code>: The square root of the <code>d</code>-th prime (2, 3, 5, 7, 11...). Irrational slopes prevent collisions.</li> <li><code>shift[d]</code>: Optional Cranley-Patterson shift for QMC randomization.</li> <li><code>fract(x)</code>: The fractional part of <code>x</code> (wraps to [0, 1)).</li> </ul>"},{"location":"documentation/concepts/probe_deep_dive/#key-properties","title":"Key Properties","text":"Property Description Anytime Quality of first K samples does NOT depend on total N Collision-Free \u221aprime slopes are mutually irrational\u2014no aliasing Deterministic Same (seed, index) always produces same point Shardable Stateless: workers can generate disjoint ranges independently"},{"location":"documentation/concepts/probe_deep_dive/#robustness-hedge","title":"Robustness Hedge","text":"<p>A configurable <code>random_spice_ratio</code> (default 10%) of uniform random points hedges against multimodal fragility.</p>"},{"location":"documentation/concepts/probe_deep_dive/#periodic-dimension-support","title":"Periodic Dimension Support","text":"<p>For dimensions marked as <code>Scale::Periodic</code> (angles, phases), the probe uses toroidal topology:</p> <ul> <li><code>wrap01(x)</code>: Wrap to [0, 1)</li> <li><code>diff01(a, b)</code>: Shortest signed distance in circular space</li> <li><code>circular_mean01(values)</code>: Mean via sin/cos averaging</li> </ul>"},{"location":"documentation/concepts/probe_deep_dive/#visual-proof","title":"Visual Proof","text":"<p>The Kronecker sequence creates a Low-Discrepancy Lattice. It looks random (no obvious repeating pattern) but fills space uniformly.</p> <p></p> <p>Comparison of Kronecker Probe (Blue) vs Uniform Random (Red). Note how Blue covers uniformly without clumping or gaps.</p>"},{"location":"documentation/concepts/probe_deep_dive/#why-it-matters","title":"Why It Matters","text":"<p>High-quality probe data is critical for the Classifier phase:</p> <ul> <li>Uniform coverage avoids misclassifying structured landscapes as chaotic.</li> <li>Anytime property allows early stopping without quality degradation.</li> <li>Sharding enables parallel probing on expensive objectives.</li> </ul>"},{"location":"documentation/concepts/probe_deep_dive/#constitution-reference","title":"Constitution Reference","text":"<p>Per Constitution v1.1.0 Section II.12:</p> <ul> <li>Kronecker/Weyl sequences are REQUIRED.</li> <li>The legacy <code>p/1000</code> heuristic is BANNED.</li> <li>Cranley-Patterson shifts are the approved randomization mechanism.</li> </ul>"},{"location":"documentation/concepts/safety/","title":"Safety &amp; Guardrails","text":"<p>Optimization without governance is an incident waiting to happen.</p> <p>In a traditional \"Human-in-the-Loop\" workflow, safety is implicit: an engineer looks at a graph, thinks \"that looks risky,\" and decides not to deploy the change. When you move to an autonomous optimization loop, that implicit judgment must be made explicit, rigorous, and deterministic.</p> <p>ArqonHPO's Safety Layer is not just a feature; it is the deterministic firewall that stands between the stochastic, potentially chaotic world of optimization algorithms and the stable, revenue-critical world of your production system. It enforces strict governance on every single parameter update, ensuring that autonomy never becomes anarchy.</p>"},{"location":"documentation/concepts/safety/#why-safety-matters","title":"Why Safety Matters","text":"<p>Allowing an algorithm to tune production parameters without constraints is inherently risky. Feedback loops can become unstable, and \"optimal\" mathematical solutions might be operationally disastrous.</p> <p>Optimization without guardrails inevitably leads to one of these failure modes:</p> Risk Operational Impact Config oscillation Parameters swing wildly (e.g., cache TTLs jumping from 1s to 1h), invalidating internal state and destabilizing downstream dependencies. Catastrophic settings The optimizer explores a \"valid\" but dangerous configuration (e.g., extremely high timeout) that causes resource exhaustion or deadlocks. Audit gaps When a system crashes, you have no record of what changed, when it changed, or why the optimizer thought it was a good idea. Feedback loops The system reacts to a change, the metrics shift, and the optimizer reacts again\u2014creating a positive feedback loop that drives parameters to extremes. <p>ArqonHPO avoids these pitfalls by treating safety as a first-class concern, with multiple layers of protection that operate independently of the optimization strategy.</p>"},{"location":"documentation/concepts/safety/#the-safety-executor","title":"The Safety Executor","text":"<p>The <code>SafetyExecutor</code> is the heart of ArqonHPO's governance model. It sits architecturally between the optimizer and your application, acting as the sole actuator allowed to modify production configuration.</p> <p>Think of it as a relentless bureaucrat: it doesn't care about \"better\" objective values; it only cares about whether a proposed change is legal according to the constitution of your guardrails.</p> <pre><code>graph LR\n    A[Optimizer Proposal] --&gt; B[SafetyExecutor]\n    B --&gt; C{Guardrails Check}\n    C --&gt;|Pass| D[Apply to Config]\n    C --&gt;|Fail| E[Violation Logged]\n    D --&gt; F[Audit Trail]\n    E --&gt; F</code></pre> <p>The SafetyExecutor enforces the following invariants (verified from <code>executor.rs</code>):</p> <ol> <li>Bounds check: \"Is this value physically possible and safe?\" (e.g., no negative timeouts).</li> <li>Delta check: \"Is this change too abrupt?\" We force smooth transitions to prevent shock.</li> <li>Rate limit: \"Are we changing things too often?\" We prevent high-frequency jitter.</li> <li>Control safety: \"Is the system stable?\" We block updates if the system is currently thrashing or regressing.</li> </ol>"},{"location":"documentation/concepts/safety/#guardrails-configuration","title":"Guardrails Configuration","text":"<p>Guardrails define the \"physics\" of your tunable parameters\u2014the hard constraints that the optimizer must never violate.</p>"},{"location":"documentation/concepts/safety/#default-guardrails","title":"Default Guardrails","text":"<p>The default values are designed to be safe for most web services and high-throughput systems.</p> <pre><code>// From crates/hotpath/src/executor.rs\nGuardrails {\n    max_delta_per_step: 0.1,           // Max 10% change per step\n    max_updates_per_second: 10.0,      // Max 10 updates per second\n    min_interval_us: 100_000,          // Min 100ms between updates\n    direction_flip_limit: 3,           // Max 3 direction reversals before thrashing detected\n    cooldown_after_flip_us: 30_000_000, // 30s cooldown after thrashing\n    max_cumulative_delta_per_minute: 0.5, // Max 50% total change per minute\n    regression_count_limit: 5,         // Max 5 regressions before Safe Mode\n    bounds: None,\n}\n</code></pre>"},{"location":"documentation/concepts/safety/#understanding-the-constraints","title":"Understanding the Constraints","text":"Field Default Operational Theory <code>max_delta_per_step</code> 0.1 Dampening. Prevents shock to the system. Even if the optimizer wants to double a value, we force it to walk there in 10% increments. <code>max_updates_per_second</code> 10.0 Stability. Prevents the \"machine gun\" effect where the optimizer fires hundreds of updates per second, causing cache churn. <code>min_interval_us</code> 100,000 Settling Time. Ensures the system has at least a momentary chance to react to a change before the next one arrives. <code>direction_flip_limit</code> 3 Anti-Thrashing. If we toggle a value Up-Down-Up-Down, we are just adding noise. This catches \"indecisive\" optimization early. <code>max_cumulative_delta_per_minute</code> 0.5 Velocity Limit. Even with small steps, a runaway process could move a value too far, too fast. This caps the aggregate rate of change. <code>regression_count_limit</code> 5 Circuit Breaker. If we make 5 changes in a row and the metric gets worse every time, we stop immediately."},{"location":"documentation/concepts/safety/#safety-presets","title":"Safety Presets","text":"<p>Different lifecycle stages require different safety profiles. ArqonHPO provides three verified presets:</p>"},{"location":"documentation/concepts/safety/#conservative-preset","title":"Conservative Preset","text":"<p>Use for: Production systems, critical infrastructure, financial services.</p> <p>This preset prioritizes stability above all else. It forces the optimizer to move slowly and patiently.</p> <pre><code>Guardrails::preset_conservative() = {\n    max_delta_per_step: 0.05,          // 5% steps\n    max_updates_per_second: 2.0,       // 2Hz limit\n    min_interval_us: 500_000,          // 500ms settling time\n    direction_flip_limit: 2,           // Very sensitive to thrashing\n    cooldown_after_flip_us: 60_000_000, // Long 60s cooldown\n    max_cumulative_delta_per_minute: 0.25,\n    regression_count_limit: 3,         // Quick to trigger Safe Mode on failure\n}\n</code></pre>"},{"location":"documentation/concepts/safety/#balanced-preset-default","title":"Balanced Preset (Default)","text":"<p>Use for: Staging environments, standard web services, \"warm-up\" phases.</p> <p>A good middle ground that allows for reasonable exploration speed while still preventing catastrophic divergence.</p> <pre><code>Guardrails::default()  // Same as balanced\n</code></pre>"},{"location":"documentation/concepts/safety/#aggressive-preset","title":"Aggressive Preset","text":"<p>Use for: Offline simulations, training runs, initial discovery in non-prod.</p> <p>This unleashes the optimizer to explore the space rapidly. Do not use this in production unless you have external safeguards.</p> <pre><code>Guardrails::preset_aggressive() = {\n    max_delta_per_step: 0.2,           // 20% steps\n    max_updates_per_second: 20.0,      // 20Hz limit\n    min_interval_us: 50_000,           // 50ms settling time\n    direction_flip_limit: 5,           // Tolerates more noise\n    cooldown_after_flip_us: 10_000_000, // Quick 10s recovery\n    max_cumulative_delta_per_minute: 1.0,\n    regression_count_limit: 8,\n}\n</code></pre>"},{"location":"documentation/concepts/safety/#rollback-policy","title":"Rollback Policy","text":"<p>The ability to undo is the ultimate safety feature. The Rollback Policy defines the automatic \"eject button\" logic.</p> <pre><code>// From crates/hotpath/src/executor.rs\nRollbackPolicy::default() = {\n    max_consecutive_regressions: 3,\n    max_rollbacks_per_hour: 4,\n    min_stable_time_us: 5_000_000,  // 5 seconds\n}\n</code></pre> <p>If the system detects <code>max_consecutive_regressions</code> (3), it doesn't just stop\u2014it reverts the configuration to the last known \"stable\" baseline. The <code>min_stable_time_us</code> ensures we don't treat a fleeting lucky moment as a stable baseline.</p>"},{"location":"documentation/concepts/safety/#violations","title":"Violations","text":"<p>A Violation is not just an error log; it is a signal that the optimizer is fighting against the system's physics.</p> <p>When a guardrail is checked, one of these specific outcomes occurs (verified from <code>executor.rs</code>):</p> Violation Type What it means System Action <code>BoundsExceeded</code> The optimizer asked for a value outside your defined <code>min</code>/<code>max</code>. Clamp. We use the <code>min</code> or <code>max</code> boundary value instead. <code>DeltaTooLarge</code> The optimizer wants to jump too far in one step (e.g., +50%). Reject. The proposal is ignored entirely; the system stays still. <code>RateLimitExceeded</code> We are updating faster than <code>max_updates_per_second</code>. Defer. The update is queued or dropped until the window opens. <code>SafeModeActive</code> The system is currently in Safe Mode (tripped). Block. All changes are rejected until Safe Mode is cleared. <code>ObjectiveRegression</code> The metric has gotten worse for N steps in a row. Rollback. We revert to the previous good config. <code>AuditQueueFull</code> The internal telemetry buffer is full. Reject. We prioritize system performance over optimization. <code>NoBaseline</code> We want to rollback, but have no history (e.g., at startup). Fail. We cannot safely revert."},{"location":"documentation/concepts/safety/#control-safety-thrashing-and-regression-detection","title":"Control Safety: Thrashing and Regression Detection","text":"<p>The <code>ControlSafety</code> module (verified from <code>control_safety.rs</code>) adds a layer of \"meta-safety\" that watches the behavior of the optimization process over time.</p>"},{"location":"documentation/concepts/safety/#thrashing-detection","title":"Thrashing Detection","text":"<p>Thrashing is when a parameter oscillates rapidly without converging. This is dangerous because it invalidates caches and prevents the system from reaching steady state.</p> <ul> <li>Direction Flips: We count how many times a parameter changes direction (Up \u2192 Down \u2192 Up). If this happens more than <code>direction_flip_limit</code> times in a short window, we assume the optimizer is confused or chasing noise.</li> <li>Result: We trigger Safe Mode to let the system settle.</li> </ul>"},{"location":"documentation/concepts/safety/#regression-detection","title":"Regression Detection","text":"<p>Regression is when we make a change, and the objective metric gets worse.</p> <ul> <li>Consecutive Regressions: We count how many times in a row we have degraded the system. One or two regressions are expected during exploration.</li> <li>Safety Trip: If we hit <code>regression_count_limit</code> (default 5), we assume the current search path is invalid. We trigger Safe Mode and optionally Rollback.</li> </ul>"},{"location":"documentation/concepts/safety/#safe-mode","title":"Safe Mode","text":"<p>Safe Mode is the system's circuit breaker. When tripped, it freezes all parameters in their current state (or rolled-back state).</p>"},{"location":"documentation/concepts/safety/#why-freeze","title":"Why Freeze?","text":"<p>When the system is unstable (thrashing) or degrading (regressing), the worst thing you can do is keep changing variables. Freezing allows: 1.  Queues to drain. 2.  Caches to fill. 3.  Metrics to stabilize.</p>"},{"location":"documentation/concepts/safety/#exit-conditions","title":"Exit Conditions","text":"<p>Safe Mode is not permanent. The system can self-heal and exit Safe Mode via:</p> <ol> <li>Timer: After <code>cooldown_after_flip_us</code>, we assume the transient noise has passed and try again.</li> <li>Objective Recovery: If the monitored metric improves past a certain threshold naturally, we re-enable optimization.</li> <li>Manual Reset: An operator can force a reset via the CLI or API.</li> </ol> <pre><code>// SafeMode exit types\nenum SafeModeExit {\n    Timer { remaining_us: u64 },                    // Time-based auto-recovery\n    ManualReset,                                    // Human intervention\n    ObjectiveRecovery { required_improvement: f64 }, // Data-driven recovery\n}\n</code></pre>"},{"location":"documentation/concepts/safety/#audit-trail","title":"Audit Trail","text":"<p>In a self-driving system, observability is forensic. The Audit Trail provides a lock-free, immutable record of every decision.</p> <p>We log every single event: *   Proposals: \"Optimizer wanted to set <code>timeout</code> to 500ms.\" *   Decisions: \"SafetyExecutor REJECTED this because <code>max_delta</code> of 10% was exceeded.\" *   State Changes: \"System entered Safe Mode due to Thrashing at 10:42:01.\"</p> <p>This allows you to answer the question: \"Why did the config change at 3 AM?\" with standard log analysis tools.</p>"},{"location":"documentation/concepts/safety/#best-practices","title":"Best Practices","text":"<ol> <li>Start Conservative: Always launch with <code>preset_conservative()</code>. Only move to Balanced once you have seen stable operation for 24+ hours.</li> <li>Monitor Violation Rates: If you see constant <code>DeltaTooLarge</code> violations, your <code>max_delta</code> is too tight, or your optimizer is too aggressive.</li> <li>Automatic Recovery: Always set a <code>RollbackPolicy</code>. A self-driving car must have brakes.</li> <li>Forensic Logging: Pipe the Audit Trail into your centralized logging (Splunk, ELK, etc.). It is your \"black box\" flight recorder.</li> <li>Test the Limits: In staging, intentionally inject noise to trigger Safe Mode. Verify that your application handles \"frozen\" parameters gracefully.</li> </ol>"},{"location":"documentation/concepts/safety/#next-steps","title":"Next Steps","text":"<ul> <li> <p> Metabolic Architecture</p> <p>How these safety primitives enable full system autonomy</p> </li> <li> <p> Strategies</p> <p>The algorithms that generate the proposals</p> </li> <li> <p> Determinism</p> <p>Reproducibility for debugging safety incidents</p> </li> </ul>"},{"location":"documentation/concepts/strategies/","title":"Optimization Strategies","text":"<p>Different landscapes require different navigators.</p> <p>A smooth, convex valley is best descended by a geometric solver. A noisy, chaotic mountain range requires a probabilistic explorer. ArqonHPO does not force you to choose one or the other\u2014it chooses for you, dynamically.</p> <p>The PCR (Probe-Classify-Refine) algorithm continuously analyzes the topology of your objective function. It calculates the fractal dimension of the response surface and automatically hot-swaps the underlying strategy to match the terrain. This allows ArqonHPO to transition seamlessly from global exploration to local polishing without human intervention.</p>"},{"location":"documentation/concepts/strategies/#strategy-overview","title":"Strategy Overview","text":"Strategy Best For Characteristics Nelder-Mead Smooth, unimodal functions Fast convergence, low overhead, requires structure TPE Noisy, expensive evaluations Robust to noise, handles multimodal landscapes"},{"location":"documentation/concepts/strategies/#nelder-mead-simplex","title":"Nelder-Mead Simplex","text":"<p>The Nelder-Mead algorithm is a derivative-free optimizer that maintains a simplex of N+1 points in N dimensions.</p>"},{"location":"documentation/concepts/strategies/#algorithm-overview","title":"Algorithm Overview","text":"<p>Nelder-Mead iteratively transforms a simplex (a geometric shape with N+1 vertices in N dimensions) to find the minimum. The algorithm uses four operations:</p> <ol> <li>Reflection: Move the worst point through the centroid of the remaining points</li> <li>Expansion: If reflection finds a good point, extend further in that direction</li> <li>Contraction: If reflection fails, pull the worst point toward the centroid</li> <li>Shrink: If contraction fails, shrink the entire simplex toward the best point</li> </ol> <p>Each iteration replaces the worst point with a better one, gradually moving the simplex toward the optimum.</p>"},{"location":"documentation/concepts/strategies/#default-coefficients","title":"Default Coefficients","text":"<p>ArqonHPO uses standard Nelder-Mead coefficients (verified from <code>nelder_mead.rs</code>):</p> Coefficient Value Purpose <code>alpha</code> (\u03b1) 1.0 Reflection coefficient <code>gamma</code> (\u03b3) 2.0 Expansion coefficient <code>rho</code> (\u03c1) 0.5 Contraction coefficient <code>sigma</code> (\u03c3) 0.5 Shrink coefficient"},{"location":"documentation/concepts/strategies/#convergence-criteria","title":"Convergence Criteria","text":"<p>The algorithm considers itself converged when the simplex diameter falls below a tolerance threshold\u2014indicating that all points have collapsed to essentially the same location.</p>"},{"location":"documentation/concepts/strategies/#when-nelder-mead-works-well","title":"When Nelder-Mead Works Well","text":"<ul> <li>\u2705 Smooth, continuous objective functions</li> <li>\u2705 Unimodal landscapes (single minimum)</li> <li>\u2705 Continuous parameters</li> <li>\u2705 Low to moderate dimensionality</li> <li>\u2705 Deterministic evaluations (no noise)</li> </ul>"},{"location":"documentation/concepts/strategies/#when-nelder-mead-struggles","title":"When Nelder-Mead Struggles","text":"<ul> <li>\u274c Noisy evaluations (can get confused by measurement noise)</li> <li>\u274c Multimodal landscapes (may converge to local minima)</li> <li>\u274c High-dimensional spaces (simplex becomes inefficient)</li> <li>\u274c Discontinuous or non-smooth functions</li> </ul>"},{"location":"documentation/concepts/strategies/#warm-starting-from-probe","title":"Warm-Starting from Probe","text":"<p>When PCR classifies a problem as \"Structured,\" Nelder-Mead is initialized using the best points from the Probe phase. This creates an initial simplex centered on promising regions rather than starting blindly.</p>"},{"location":"documentation/concepts/strategies/#tree-structured-parzen-estimator-tpe","title":"Tree-structured Parzen Estimator (TPE)","text":"<p>TPE is a Bayesian optimization algorithm that models the relationship between parameters and objective values probabilistically.</p>"},{"location":"documentation/concepts/strategies/#algorithm-overview_1","title":"Algorithm Overview","text":"<p>Unlike traditional Bayesian optimization that models P(y|x), TPE models P(x|y)\u2014the probability of parameters given \"good\" or \"bad\" outcomes.</p> <ol> <li>Split observations: Divide all evaluated points into \"good\" (below a threshold) and \"bad\" (above threshold) groups based on objective values</li> <li>Fit density estimators: Build kernel density estimates (KDEs) for both groups</li> <li>Sample candidates: Draw samples that maximize the ratio l(x)/g(x), where l(x) is the \"good\" density and g(x) is the \"bad\" density</li> <li>Evaluate and update: Evaluate the best candidates and add results to history</li> </ol>"},{"location":"documentation/concepts/strategies/#bandwidth-selection","title":"Bandwidth Selection","text":"<p>TPE uses kernel density estimation, which requires choosing an appropriate bandwidth (smoothing parameter). ArqonHPO supports multiple bandwidth rules (verified from <code>tpe.rs</code>):</p> Rule Formula Use Case Scott's Rule (default) \u03c3 = 1.06 \u00d7 stddev \u00d7 n^(-1/5) Standard choice, adapts to distribution Silverman's Rule \u03c3 = 0.9 \u00d7 min(stddev, IQR/1.34) \u00d7 n^(-1/5) More robust to outliers Fixed Percentage of range Legacy behavior"},{"location":"documentation/concepts/strategies/#when-tpe-works-well","title":"When TPE Works Well","text":"<ul> <li>\u2705 Noisy objective functions (measurement noise, stochastic training)</li> <li>\u2705 Expensive evaluations (makes efficient use of samples)</li> <li>\u2705 Multimodal landscapes (explores multiple regions)</li> <li>\u2705 Mixed or categorical parameters (handles discrete choices)</li> </ul>"},{"location":"documentation/concepts/strategies/#when-tpe-is-less-efficient","title":"When TPE Is Less Efficient","text":"<ul> <li>\u26a0\ufe0f Higher per-candidate computational overhead</li> <li>\u26a0\ufe0f Slower convergence on smooth, well-behaved functions</li> <li>\u26a0\ufe0f Small sample sizes (needs sufficient data to build good density models)</li> </ul>"},{"location":"documentation/concepts/strategies/#online-optimization","title":"Online Optimization","text":"<p>TPE is the strategy used by <code>ask_one()</code> for online/real-time optimization. Its incremental nature makes it well-suited for streaming scenarios where evaluations arrive one at a time.</p>"},{"location":"documentation/concepts/strategies/#automatic-strategy-selection","title":"Automatic Strategy Selection","text":"<p>ArqonHPO's PCR algorithm automatically selects the appropriate strategy based on landscape analysis:</p> <pre><code>graph TD\n    A[Probe Phase] --&gt; B[Classify Phase]\n    B --&gt; C{Residual Decay \u03b1}\n    C --&gt;|\u03b1 &gt; 0.5| D[Nelder-Mead]\n    C --&gt;|\u03b1 \u2264 0.5| E[TPE]\n\n    D --&gt; F[Refine Phase]\n    E --&gt; F</code></pre>"},{"location":"documentation/concepts/strategies/#classification-logic","title":"Classification Logic","text":"<p>The ResidualDecayClassifier examines how objective values improve across the probe samples. Functions with exploitable structure show geometric decay in residuals, while noisy or multimodal functions show irregular patterns.</p> Signal Interpretation Strategy High \u03b1 (&gt; 0.5) Geometric residual decay Nelder-Mead Low \u03b1 (\u2264 0.5) Flat or irregular residuals TPE <p>For details on the classification algorithm, see PCR Algorithm.</p>"},{"location":"documentation/concepts/strategies/#multi-start-nelder-mead","title":"Multi-Start Nelder-Mead","text":"<p>Not Currently Used by PCR</p> <p>Multi-Start NM is available in the codebase but is not currently selected by the PCR classifier. It remains available for potential future use or manual configuration.</p> <p>For multimodal functions with multiple local minima, Multi-Start NM launches several simplex searches from different starting points.</p>"},{"location":"documentation/concepts/strategies/#how-it-works","title":"How It Works","text":"<ol> <li>Probe phase samples the landscape</li> <li>Identify multiple promising regions</li> <li>Launch independent NM searches per region</li> <li>Return the best result across all runs</li> </ol> <p>This approach is more expensive than single NM but can escape local minima.</p>"},{"location":"documentation/concepts/strategies/#strategy-comparison","title":"Strategy Comparison","text":"Aspect Nelder-Mead TPE Mechanism Geometric simplex operations Probabilistic density modeling Per-step overhead Minimal Higher (density estimation) Sample efficiency on smooth functions Excellent Good Noise tolerance Poor Excellent Incremental/online use Difficult (needs full simplex) Natural fit Warm-start support Yes (from probe points) Yes (from all history)"},{"location":"documentation/concepts/strategies/#next-steps","title":"Next Steps","text":"<ul> <li> PCR Algorithm</li> </ul> <p>How Probe-Classify-Refine works</p> <ul> <li> Batch vs. Online</li> </ul> <p>When to use <code>ask()</code> vs. <code>ask_one()</code></p> <ul> <li> Probe Deep Dive</li> </ul> <p>Mathematics of the sampling phase</p>"},{"location":"documentation/cookbook/","title":"Cookbook","text":"<p>Real-world recipes for common optimization scenarios.</p>"},{"location":"documentation/cookbook/#simulation-tuning","title":"Simulation Tuning","text":"<ul> <li> CFD Parameter Sweep</li> </ul> <p>Tune expensive physics simulations with minimal objective calls.</p>"},{"location":"documentation/cookbook/#ml-model-tuning","title":"ML Model Tuning","text":"<ul> <li> Sklearn Hyperparameters</li> </ul> <p>Tune RandomForest, XGBoost, or any sklearn estimator.</p>"},{"location":"documentation/cookbook/fastapi/","title":"FastAPI Integration","text":"<p>Expose ArqonHPO as a REST API service using FastAPI.</p>"},{"location":"documentation/cookbook/fastapi/#basic-setup","title":"Basic Setup","text":"<pre><code>from fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\nfrom arqonhpo import ArqonSolver\nimport json\nfrom typing import Optional\n\napp = FastAPI(title=\"ArqonHPO Service\")\n\n# Global solver state\nsolver: Optional[ArqonSolver] = None\n\nclass ConfigRequest(BaseModel):\n    seed: int = 42\n    budget: int = 100\n    bounds: dict\n\nclass TellRequest(BaseModel):\n    params: dict\n    value: float\n    cost: float = 1.0\n\n@app.post(\"/init\")\ndef init_solver(config: ConfigRequest):\n    global solver\n    config_dict = {\n        \"seed\": config.seed,\n        \"budget\": config.budget,\n        \"bounds\": config.bounds\n    }\n    solver = ArqonSolver(json.dumps(config_dict))\n    return {\"status\": \"initialized\", \"budget\": config.budget}\n\n@app.get(\"/ask\")\ndef ask():\n    if solver is None:\n        raise HTTPException(status_code=400, detail=\"Solver not initialized\")\n\n    candidates = solver.ask()\n    if candidates is None:\n        return {\"done\": True, \"candidates\": []}\n    return {\"done\": False, \"candidates\": candidates}\n\n@app.post(\"/tell\")\ndef tell(results: list[TellRequest]):\n    if solver is None:\n        raise HTTPException(status_code=400, detail=\"Solver not initialized\")\n\n    results_list = [\n        {\"params\": r.params, \"value\": r.value, \"cost\": r.cost}\n        for r in results\n    ]\n    solver.tell(json.dumps(results_list))\n    return {\"status\": \"ok\", \"history_len\": solver.get_history_len()}\n\n@app.get(\"/status\")\ndef status():\n    if solver is None:\n        return {\"initialized\": False}\n    return {\n        \"initialized\": True,\n        \"history_len\": solver.get_history_len()\n    }\n</code></pre>"},{"location":"documentation/cookbook/fastapi/#run-the-service","title":"Run the Service","text":"<pre><code>pip install fastapi uvicorn arqonhpo\nuvicorn main:app --host 0.0.0.0 --port 8000\n</code></pre>"},{"location":"documentation/cookbook/fastapi/#client-usage","title":"Client Usage","text":"<pre><code>import requests\n\n# Initialize\nresp = requests.post(\"http://localhost:8000/init\", json={\n    \"seed\": 42,\n    \"budget\": 100,\n    \"bounds\": {\"x\": {\"min\": -5, \"max\": 5}}\n})\n\n# Optimization loop\nwhile True:\n    # Ask for candidates\n    resp = requests.get(\"http://localhost:8000/ask\")\n    data = resp.json()\n\n    if data[\"done\"]:\n        break\n\n    # Evaluate candidates\n    results = []\n    for params in data[\"candidates\"]:\n        value = evaluate(params)  # Your function\n        results.append({\"params\": params, \"value\": value, \"cost\": 1.0})\n\n    # Tell results\n    requests.post(\"http://localhost:8000/tell\", json=results)\n</code></pre>"},{"location":"documentation/cookbook/fastapi/#with-background-tasks","title":"With Background Tasks","text":"<p>For long-running evaluations:</p> <pre><code>from fastapi import BackgroundTasks\nimport asyncio\n\npending_evals = {}\n\n@app.post(\"/start-eval/{eval_id}\")\nasync def start_eval(eval_id: str, params: dict, background_tasks: BackgroundTasks):\n    background_tasks.add_task(run_evaluation, eval_id, params)\n    return {\"status\": \"started\", \"eval_id\": eval_id}\n\nasync def run_evaluation(eval_id: str, params: dict):\n    # Long-running evaluation\n    value = await expensive_evaluation(params)\n    pending_evals[eval_id] = {\"params\": params, \"value\": value}\n\n@app.get(\"/result/{eval_id}\")\ndef get_result(eval_id: str):\n    if eval_id not in pending_evals:\n        raise HTTPException(status_code=404, detail=\"Eval not found\")\n    return pending_evals.pop(eval_id)\n</code></pre>"},{"location":"documentation/cookbook/fastapi/#docker-deployment","title":"Docker Deployment","text":"<pre><code>FROM python:3.11-slim\n\nRUN pip install fastapi uvicorn arqonhpo\n\nCOPY main.py .\n\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre> <pre><code>docker build -t arqon-api .\ndocker run -p 8000:8000 arqon-api\n</code></pre>"},{"location":"documentation/cookbook/fastapi/#openapi-docs","title":"OpenAPI Docs","text":"<p>FastAPI auto-generates OpenAPI docs at:</p> <ul> <li>Swagger UI: <code>http://localhost:8000/docs</code></li> <li>ReDoc: <code>http://localhost:8000/redoc</code></li> </ul>"},{"location":"documentation/cookbook/fastapi/#next-steps","title":"Next Steps","text":"<ul> <li>Python API \u2014 ArqonSolver reference</li> <li>Kubernetes \u2014 Deploy to K8s</li> <li>Observability \u2014 Add metrics</li> </ul>"},{"location":"documentation/cookbook/kubernetes/","title":"Kubernetes Integration","text":"<p>Run ArqonHPO in Kubernetes for production hyperparameter optimization.</p>"},{"location":"documentation/cookbook/kubernetes/#architecture-patterns","title":"Architecture Patterns","text":""},{"location":"documentation/cookbook/kubernetes/#pattern-1-sidecar","title":"Pattern 1: Sidecar","text":"<p>ArqonHPO runs as a sidecar container, optimizing your main application's parameters.</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app\nspec:\n  replicas: 1\n  template:\n    spec:\n      containers:\n        - name: app\n          image: my-app:latest\n          env:\n            - name: CONFIG_PATH\n              value: /shared/config.json\n          volumeMounts:\n            - name: shared\n              mountPath: /shared\n\n        - name: arqon\n          image: arqonhpo:latest\n          command:\n            - arqonhpo\n            - dashboard\n            - --state=/shared/state.json\n            - --addr=0.0.0.0:3030\n          volumeMounts:\n            - name: shared\n              mountPath: /shared\n          ports:\n            - containerPort: 3030\n              name: dashboard\n            - containerPort: 9898\n              name: metrics\n\n      volumes:\n        - name: shared\n          emptyDir: {}\n</code></pre>"},{"location":"documentation/cookbook/kubernetes/#pattern-2-job-based","title":"Pattern 2: Job-based","text":"<p>Parallelize evaluations using Kubernetes Jobs.</p> <pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: arqon-eval-{{ .Candidate.ID }}\nspec:\n  template:\n    spec:\n      containers:\n        - name: eval\n          image: my-evaluator:latest\n          env:\n            - name: ARQON_x\n              value: \"{{ .Candidate.Params.x }}\"\n            - name: ARQON_y\n              value: \"{{ .Candidate.Params.y }}\"\n          command:\n            - ./evaluate.sh\n      restartPolicy: Never\n</code></pre> <p>Controller Loop:</p> <pre><code>import json\nimport subprocess\nfrom arqonhpo import ArqonSolver\n\nsolver = ArqonSolver(json.dumps(config))\n\nwhile True:\n    candidates = solver.ask()\n    if not candidates:\n        break\n\n    # Launch K8s jobs for each candidate\n    jobs = []\n    for i, params in enumerate(candidates):\n        job = launch_k8s_job(f\"eval-{i}\", params)\n        jobs.append((job, params))\n\n    # Wait and collect results\n    results = []\n    for job, params in jobs:\n        value = wait_for_job_result(job)\n        results.append({\n            \"params\": params,\n            \"value\": value,\n            \"cost\": 1.0\n        })\n\n    solver.tell(json.dumps(results))\n</code></pre>"},{"location":"documentation/cookbook/kubernetes/#pattern-3-cronjob-tuning","title":"Pattern 3: CronJob Tuning","text":"<p>Periodic re-optimization for drifting systems.</p> <pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: arqon-retune\nspec:\n  schedule: \"0 */6 * * *\" # Every 6 hours\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: tune\n              image: arqonhpo:latest\n              command:\n                - arqonhpo\n                - run\n                - --config=/config/config.json\n                - --script=/scripts/evaluate.sh\n                - --state=/state/state.json\n              volumeMounts:\n                - name: config\n                  mountPath: /config\n                - name: state\n                  mountPath: /state\n          restartPolicy: OnFailure\n          volumes:\n            - name: config\n              configMap:\n                name: arqon-config\n            - name: state\n              persistentVolumeClaim:\n                claimName: arqon-state\n</code></pre>"},{"location":"documentation/cookbook/kubernetes/#configmap-for-optimization-config","title":"ConfigMap for Optimization Config","text":"<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: arqon-config\ndata:\n  config.json: |\n    {\n      \"seed\": 42,\n      \"budget\": 100,\n      \"bounds\": {\n        \"batch_size\": {\"min\": 1, \"max\": 64, \"scale\": \"Log\"},\n        \"learning_rate\": {\"min\": 0.0001, \"max\": 0.1, \"scale\": \"Log\"}\n      }\n    }\n</code></pre>"},{"location":"documentation/cookbook/kubernetes/#prometheus-integration","title":"Prometheus Integration","text":"<p>ArqonHPO exposes metrics compatible with Prometheus Operator:</p> <pre><code>apiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: arqon-metrics\nspec:\n  selector:\n    matchLabels:\n      app: arqon\n  endpoints:\n    - port: metrics\n      interval: 15s\n</code></pre>"},{"location":"documentation/cookbook/kubernetes/#persistentvolumeclaim-for-state","title":"PersistentVolumeClaim for State","text":"<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: arqon-state\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 100Mi\n</code></pre>"},{"location":"documentation/cookbook/kubernetes/#helm-chart-planned","title":"Helm Chart (Planned)","text":"<p>We're working on an official Helm chart. Track progress: Issue #XX</p>"},{"location":"documentation/cookbook/kubernetes/#best-practices","title":"Best Practices","text":"<ol> <li>State persistence \u2014 Use PVC for state files across restarts</li> <li>Resource limits \u2014 ArqonHPO is lightweight (~50MB memory)</li> <li>Health checks \u2014 Dashboard has <code>/api/summary</code> for liveness</li> <li>Secrets \u2014 Use K8s Secrets for sensitive config values</li> </ol>"},{"location":"documentation/cookbook/kubernetes/#next-steps","title":"Next Steps","text":"<ul> <li>Observability \u2014 Prometheus metrics</li> <li>Dashboard \u2014 REST API</li> <li>Safety \u2014 Guardrails for production</li> </ul>"},{"location":"documentation/cookbook/ml_tuning/","title":"Cookbook: ML Model Tuning","text":"<p>Tune sklearn or PyTorch hyperparameters with TPE.</p>"},{"location":"documentation/cookbook/ml_tuning/#the-pcr-algorithm-for-ml","title":"The PCR Algorithm for ML","text":"<p>While ArqonHPO is known for fast simulation tuning, it excels at ML tuning via the PCR (Probe-Classify-Refine) algorithm:</p> <ol> <li>Probe: Scans the hyperparameter space.</li> <li>Classify: ResidualDecayClassifier detects that ML loss surfaces are chaotic/noisy (slow residual decay, $\\alpha \\le 0.5$).</li> <li>Refine: Automatically selects TPE (Tree-structured Parzen Estimator) instead of Nelder-Mead.</li> </ol> <p>When probe samples show flat or irregular residual patterns (no geometric decay), ArqonHPO classifies the landscape as Chaotic and selects TPE:</p> <ul> <li>\u03b1 \u2264 0.5 \u2192 Many local optima, noisy evaluations \u2192 TPE</li> <li>TPE models \"good\" (l(x)) and \"bad\" (g(x)) distributions using kernel density estimation</li> <li>Samples are drawn to maximize Expected Improvement (EI)</li> </ul>"},{"location":"documentation/cookbook/ml_tuning/#example-sklearn-randomforest","title":"Example: Sklearn RandomForest","text":"<pre><code>import json\nfrom sklearn.datasets import load_iris\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom arqonhpo import ArqonSolver\n\n# Data\nX, y = load_iris(return_X_y=True)\n\ndef objective(params):\n    clf = RandomForestClassifier(\n        n_estimators=int(params[\"n_estimators\"]),\n        max_depth=int(params[\"max_depth\"]),\n        random_state=42\n    )\n    # Cross-validation score (higher is better, so negate for minimization)\n    score = cross_val_score(clf, X, y, cv=3).mean()\n    return -score  # Minimize negative accuracy\n\n# Config\nconfig = {\n    \"seed\": 42,\n    \"budget\": 100,\n    \"probe_ratio\": 0.3,  # More probing to detect noise\n    \"bounds\": {\n        \"n_estimators\": {\"min\": 10, \"max\": 200},\n        \"max_depth\": {\"min\": 2, \"max\": 20}\n    }\n}\n\nsolver = ArqonSolver(json.dumps(config))\nbest = {\"value\": float('inf')}\n\nwhile True:\n    batch = solver.ask()\n    if batch is None:\n        break\n\n    results = []\n    for params in batch:\n        loss = objective(params)\n        if loss &lt; best[\"value\"]:\n            best = {\"params\": params, \"value\": loss}\n        results.append({\n            \"eval_id\": 0,\n            \"params\": params,\n            \"value\": loss,\n            \"cost\": 0.5\n        })\n\n    solver.tell(json.dumps(results))\n\nprint(f\"Best: n_estimators={int(best['params']['n_estimators'])}, max_depth={int(best['params']['max_depth'])}\")\nprint(f\"Accuracy: {-best['value']:.4f}\")\n# Best: n_estimators=120, max_depth=8\n# Accuracy: 0.9667\n</code></pre>"},{"location":"documentation/cookbook/ml_tuning/#why-tpe","title":"Why TPE?","text":"<p>TPE builds probabilistic models of \"good\" and \"bad\" regions of the hyperparameter space, making it robust to noise and efficient at exploration.</p>"},{"location":"documentation/cookbook/ml_tuning/#scotts-rule-bandwidth","title":"Scott's Rule Bandwidth","text":"<p>ArqonHPO uses Scott's Rule for adaptive kernel bandwidth in TPE:</p> <pre><code>\u03c3 = 1.06 \u00d7 stddev \u00d7 n^(-1/5)\n</code></pre> <p>This provides:</p> <ul> <li>Automatic adaptation: Bandwidth shrinks as more samples are collected</li> <li>Data-driven scaling: Uses sample standard deviation, not fixed percentages</li> <li>Asymptotic optimality: Minimizes mean integrated squared error for Gaussian kernels</li> </ul> <p>Compared to fixed bandwidth (e.g., 10% of range):</p> Method Pros Cons Scott's Rule Adapts to data distribution, optimal for smooth densities May under-smooth in tails Fixed 10% Simple, predictable Ignores data structure, often suboptimal <p>ArqonHPO defaults to Scott's Rule but supports alternatives via <code>BandwidthRule</code>:</p> <pre><code>TPE::with_bandwidth_rule(dim, BandwidthRule::Scott)    // Default\nTPE::with_bandwidth_rule(dim, BandwidthRule::Silverman)  // Alternative\nTPE::with_bandwidth_rule(dim, BandwidthRule::Fixed(0.1)) // Legacy behavior\n</code></pre>"},{"location":"documentation/cookbook/mlflow/","title":"MLflow Integration","text":"<p>Track ArqonHPO optimization runs with MLflow.</p>"},{"location":"documentation/cookbook/mlflow/#basic-setup","title":"Basic Setup","text":"<pre><code>import mlflow\nfrom arqonhpo import ArqonSolver\nimport json\n\n# Start MLflow run\nmlflow.set_experiment(\"hyperparameter-tuning\")\n\nwith mlflow.start_run(run_name=\"arqon-optimization\"):\n    config = {\n        \"seed\": 42,\n        \"budget\": 100,\n        \"bounds\": {\n            \"lr\": {\"min\": 0.0001, \"max\": 0.1, \"scale\": \"Log\"},\n            \"batch_size\": {\"min\": 8, \"max\": 128}\n        }\n    }\n\n    # Log config as params\n    mlflow.log_params({\n        \"arqon_seed\": config[\"seed\"],\n        \"arqon_budget\": config[\"budget\"],\n        \"optimizer\": \"arqonhpo\"\n    })\n\n    solver = ArqonSolver(json.dumps(config))\n\n    iteration = 0\n    while True:\n        candidates = solver.ask()\n        if candidates is None:\n            break\n\n        for params in candidates:\n            # Evaluate\n            value = train_model(params)\n\n            # Log each evaluation\n            mlflow.log_metrics({\n                \"objective\": value,\n                \"lr\": params[\"lr\"],\n                \"batch_size\": params[\"batch_size\"]\n            }, step=iteration)\n\n            # Tell ArqonHPO\n            solver.seed(json.dumps([{\n                \"params\": params,\n                \"value\": value,\n                \"cost\": 1.0\n            }]))\n\n            iteration += 1\n\n    # Log best result\n    best = min(results, key=lambda x: x[\"value\"])\n    mlflow.log_metrics({\"best_objective\": best[\"value\"]})\n    mlflow.log_params({\"best_\" + k: v for k, v in best[\"params\"].items()})\n</code></pre>"},{"location":"documentation/cookbook/mlflow/#log-optimization-artifact","title":"Log Optimization Artifact","text":"<p>Export and log ArqonHPO state as an artifact:</p> <pre><code>import tempfile\nimport os\n\n# After optimization\nwith tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:\n    artifact = solver.export()\n    f.write(artifact)\n    artifact_path = f.name\n\nmlflow.log_artifact(artifact_path, \"arqon\")\nos.unlink(artifact_path)\n</code></pre>"},{"location":"documentation/cookbook/mlflow/#custom-mlflow-callback","title":"Custom MLflow Callback","text":"<p>Create a reusable callback pattern:</p> <pre><code>class MLflowCallback:\n    def __init__(self, experiment_name, run_name=None):\n        mlflow.set_experiment(experiment_name)\n        self.run = mlflow.start_run(run_name=run_name)\n        self.step = 0\n\n    def on_ask(self, candidates):\n        mlflow.log_metric(\"candidates_requested\", len(candidates), step=self.step)\n\n    def on_tell(self, results):\n        for result in results:\n            mlflow.log_metrics({\n                \"objective\": result[\"value\"],\n                **{f\"param_{k}\": v for k, v in result[\"params\"].items()}\n            }, step=self.step)\n            self.step += 1\n\n    def on_complete(self, best):\n        mlflow.log_metrics({\"best_objective\": best[\"value\"]})\n        mlflow.log_params({f\"best_{k}\": v for k, v in best[\"params\"].items()})\n        mlflow.end_run()\n\n# Usage\ncallback = MLflowCallback(\"my-experiment\", \"run-001\")\n\nwhile True:\n    candidates = solver.ask()\n    if candidates is None:\n        break\n\n    callback.on_ask(candidates)\n    results = evaluate_batch(candidates)\n    solver.tell(json.dumps(results))\n    callback.on_tell(results)\n\ncallback.on_complete(best)\n</code></pre>"},{"location":"documentation/cookbook/mlflow/#mlflow-ui","title":"MLflow UI","text":"<p>View optimization runs:</p> <pre><code>mlflow ui --port 5000\n</code></pre> <p>Navigate to <code>http://localhost:5000</code> to see:</p> <ul> <li>Parameter progression</li> <li>Objective value over time</li> <li>Best configurations</li> </ul>"},{"location":"documentation/cookbook/mlflow/#compare-runs","title":"Compare Runs","text":"<pre><code>import mlflow\n\n# Get experiment\nexperiment = mlflow.get_experiment_by_name(\"hyperparameter-tuning\")\n\n# Query runs\nruns = mlflow.search_runs(\n    experiment_ids=[experiment.experiment_id],\n    order_by=[\"metrics.best_objective ASC\"]\n)\n\n# Best run\nbest_run = runs.iloc[0]\nprint(f\"Best run: {best_run['run_id']}\")\nprint(f\"Best objective: {best_run['metrics.best_objective']}\")\n</code></pre>"},{"location":"documentation/cookbook/mlflow/#docker-deployment","title":"Docker Deployment","text":"<pre><code>FROM python:3.11-slim\n\nRUN pip install arqonhpo mlflow\n\nCOPY train.py .\n\nENV MLFLOW_TRACKING_URI=http://mlflow-server:5000\n\nCMD [\"python\", \"train.py\"]\n</code></pre>"},{"location":"documentation/cookbook/mlflow/#next-steps","title":"Next Steps","text":"<ul> <li>Ray Tune \u2014 Distributed optimization</li> <li>Integrations \u2014 All integrations</li> <li>Observability \u2014 Prometheus metrics</li> </ul>"},{"location":"documentation/cookbook/ray/","title":"Ray Tune Integration","text":"<p>Use ArqonHPO as a backend for Ray Tune distributed hyperparameter optimization.</p>"},{"location":"documentation/cookbook/ray/#why-arqonhpo-ray","title":"Why ArqonHPO + Ray?","text":"Feature ArqonHPO Alone Ray Tune + ArqonHPO Parallelism Manual Automatic Distributed Manual sharding Built-in Fault tolerance Manual Checkpointing Scheduling None ASHA, HyperBand"},{"location":"documentation/cookbook/ray/#basic-integration","title":"Basic Integration","text":"<p>ArqonHPO can be used as a custom search algorithm in Ray Tune:</p> <pre><code>from ray import tune\nfrom ray.tune.search import Searcher\nfrom arqonhpo import ArqonSolver\nimport json\n\nclass ArqonSearcher(Searcher):\n    def __init__(self, config, **kwargs):\n        super().__init__(**kwargs)\n        self.solver = ArqonSolver(json.dumps(config))\n        self._pending = {}\n\n    def suggest(self, trial_id):\n        candidate = self.solver.ask_one()\n        if candidate is None:\n            return Searcher.FINISHED\n        self._pending[trial_id] = candidate\n        return candidate\n\n    def on_trial_complete(self, trial_id, result, **kwargs):\n        params = self._pending.pop(trial_id)\n        self.solver.seed(json.dumps([{\n            \"params\": params,\n            \"value\": result[\"loss\"],\n            \"cost\": 1.0\n        }]))\n\n# Usage\ndef train_fn(config):\n    # Your training code\n    loss = train_model(config[\"lr\"], config[\"batch_size\"])\n    return {\"loss\": loss}\n\narqon_config = {\n    \"seed\": 42,\n    \"budget\": 100,\n    \"bounds\": {\n        \"lr\": {\"min\": 0.0001, \"max\": 0.1, \"scale\": \"Log\"},\n        \"batch_size\": {\"min\": 8, \"max\": 128, \"scale\": \"Log\"}\n    }\n}\n\nsearcher = ArqonSearcher(arqon_config)\n\nanalysis = tune.run(\n    train_fn,\n    num_samples=100,\n    search_alg=searcher,\n    resources_per_trial={\"cpu\": 1, \"gpu\": 0.5}\n)\n</code></pre>"},{"location":"documentation/cookbook/ray/#with-early-stopping-asha","title":"With Early Stopping (ASHA)","text":"<p>Combine ArqonHPO suggestions with ASHA scheduler:</p> <pre><code>from ray.tune.schedulers import ASHAScheduler\n\nscheduler = ASHAScheduler(\n    max_t=100,\n    grace_period=10,\n    reduction_factor=2\n)\n\nanalysis = tune.run(\n    train_fn,\n    num_samples=100,\n    search_alg=ArqonSearcher(arqon_config),\n    scheduler=scheduler,  # ASHA stops bad trials early\n)\n</code></pre>"},{"location":"documentation/cookbook/ray/#distributed-arqonprobe","title":"Distributed ArqonProbe","text":"<p>For large parameter spaces, use <code>ArqonProbe</code> for embarrassingly parallel sampling:</p> <pre><code>from arqonhpo import ArqonProbe\nfrom ray import remote\nimport json\n\nconfig = json.dumps({\n    \"bounds\": {\n        \"lr\": {\"min\": 0.0001, \"max\": 0.1},\n        \"bs\": {\"min\": 8, \"max\": 128}\n    }\n})\n\n@remote\ndef evaluate_sample(probe_config, seed, index):\n    probe = ArqonProbe(probe_config, seed=seed)\n    params = probe.sample_at(index)\n    return {\"params\": params, \"value\": train_and_eval(params)}\n\n# Launch 1000 parallel evaluations\nfutures = [\n    evaluate_sample.remote(config, 42, i)\n    for i in range(1000)\n]\nresults = ray.get(futures)\n</code></pre> <p>Each worker generates deterministic, non-overlapping samples without coordination.</p>"},{"location":"documentation/cookbook/ray/#checkpointing","title":"Checkpointing","text":"<p>Save ArqonHPO state with Ray Tune checkpoints:</p> <pre><code>class ArqonSearcherWithCheckpoint(ArqonSearcher):\n    def save(self, checkpoint_path):\n        # Export solver state\n        state = self.solver.export()\n        with open(checkpoint_path, \"w\") as f:\n            f.write(state)\n\n    def restore(self, checkpoint_path):\n        with open(checkpoint_path) as f:\n            state = f.read()\n        self.solver = ArqonSolver.from_state(state)\n</code></pre>"},{"location":"documentation/cookbook/ray/#resource-optimization","title":"Resource Optimization","text":"<p>Use ArqonHPO to optimize Ray cluster resources:</p> <pre><code>arqon_config = {\n    \"seed\": 42,\n    \"budget\": 50,\n    \"bounds\": {\n        \"num_workers\": {\"min\": 1, \"max\": 32},\n        \"cpus_per_worker\": {\"min\": 1, \"max\": 8},\n        \"memory_per_worker_gb\": {\"min\": 2, \"max\": 32}\n    }\n}\n</code></pre>"},{"location":"documentation/cookbook/ray/#next-steps","title":"Next Steps","text":"<ul> <li>Python API \u2014 ArqonSolver/ArqonProbe</li> <li>Determinism \u2014 Sharding pattern</li> <li>Kubernetes \u2014 Deploy Ray on K8s</li> </ul>"},{"location":"documentation/cookbook/sim_tuning/","title":"Cookbook: Simulation Tuning","text":"<p>Tune expensive, smooth simulation objectives with Nelder-Mead.</p>"},{"location":"documentation/cookbook/sim_tuning/#scenario","title":"Scenario","text":"<p>You have a CFD or physics simulation that:</p> <ul> <li>Takes minutes to hours per evaluation.</li> <li>Has a smooth landscape (small parameter changes = small output changes).</li> <li>You have a tight evaluation budget (e.g., 50-100 runs).</li> </ul> <p>ArqonHPO will automatically detect this and use Nelder-Mead, which minimizes evaluations.</p>"},{"location":"documentation/cookbook/sim_tuning/#the-pcr-algorithm","title":"The PCR Algorithm","text":"<p>For simulation tuning, ArqonHPO uses the Probe-Classify-Refine (PCR) algorithm:</p> <ol> <li>Probe: It samples the parameter space using a multi-scale prime-index grid.</li> <li>Classify: It analyzes the residuals of the probe phase. Smooth simulations show fast residual decay ($\\alpha &gt; 0.5$).</li> <li>Refine: If structured, it launches Nelder-Mead initialized from the best probe points.</li> </ol> <p>This \"Hybrid Seeding\" allows Nelder-Mead to start exploitation immediately from a high-quality region. This means for CFD simulations with smooth, bowl-shaped objectives, ArqonHPO will:</p> <ul> <li>Detect geometric decay in residuals (fast convergence signature)</li> <li>Automatically select Nelder-Mead without manual configuration</li> <li>Use probe results to intelligently initialize the simplex</li> </ul>"},{"location":"documentation/cookbook/sim_tuning/#example-cfd-parameter-sweep","title":"Example: CFD Parameter Sweep","text":"<pre><code>import json\nimport time\nfrom arqonhpo import ArqonSolver\n\n# Simulate expensive CFD call\ndef cfd_simulation(params):\n    inlet_velocity = params[\"inlet_velocity\"]\n    turbulence_k = params[\"turbulence_k\"]\n\n    time.sleep(0.5)  # Simulate 30-minute CFD; use 0.5s for demo\n\n    # Fake \"drag coefficient\" as objective\n    drag = (inlet_velocity - 5.0)**2 + (turbulence_k - 0.1)**2\n    return drag\n\n# Config\nconfig = {\n    \"seed\": 123,\n    \"budget\": 30,  # Very tight budget\n    \"probe_ratio\": 0.2,\n    \"bounds\": {\n        \"inlet_velocity\": {\"min\": 1.0, \"max\": 10.0},\n        \"turbulence_k\": {\"min\": 0.01, \"max\": 0.5}\n    }\n}\n\nsolver = ArqonSolver(json.dumps(config))\nbest = {\"value\": float('inf')}\n\nwhile True:\n    batch = solver.ask()\n    if batch is None:\n        break\n\n    results = []\n    for i, params in enumerate(batch):\n        drag = cfd_simulation(params)\n        if drag &lt; best[\"value\"]:\n            best = {\"params\": params, \"value\": drag}\n        results.append({\n            \"eval_id\": i,\n            \"params\": params,\n            \"value\": drag,\n            \"cost\": 30.0  # 30 mins\n        })\n\n    solver.tell(json.dumps(results))\n\nprint(f\"Optimal: {best}\")\n# Optimal: {'params': {'inlet_velocity': 5.02, 'turbulence_k': 0.098}, 'value': 0.0004}\n</code></pre>"},{"location":"documentation/cookbook/sim_tuning/#why-nelder-mead","title":"Why Nelder-Mead?","text":"<p>For smooth landscapes, Nelder-Mead's simplex operations converge faster than random search or TPE because it exploits local gradient information without needing derivatives.</p>"},{"location":"documentation/cookbook/sim_tuning/#nelder-mead-operations","title":"Nelder-Mead Operations","text":"<p>ArqonHPO implements all 5 standard NM operations:</p> Operation When Used Formula Reflection Always tried first x_r = c + \u03b1(c - worst) Expansion Reflection is best so far x_e = c + \u03b3(r - c) Outside Contraction Reflection between 2nd-worst and worst x_c = c + \u03c1(r - c) Inside Contraction Reflection worse than worst x_c = c + \u03c1(worst - c) Shrink Contraction fails x_i = best + \u03c3(x_i - best) <p>Standard coefficients: \u03b1=1.0, \u03b3=2.0, \u03c1=0.5, \u03c3=0.5</p>"},{"location":"documentation/cookbook/warm_starting/","title":"Warm-Starting with Seed Data","text":"<p>This guide shows how to use the <code>seed()</code> method to warm-start the solver with historical evaluation data.</p>"},{"location":"documentation/cookbook/warm_starting/#use-cases","title":"Use Cases","text":"<ul> <li>Resume optimization: Continue from a previous run's data</li> <li>Transfer learning: Use data from similar optimization problems</li> <li>Online/streaming optimization: External systems generate evaluations</li> </ul>"},{"location":"documentation/cookbook/warm_starting/#basic-usage","title":"Basic Usage","text":"<pre><code>import json\nfrom arqonhpo import ArqonSolver\n\n# Configure the solver\nconfig = {\n    \"seed\": 42,\n    \"budget\": 100,\n    \"bounds\": {\n        \"learning_rate\": {\"min\": 1e-5, \"max\": 1e-1, \"scale\": \"Log\"},\n        \"batch_size\": {\"min\": 16, \"max\": 256, \"scale\": \"Linear\"}\n    },\n    \"probe_ratio\": 0.2\n}\nsolver = ArqonSolver(json.dumps(config))\n\n# Historical data from a previous run\nhistorical_data = [\n    {\"params\": {\"learning_rate\": 0.001, \"batch_size\": 32}, \"value\": 0.85, \"cost\": 1.0},\n    {\"params\": {\"learning_rate\": 0.01, \"batch_size\": 64}, \"value\": 0.78, \"cost\": 1.0},\n    {\"params\": {\"learning_rate\": 0.0001, \"batch_size\": 128}, \"value\": 0.92, \"cost\": 1.0},\n]\n\n# Seed the solver with historical data\nsolver.seed(json.dumps(historical_data))\n\n# Verify the data was added\nprint(f\"History length: {solver.get_history_len()}\")  # Output: 3\n\n# Continue optimization - solver will use seeded data\nbatch = solver.ask()\n</code></pre>"},{"location":"documentation/cookbook/warm_starting/#warm-starting-from-a-previous-run","title":"Warm-Starting from a Previous Run","text":"<pre><code>import json\nfrom pathlib import Path\nfrom arqonhpo import ArqonSolver\n\ndef load_previous_run(run_path: str) -&gt; list:\n    \"\"\"Load evaluation history from a previous run.\"\"\"\n    with open(run_path) as f:\n        artifact = json.load(f)\n\n    # Convert EvalTrace format to SeedPoint format\n    return [\n        {\n            \"params\": eval[\"params\"],\n            \"value\": eval[\"value\"],\n            \"cost\": eval[\"cost\"]\n        }\n        for eval in artifact[\"history\"]\n    ]\n\n# Resume from previous run\nconfig = {\n    \"seed\": 42,\n    \"budget\": 200,  # Continue with more budget\n    \"bounds\": {\n        \"x\": {\"min\": -5.0, \"max\": 5.0, \"scale\": \"Linear\"},\n        \"y\": {\"min\": -5.0, \"max\": 5.0, \"scale\": \"Linear\"}\n    },\n    \"probe_ratio\": 0.2\n}\n\nsolver = ArqonSolver(json.dumps(config))\n\n# Seed with previous run data\nprevious_data = load_previous_run(\"run_artifact.json\")\nsolver.seed(json.dumps(previous_data))\n\n# Continue optimization\nwhile True:\n    batch = solver.ask()\n    if batch is None:\n        break\n\n    # Evaluate and tell...\n</code></pre>"},{"location":"documentation/cookbook/warm_starting/#streaming-optimization","title":"Streaming Optimization","text":"<p>For online systems where evaluations arrive asynchronously:</p> <pre><code>import json\nfrom arqonhpo import ArqonSolver\n\nconfig = {\n    \"seed\": 42,\n    \"budget\": 1000,\n    \"bounds\": {\"x\": {\"min\": 0.0, \"max\": 1.0, \"scale\": \"Linear\"}},\n    \"probe_ratio\": 0.2\n}\nsolver = ArqonSolver(json.dumps(config))\n\ndef on_external_evaluation(params: dict, value: float, cost: float):\n    \"\"\"Called when an external system completes an evaluation.\"\"\"\n    seed_point = [{\"params\": params, \"value\": value, \"cost\": cost}]\n    solver.seed(json.dumps(seed_point))\n    print(f\"Seeded evaluation: {params} -&gt; {value}\")\n\n# External evaluations can arrive any time\non_external_evaluation({\"x\": 0.5}, 10.0, 1.0)\non_external_evaluation({\"x\": 0.25}, 8.5, 1.0)\n\n# Solver history now includes external data\nprint(f\"Total evaluations: {solver.get_history_len()}\")\n</code></pre>"},{"location":"documentation/cookbook/warm_starting/#key-points","title":"Key Points","text":"<p>Probe Budget</p> <p>The solver needs <code>budget \u00d7 probe_ratio</code> evaluations (default: 20%) to transition from Probe to Classify phase. Seed enough data to meet this threshold if you want to skip probing.</p> <p>eval_id Not Required</p> <p>Unlike <code>tell()</code>, the <code>seed()</code> method does not require <code>eval_id</code> in the input data. The solver assigns IDs automatically.</p> <p>Bounds Consistency</p> <p>Ensure seeded parameter values are within the configured bounds. The solver does not validate seeded data against bounds.</p>"},{"location":"documentation/integrations/","title":"Integrations","text":"<p>ArqonHPO integrates with your existing infrastructure.</p>"},{"location":"documentation/integrations/#monitoring-observability","title":"Monitoring &amp; Observability","text":"Integration Status Description Prometheus \u2705 Built-in Metrics via <code>--metrics-addr</code> Grafana \u2705 Compatible Use Prometheus data source OpenTelemetry \ud83d\udd1c Planned v0.4 roadmap <p>\u2192 Observability Guide</p>"},{"location":"documentation/integrations/#ml-frameworks","title":"ML Frameworks","text":"Integration Status Description Ray Tune \u2705 Custom Searcher Ray Guide MLflow \ud83d\udd1c Planned Tracking plugin Weights &amp; Biases \ud83d\udd1c Planned Callback"},{"location":"documentation/integrations/#web-frameworks","title":"Web Frameworks","text":"Integration Status Description FastAPI \u2705 Example FastAPI Guide Flask \u2705 Compatible Similar to FastAPI Django \u2705 Compatible Use management commands"},{"location":"documentation/integrations/#infrastructure","title":"Infrastructure","text":"Integration Status Description Kubernetes \u2705 Patterns K8s Guide Docker \u2705 Example See K8s guide Helm \ud83d\udd1c Planned Official chart in v0.4"},{"location":"documentation/integrations/#databases","title":"Databases","text":"<p>ArqonHPO stores state in JSON files by default. For persistent storage:</p> Integration Status Description Redis \u2705 Use <code>--state</code> Store state in Redis via wrapper PostgreSQL \u2705 Use artifacts Import/export via SQL S3 \u2705 Use artifacts Store artifacts in S3 <p>Example: S3 State Storage</p> <pre><code>import boto3\nimport json\nfrom arqonhpo import ArqonSolver\n\ns3 = boto3.client('s3')\n\ndef load_state(bucket, key):\n    resp = s3.get_object(Bucket=bucket, Key=key)\n    return resp['Body'].read().decode()\n\ndef save_state(bucket, key, state):\n    s3.put_object(Bucket=bucket, Key=key, Body=state)\n\n# Load existing or create new\ntry:\n    state = load_state('my-bucket', 'arqon/state.json')\n    solver = ArqonSolver.from_state(state)\nexcept:\n    solver = ArqonSolver(json.dumps(config))\n\n# ... optimization loop ...\n\n# Save state\nsave_state('my-bucket', 'arqon/state.json', solver.export())\n</code></pre>"},{"location":"documentation/integrations/#message-queues","title":"Message Queues","text":"Integration Status Description RabbitMQ \u2705 JSONL Use interactive mode Kafka \u2705 JSONL Use interactive mode Redis Streams \u2705 JSONL Use interactive mode <p>Example: RabbitMQ</p> <pre><code>import pika\nimport json\nimport subprocess\n\nconnection = pika.BlockingConnection()\nchannel = connection.channel()\n\nchannel.queue_declare(queue='arqon_ask')\nchannel.queue_declare(queue='arqon_results')\n\n# Start interactive mode\nproc = subprocess.Popen(\n    ['arqonhpo', 'interactive', '--config', 'config.json'],\n    stdin=subprocess.PIPE,\n    stdout=subprocess.PIPE\n)\n\ndef on_result(ch, method, props, body):\n    result = json.loads(body)\n    proc.stdin.write(json.dumps({\"cmd\": \"tell\", \"results\": [result]}).encode() + b'\\n')\n    proc.stdin.flush()\n\n    # Ask for next\n    proc.stdin.write(json.dumps({\"cmd\": \"ask\", \"batch\": 1}).encode() + b'\\n')\n    proc.stdin.flush()\n    response = proc.stdout.readline()\n\n    channel.basic_publish(exchange='', routing_key='arqon_ask', body=response)\n\nchannel.basic_consume(queue='arqon_results', on_message_callback=on_result)\nchannel.start_consuming()\n</code></pre>"},{"location":"documentation/integrations/#cicd","title":"CI/CD","text":"Integration Status Description GitHub Actions \u2705 CLI Run optimization in workflows GitLab CI \u2705 CLI Same as GitHub ArqonShip \u2705 Built-in Self-healing CI <p>\u2192 ArqonShip Docs</p>"},{"location":"documentation/integrations/#next-steps","title":"Next Steps","text":"<ul> <li>Kubernetes \u2014 Production deployment</li> <li>FastAPI \u2014 REST API service</li> <li>Ray Tune \u2014 Distributed optimization</li> </ul>"},{"location":"documentation/integrations/prometheus/","title":"Prometheus Integration","text":"<p>Detailed guide for monitoring ArqonHPO with Prometheus.</p>"},{"location":"documentation/integrations/prometheus/#enable-metrics","title":"Enable Metrics","text":""},{"location":"documentation/integrations/prometheus/#cli","title":"CLI","text":"<pre><code>arqonhpo --metrics-addr 127.0.0.1:9898 run --config config.json --script eval.sh\n</code></pre>"},{"location":"documentation/integrations/prometheus/#dashboard-server","title":"Dashboard Server","text":"<pre><code>arqonhpo dashboard --state state.json --metrics-addr 127.0.0.1:9898\n</code></pre> <p>Metrics available at: <code>http://127.0.0.1:9898/metrics</code></p>"},{"location":"documentation/integrations/prometheus/#prometheus-configuration","title":"Prometheus Configuration","text":"<p>Add to <code>prometheus.yml</code>:</p> <pre><code>scrape_configs:\n  - job_name: \"arqonhpo\"\n    static_configs:\n      - targets: [\"localhost:9898\"]\n    scrape_interval: 15s\n    metrics_path: /metrics\n</code></pre>"},{"location":"documentation/integrations/prometheus/#available-metrics","title":"Available Metrics","text":""},{"location":"documentation/integrations/prometheus/#counters","title":"Counters","text":"<pre><code># Total operations\narqonhpo_ask_calls_total\narqonhpo_tell_calls_total\narqonhpo_candidates_emitted_total\narqonhpo_results_ingested_total\n\n# Safety events\narqonhpo_violations_total{type=\"DeltaTooLarge\"}\narqonhpo_violations_total{type=\"RateLimitExceeded\"}\narqonhpo_violations_total{type=\"DirectionFlipViolation\"}\narqonhpo_rollbacks_total\n</code></pre>"},{"location":"documentation/integrations/prometheus/#gauges","title":"Gauges","text":"<pre><code># Current state\narqonhpo_history_len\narqonhpo_budget_remaining\narqonhpo_best_value\narqonhpo_config_generation\n\n# SPSA state\narqonhpo_spsa_iteration\narqonhpo_spsa_learning_rate\narqonhpo_spsa_perturbation_scale\n\n# Safety\narqonhpo_safe_mode_active  # 1 = in safe mode\n</code></pre>"},{"location":"documentation/integrations/prometheus/#histograms","title":"Histograms","text":"<pre><code># Latency distributions (seconds)\narqonhpo_eval_duration_seconds_bucket{le=\"0.001\"}\narqonhpo_eval_duration_seconds_bucket{le=\"0.01\"}\narqonhpo_eval_duration_seconds_bucket{le=\"0.1\"}\narqonhpo_eval_duration_seconds_bucket{le=\"1\"}\narqonhpo_eval_duration_seconds_bucket{le=\"10\"}\narqonhpo_eval_duration_seconds_bucket{le=\"+Inf\"}\n\narqonhpo_ask_duration_seconds_bucket\narqonhpo_apply_duration_seconds_bucket\n</code></pre>"},{"location":"documentation/integrations/prometheus/#promql-examples","title":"PromQL Examples","text":""},{"location":"documentation/integrations/prometheus/#throughput","title":"Throughput","text":"<pre><code># Evaluations per second\nrate(arqonhpo_tell_calls_total[5m])\n\n# Candidates per second\nrate(arqonhpo_candidates_emitted_total[5m])\n</code></pre>"},{"location":"documentation/integrations/prometheus/#latency","title":"Latency","text":"<pre><code># 50th percentile eval latency\nhistogram_quantile(0.5, rate(arqonhpo_eval_duration_seconds_bucket[5m]))\n\n# 99th percentile eval latency\nhistogram_quantile(0.99, rate(arqonhpo_eval_duration_seconds_bucket[5m]))\n\n# Average ask latency\nrate(arqonhpo_ask_duration_seconds_sum[5m]) / rate(arqonhpo_ask_duration_seconds_count[5m])\n</code></pre>"},{"location":"documentation/integrations/prometheus/#safety","title":"Safety","text":"<pre><code># Violation rate\nrate(arqonhpo_violations_total[5m])\n\n# Violations by type\nsum by (type) (rate(arqonhpo_violations_total[5m]))\n\n# Rollback frequency\nincrease(arqonhpo_rollbacks_total[1h])\n\n# Safe mode duration\nchanges(arqonhpo_safe_mode_active[1h])\n</code></pre>"},{"location":"documentation/integrations/prometheus/#progress","title":"Progress","text":"<pre><code># Budget consumption rate\nrate(arqonhpo_history_len[5m])\n\n# Time to completion (estimate)\narqonhpo_budget_remaining / rate(arqonhpo_history_len[5m])\n</code></pre>"},{"location":"documentation/integrations/prometheus/#grafana-dashboard","title":"Grafana Dashboard","text":""},{"location":"documentation/integrations/prometheus/#import-json","title":"Import JSON","text":"<pre><code>{\n  \"title\": \"ArqonHPO Monitoring\",\n  \"panels\": [\n    {\n      \"title\": \"Throughput\",\n      \"type\": \"graph\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(arqonhpo_tell_calls_total[5m])\",\n          \"legendFormat\": \"evals/s\"\n        }\n      ]\n    },\n    {\n      \"title\": \"Best Objective\",\n      \"type\": \"stat\",\n      \"targets\": [{ \"expr\": \"arqonhpo_best_value\", \"legendFormat\": \"best\" }]\n    },\n    {\n      \"title\": \"Eval Latency p99\",\n      \"type\": \"graph\",\n      \"targets\": [\n        {\n          \"expr\": \"histogram_quantile(0.99, rate(arqonhpo_eval_duration_seconds_bucket[5m]))\",\n          \"legendFormat\": \"p99\"\n        }\n      ]\n    },\n    {\n      \"title\": \"Violations\",\n      \"type\": \"graph\",\n      \"targets\": [\n        {\n          \"expr\": \"sum by (type) (rate(arqonhpo_violations_total[5m]))\",\n          \"legendFormat\": \"{{type}}\"\n        }\n      ]\n    },\n    {\n      \"title\": \"Budget Progress\",\n      \"type\": \"gauge\",\n      \"targets\": [\n        {\n          \"expr\": \"1 - (arqonhpo_budget_remaining / (arqonhpo_history_len + arqonhpo_budget_remaining))\",\n          \"legendFormat\": \"progress\"\n        }\n      ]\n    },\n    {\n      \"title\": \"Safe Mode\",\n      \"type\": \"stat\",\n      \"targets\": [\n        { \"expr\": \"arqonhpo_safe_mode_active\", \"legendFormat\": \"active\" }\n      ],\n      \"valueMappings\": [\n        { \"value\": 0, \"text\": \"Normal\", \"color\": \"green\" },\n        { \"value\": 1, \"text\": \"SAFE MODE\", \"color\": \"red\" }\n      ]\n    }\n  ]\n}\n</code></pre>"},{"location":"documentation/integrations/prometheus/#alerting-rules","title":"Alerting Rules","text":"<p>Add to Prometheus rules:</p> <pre><code>groups:\n  - name: arqonhpo\n    rules:\n      - alert: ArqonHighViolationRate\n        expr: rate(arqonhpo_violations_total[5m]) &gt; 0.1\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High violation rate in ArqonHPO\"\n          description: \"{{ $value }} violations/s over 5 minutes\"\n\n      - alert: ArqonSafeModeActive\n        expr: arqonhpo_safe_mode_active == 1\n        for: 1m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"ArqonHPO in safe mode\"\n          description: \"Optimization paused due to safety trigger\"\n\n      - alert: ArqonHighEvalLatency\n        expr: histogram_quantile(0.99, rate(arqonhpo_eval_duration_seconds_bucket[5m])) &gt; 60\n        for: 10m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High evaluation latency\"\n          description: \"p99 latency {{ $value }}s\"\n\n      - alert: ArqonStalled\n        expr: rate(arqonhpo_tell_calls_total[30m]) == 0\n        for: 30m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"ArqonHPO appears stalled\"\n          description: \"No evaluations in 30 minutes\"\n</code></pre>"},{"location":"documentation/integrations/prometheus/#kubernetes-servicemonitor","title":"Kubernetes ServiceMonitor","text":"<p>For Prometheus Operator:</p> <pre><code>apiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: arqonhpo\n  labels:\n    app: arqonhpo\nspec:\n  selector:\n    matchLabels:\n      app: arqonhpo\n  endpoints:\n    - port: metrics\n      interval: 15s\n      path: /metrics\n</code></pre>"},{"location":"documentation/integrations/prometheus/#next-steps","title":"Next Steps","text":"<ul> <li>Observability Overview \u2014 All observability features</li> <li>Dashboard \u2014 Web UI</li> <li>Kubernetes \u2014 K8s deployment</li> </ul>"},{"location":"documentation/reference/cli/","title":"CLI Reference","text":"<p>ArqonHPO provides a command-line interface for batch optimization, interactive ask/tell flows, and observability.</p>"},{"location":"documentation/reference/cli/#installation","title":"Installation","text":"<pre><code># From cargo\ncargo install --path crates/cli --bin arqonhpo-cli\n\n# Or use Python wrapper\npip install arqonhpo\npython -m arqonhpo --help\n</code></pre>"},{"location":"documentation/reference/cli/#commands","title":"Commands","text":""},{"location":"documentation/reference/cli/#run-batch-optimization","title":"<code>run</code> \u2014 Batch Optimization","text":"<p>Run a complete optimization loop with an evaluation script.</p> <pre><code>arqonhpo run --config config.json --script ./evaluate.sh --state state.json\n</code></pre> Flag Required Default Description <code>--config</code> \u2713 \u2014 Path to config JSON <code>--script</code> \u2713 \u2014 Path to evaluation script <code>--state</code> \u2717 \u2014 Path to state file (for resume) <p>Evaluation Script:</p> <p>The script receives parameters as environment variables prefixed with <code>ARQON_</code>:</p> <pre><code>#!/bin/bash\n# evaluate.sh\necho \"RESULT=$(python my_sim.py --x=$ARQON_x --y=$ARQON_y)\"\n</code></pre> <p>The script must print <code>RESULT=&lt;float&gt;</code> to stdout.</p>"},{"location":"documentation/reference/cli/#ask-request-candidates","title":"<code>ask</code> \u2014 Request Candidates","text":"<p>Request the next batch of candidate parameters.</p> <pre><code>arqonhpo ask --config config.json --state state.json --batch 4\n</code></pre> Flag Required Default Description <code>--config</code> \u2713 \u2014 Path to config JSON <code>--state</code> \u2717 \u2014 Path to state file <code>--batch</code> \u2717 1 Number of candidates to request <p>Output (stdout):</p> <pre><code>[\n  { \"x\": 0.4, \"y\": -1.2 },\n  { \"x\": 0.5, \"y\": -1.0 }\n]\n</code></pre> <p>Returns empty array <code>[]</code> if budget exhausted.</p>"},{"location":"documentation/reference/cli/#tell-report-results","title":"<code>tell</code> \u2014 Report Results","text":"<p>Report evaluation results back to the solver.</p> <pre><code>arqonhpo tell --state state.json --results results.json\n</code></pre> Flag Required Default Description <code>--state</code> \u2713 \u2014 Path to state file <code>--results</code> \u2717 stdin Path to results JSON (or read from stdin) <p>Results Schema:</p> <pre><code>[\n  {\n    \"params\": { \"x\": 0.4, \"y\": -1.2 },\n    \"value\": 0.12,\n    \"cost\": 1.0\n  }\n]\n</code></pre> Field Type Required Description <code>params</code> object \u2713 Parameter values <code>value</code> float \u2713 Objective value (minimize) <code>cost</code> float \u2717 Evaluation cost (default: 1.0)"},{"location":"documentation/reference/cli/#interactive-jsonl-mode","title":"<code>interactive</code> \u2014 JSONL Mode","text":"<p>Start an interactive JSONL session over stdin/stdout.</p> <pre><code>arqonhpo interactive --config config.json --state state.json\n</code></pre> <p>Protocol:</p> <pre><code>\u2192 {\"cmd\":\"ask\",\"batch\":2}\n\u2190 {\"params\":[{\"x\":0.4,\"y\":-1.2},{\"x\":0.5,\"y\":-1.0}]}\n\n\u2192 {\"cmd\":\"tell\",\"results\":[{\"params\":{\"x\":0.4,\"y\":-1.2},\"value\":0.12,\"cost\":1.0}]}\n\u2190 {\"ok\":true}\n</code></pre> <p>Commands:</p> Command Fields Response <code>{\"cmd\":\"ask\",\"batch\":N}</code> <code>batch</code> (optional) <code>{\"params\":[...]}</code> or <code>{\"done\":true}</code> <code>{\"cmd\":\"tell\",\"results\":[...]}</code> <code>results</code> (required) <code>{\"ok\":true}</code> <code>{\"cmd\":\"status\"}</code> \u2014 <code>{\"history_len\":N,\"budget_remaining\":M}</code>"},{"location":"documentation/reference/cli/#validate-validate-config","title":"<code>validate</code> \u2014 Validate Config","text":"<p>Check a config file for errors without running optimization.</p> <pre><code>arqonhpo validate --config config.json\n</code></pre> <p>Output:</p> <pre><code>\u2713 Config valid: 2 parameters, budget=100\n</code></pre> <p>Or on error:</p> <pre><code>\u2717 Error: bounds.x.min must be less than bounds.x.max\n</code></pre>"},{"location":"documentation/reference/cli/#export-export-artifact","title":"<code>export</code> \u2014 Export Artifact","text":"<p>Export solver state as a portable artifact for replay.</p> <pre><code>arqonhpo export --state state.json --output artifact.json --run-id my-experiment\n</code></pre> Flag Required Default Description <code>--state</code> \u2713 \u2014 Path to state file <code>--output</code> \u2717 stdout Output path <code>--run-id</code> \u2717 UUID Run identifier <p>Artifact Schema:</p> <pre><code>{\n  \"run_id\": \"my-experiment\",\n  \"timestamp\": \"2026-01-09T12:00:00Z\",\n  \"config\": { ... },\n  \"history\": [\n    {\"eval_id\": 0, \"params\": {...}, \"value\": 0.5, \"cost\": 1.0}\n  ]\n}\n</code></pre>"},{"location":"documentation/reference/cli/#import-import-artifact","title":"<code>import</code> \u2014 Import Artifact","text":"<p>Import a previously exported artifact to resume or replay.</p> <pre><code>arqonhpo import --artifact artifact.json --state state.json\n</code></pre> Flag Required Default Description <code>--artifact</code> \u2713 \u2014 Path to artifact JSON <code>--state</code> \u2713 \u2014 Output state file path"},{"location":"documentation/reference/cli/#tui-terminal-dashboard","title":"<code>tui</code> \u2014 Terminal Dashboard","text":"<p>Launch the terminal UI for real-time monitoring.</p> <pre><code>arqonhpo tui --state state.json --events events.jsonl --refresh-ms 500\n</code></pre> Flag Required Default Description <code>--state</code> \u2713 \u2014 Path to state file <code>--events</code> \u2717 \u2014 Path to events log <code>--refresh-ms</code> \u2717 500 Refresh interval <p>See TUI Reference for keybindings and interface details.</p>"},{"location":"documentation/reference/cli/#dashboard-web-dashboard","title":"<code>dashboard</code> \u2014 Web Dashboard","text":"<p>Launch the web-based monitoring dashboard.</p> <pre><code>arqonhpo dashboard --state state.json --addr 127.0.0.1:3030\n</code></pre> Flag Required Default Description <code>--state</code> \u2713 \u2014 Path to state file <code>--events</code> \u2717 \u2014 Path to events log <code>--actions</code> \u2717 \u2014 Path to actions log <code>--addr</code> \u2717 127.0.0.1:3030 Bind address <p>See Dashboard Reference for REST API endpoints.</p>"},{"location":"documentation/reference/cli/#global-options","title":"Global Options","text":"Flag Values Default Description <code>--log-format</code> <code>pretty</code>, <code>json</code> <code>pretty</code> Log output format <code>--log-level</code> <code>error</code>, <code>warn</code>, <code>info</code>, <code>debug</code>, <code>trace</code> <code>info</code> Log verbosity <code>--metrics-addr</code> <code>HOST:PORT</code> \u2014 Prometheus metrics endpoint <p>Example:</p> <pre><code>arqonhpo --log-format json --log-level debug --metrics-addr 127.0.0.1:9898 run ...\n</code></pre>"},{"location":"documentation/reference/cli/#environment-variables","title":"Environment Variables","text":"Variable Description <code>ARQON_LOG_LEVEL</code> Override log level <code>ARQON_LOG_FORMAT</code> Override log format <code>ARQON_&lt;param&gt;</code> Parameter value (set during script execution)"},{"location":"documentation/reference/cli/#exit-codes","title":"Exit Codes","text":"Code Meaning <code>0</code> Success <code>1</code> General error (invalid config, IO error) <code>2</code> Config validation error <code>3</code> State file error (corrupt, incompatible) <code>10</code> Budget exhausted <code>20</code> Script execution failed <code>130</code> Interrupted (SIGINT)"},{"location":"documentation/reference/cli/#config-file-schema","title":"Config File Schema","text":"<pre><code>{\n  \"seed\": 42,\n  \"budget\": 100,\n  \"bounds\": {\n    \"x\": { \"min\": -5, \"max\": 5, \"scale\": \"Linear\" },\n    \"y\": { \"min\": 0.01, \"max\": 100, \"scale\": \"Log\" }\n  },\n  \"probe_ratio\": 0.2,\n  \"batch_size\": 4,\n  \"strategy\": null,\n  \"strategy_params\": {}\n}\n</code></pre> Field Type Required Default Description <code>seed</code> int \u2713 \u2014 RNG seed for reproducibility <code>budget</code> int \u2713 \u2014 Max evaluations <code>bounds</code> object \u2713 \u2014 Parameter bounds <code>bounds.&lt;name&gt;.min</code> float \u2713 \u2014 Minimum value <code>bounds.&lt;name&gt;.max</code> float \u2713 \u2014 Maximum value <code>bounds.&lt;name&gt;.scale</code> string \u2717 <code>Linear</code> <code>Linear</code>, <code>Log</code>, <code>Periodic</code> <code>probe_ratio</code> float \u2717 0.2 Fraction for probing <code>batch_size</code> int \u2717 4 Candidates per ask <code>strategy</code> string \u2717 auto Force strategy: <code>nelder_mead</code>, <code>multi_start_nm</code>, <code>tpe</code> <code>strategy_params</code> object \u2717 {} Strategy-specific params"},{"location":"documentation/reference/cli/#state-file","title":"State File","text":"<p>The state file persists solver state between commands. It's updated by <code>ask</code> and <code>tell</code>.</p> <p>[!WARNING] Do not manually edit state files. Use <code>import</code>/<code>export</code> for portability.</p>"},{"location":"documentation/reference/cli/#next-steps","title":"Next Steps","text":"<ul> <li>TUI Reference \u2014 Terminal monitoring</li> <li>Dashboard Reference \u2014 Web monitoring</li> <li>Python API \u2014 Programmatic access</li> </ul>"},{"location":"documentation/reference/dashboard/","title":"Dashboard Reference","text":"<p>The ArqonHPO Dashboard is a web-based UI for monitoring and interacting with running optimization jobs.</p> <p></p>"},{"location":"documentation/reference/dashboard/#starting-the-dashboard","title":"Starting the Dashboard","text":"<pre><code>arqonhpo dashboard --state state.json --addr 127.0.0.1:3030\n</code></pre>"},{"location":"documentation/reference/dashboard/#options","title":"Options","text":"Flag Default Description <code>--state</code> (required) Path to solver state file <code>--events</code> (optional) Path to events log file <code>--actions</code> (optional) Path to actions log file <code>--addr</code> <code>127.0.0.1:3030</code> Address to bind HTTP server <p>Then open <code>http://127.0.0.1:3030</code> in your browser.</p>"},{"location":"documentation/reference/dashboard/#interface-overview","title":"Interface Overview","text":"<p>The dashboard provides:</p> <ul> <li>Status Panel \u2014 Current phase, budget usage, best value</li> <li>Parameters Table \u2014 Current best parameters</li> <li>History Chart \u2014 Objective value over iterations</li> <li>Event Log \u2014 Real-time event stream</li> <li>Actions Panel \u2014 Send commands to the solver</li> </ul>"},{"location":"documentation/reference/dashboard/#rest-api-endpoints","title":"REST API Endpoints","text":"<p>The dashboard serves a REST API for programmatic access:</p>"},{"location":"documentation/reference/dashboard/#get-apistate","title":"GET /api/state","text":"<p>Returns the full solver state.</p> <pre><code>curl http://127.0.0.1:3030/api/state\n</code></pre> <p>Response:</p> <pre><code>{\n  \"config\": {\n    \"seed\": 42,\n    \"budget\": 100,\n    \"bounds\": { ... }\n  },\n  \"history\": [\n    {\"params\": {\"x\": 0.5}, \"value\": 1.23, \"cost\": 1.0},\n    ...\n  ],\n  \"phase\": \"Refine\",\n  \"best_idx\": 42\n}\n</code></pre>"},{"location":"documentation/reference/dashboard/#get-apisummary","title":"GET /api/summary","text":"<p>Returns a compact summary of optimization progress.</p> <pre><code>curl http://127.0.0.1:3030/api/summary\n</code></pre> <p>Response:</p> <pre><code>{\n  \"phase\": \"Refine\",\n  \"budget_used\": 45,\n  \"budget_total\": 100,\n  \"best_value\": 0.0234,\n  \"best_params\": { \"x\": 1.98, \"y\": -0.99 },\n  \"history_len\": 45\n}\n</code></pre>"},{"location":"documentation/reference/dashboard/#get-apievents","title":"GET /api/events","text":"<p>Returns recent events from the events log.</p> <pre><code>curl \"http://127.0.0.1:3030/api/events?since=1704067200\"\n</code></pre> <p>Query Parameters:</p> Param Type Description <code>since</code> int Unix timestamp, return events after this time <code>limit</code> int Maximum events to return (default: 100) <p>Response:</p> <pre><code>{\n  \"events\": [\n    { \"ts\": 1704067201, \"type\": \"ask\", \"batch\": 4 },\n    { \"ts\": 1704067202, \"type\": \"tell\", \"count\": 4 }\n  ]\n}\n</code></pre>"},{"location":"documentation/reference/dashboard/#get-apiactions","title":"GET /api/actions","text":"<p>Returns recent actions from the actions log.</p> <pre><code>curl \"http://127.0.0.1:3030/api/actions?since=0\"\n</code></pre> <p>Response:</p> <pre><code>{\n  \"actions\": [\n    { \"ts\": 1704067300, \"type\": \"pause\" },\n    { \"ts\": 1704067400, \"type\": \"resume\" }\n  ]\n}\n</code></pre>"},{"location":"documentation/reference/dashboard/#post-apiactions","title":"POST /api/actions","text":"<p>Send an action to the solver.</p> <pre><code>curl -X POST http://127.0.0.1:3030/api/actions \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"type\": \"pause\"}'\n</code></pre> <p>Action Types:</p> Type Description <code>pause</code> Pause optimization <code>resume</code> Resume optimization <code>stop</code> Stop optimization (cannot resume) <code>rollback</code> Revert to previous best <p>Response:</p> <pre><code>{ \"ok\": true, \"message\": \"Action queued\" }\n</code></pre>"},{"location":"documentation/reference/dashboard/#security-considerations","title":"Security Considerations","text":"<p>[!WARNING] The dashboard does not have authentication. Bind only to <code>127.0.0.1</code> or use a reverse proxy with auth.</p> <p>For production use:</p> <pre><code># Behind nginx with basic auth\narqonhpo dashboard --state state.json --addr 127.0.0.1:3030\n</code></pre>"},{"location":"documentation/reference/dashboard/#prometheus-metrics","title":"Prometheus Metrics","text":"<p>The dashboard also exposes Prometheus metrics if <code>--metrics-addr</code> is set:</p> <pre><code>arqonhpo dashboard --state state.json --addr 127.0.0.1:3030 --metrics-addr 127.0.0.1:9898\n</code></pre> <p>Then scrape <code>http://127.0.0.1:9898/metrics</code>.</p>"},{"location":"documentation/reference/dashboard/#next-steps","title":"Next Steps","text":"<ul> <li>TUI Reference \u2014 Terminal-based monitoring</li> <li>Observability \u2014 Prometheus metrics</li> <li>CLI Reference \u2014 Full CLI documentation</li> </ul>"},{"location":"documentation/reference/error_codes/","title":"Error Codes Reference","text":"<p>This page documents all error codes, exceptions, and common error messages in ArqonHPO.</p>"},{"location":"documentation/reference/error_codes/#cli-exit-codes","title":"CLI Exit Codes","text":"Code Name Description <code>0</code> Success Command completed successfully <code>1</code> GeneralError Unspecified error (check message) <code>2</code> ConfigError Config validation failed <code>3</code> StateError State file corrupt or incompatible <code>10</code> BudgetExhausted Optimization budget exhausted <code>20</code> ScriptError Evaluation script failed <code>130</code> Interrupted Process interrupted (Ctrl+C) <p>Example handling:</p> <pre><code>arqonhpo run --config config.json --script ./eval.sh\ncase $? in\n  0) echo \"Optimization complete\" ;;\n  2) echo \"Fix your config file\" ;;\n  10) echo \"Budget exhausted - optimization finished\" ;;\n  20) echo \"Evaluation script failed\" ;;\n  *) echo \"Error: $?\" ;;\nesac\n</code></pre>"},{"location":"documentation/reference/error_codes/#python-exceptions","title":"Python Exceptions","text":"<p>All ArqonHPO Python exceptions inherit from <code>ArqonError</code>.</p> Exception When Raised Example <code>ValueError</code> Invalid config JSON Missing required field <code>RuntimeError</code> Internal Rust panic Unexpected state <code>TypeError</code> Wrong argument type Non-string passed to constructor <p>Example handling:</p> <pre><code>from arqonhpo import ArqonSolver\nimport json\n\ntry:\n    solver = ArqonSolver(json.dumps({\"seed\": 42}))  # Missing budget!\nexcept ValueError as e:\n    print(f\"Config error: {e}\")\n    # Output: Config error: missing field `budget`\n</code></pre>"},{"location":"documentation/reference/error_codes/#config-validation-errors","title":"Config Validation Errors","text":"<p>Errors returned by <code>arqonhpo validate</code> or when constructing <code>ArqonSolver</code>:</p> Error Message Cause Fix <code>missing field 'seed'</code> Required field missing Add <code>\"seed\": 42</code> <code>missing field 'budget'</code> Required field missing Add <code>\"budget\": 100</code> <code>missing field 'bounds'</code> Required field missing Add bounds object <code>bounds.X.min &gt;= bounds.X.max</code> Invalid range Ensure min &lt; max <code>invalid scale 'Foo'</code> Unknown scale type Use <code>Linear</code>, <code>Log</code>, or <code>Periodic</code> <code>budget must be &gt; 0</code> Zero or negative budget Use positive integer <code>seed must be u64</code> Seed too large/negative Use 0 to 2^64-1 <code>probe_ratio must be in [0, 1]</code> Invalid ratio Use value 0.0-1.0"},{"location":"documentation/reference/error_codes/#tellseed-errors","title":"Tell/Seed Errors","text":"<p>Errors when calling <code>tell()</code> or <code>seed()</code>:</p> Error Message Cause Fix <code>invalid JSON</code> Malformed JSON string Validate JSON syntax <code>expected array</code> Root is not array Wrap results in <code>[...]</code> <code>missing field 'params'</code> Result missing params Add params object <code>missing field 'value'</code> Result missing objective Add value field <code>param X not in bounds</code> Unknown parameter Check param names <code>duplicate eval_id N</code> IDs not unique Use unique IDs in tell()"},{"location":"documentation/reference/error_codes/#rust-error-types","title":"Rust Error Types","text":"<p>For Rust users, errors are returned as <code>Result&lt;T, Error&gt;</code>:</p>"},{"location":"documentation/reference/error_codes/#core-crate","title":"Core Crate","text":"<pre><code>pub enum SolverError {\n    /// Config validation failed\n    ConfigError(String),\n\n    /// State is corrupt\n    StateError(String),\n\n    /// Budget exhausted\n    BudgetExhausted,\n\n    /// Invalid results\n    ResultError(String),\n}\n</code></pre>"},{"location":"documentation/reference/error_codes/#hotpath-crate","title":"Hotpath Crate","text":"<pre><code>pub enum Violation {\n    DeltaTooLarge,\n    RateLimitExceeded,\n    DirectionFlipViolation,\n    CumulativeDeltaViolation,\n    InSafeMode,\n    AuditQueueFull,\n    NoBaseline,\n}\n</code></pre> <p>See Hotpath API Reference for violation details.</p>"},{"location":"documentation/reference/error_codes/#dashboard-api-errors","title":"Dashboard API Errors","text":"<p>HTTP errors from the dashboard REST API:</p> Status Endpoint Cause <code>404</code> Any Invalid endpoint path <code>400</code> POST /api/actions Invalid action JSON <code>500</code> Any Internal server error"},{"location":"documentation/reference/error_codes/#common-runtime-issues","title":"Common Runtime Issues","text":""},{"location":"documentation/reference/error_codes/#no-candidates-returned","title":"\"No candidates returned\"","text":"<p>Problem: <code>ask()</code> or <code>ask_one()</code> returns <code>None</code> immediately.</p> <p>Causes:</p> <ol> <li>Budget already exhausted</li> <li>Config has 0 budget</li> </ol> <p>Solution:</p> <pre><code>print(f\"Budget: {solver.get_history_len()}\")\n</code></pre>"},{"location":"documentation/reference/error_codes/#import-failed-incompatible-version","title":"\"Import failed: incompatible version\"","text":"<p>Problem: Artifact from different ArqonHPO version.</p> <p>Solution: Re-export with current version or use migration guide.</p>"},{"location":"documentation/reference/error_codes/#state-file-locked","title":"\"State file locked\"","text":"<p>Problem: Another process is using the state file.</p> <p>Solution: Ensure only one process uses state file at a time.</p>"},{"location":"documentation/reference/error_codes/#next-steps","title":"Next Steps","text":"<ul> <li>Troubleshooting \u2014 Full troubleshooting guide</li> <li>CLI Reference \u2014 Command documentation</li> <li>Hotpath API \u2014 Violation handling</li> </ul>"},{"location":"documentation/reference/hotpath/","title":"Hotpath API Reference","text":"<p>The <code>hotpath</code> crate contains the safety-critical, lock-free components for real-time parameter updates. These are the core internals that enforce governance on every configuration change.</p> <p>[!CAUTION] This is low-level API. Most users should use <code>ArqonSolver</code> (Python) or <code>Solver</code> (Rust core) instead. Direct hotpath usage is for embedding ArqonHPO in control loops.</p>"},{"location":"documentation/reference/hotpath/#architecture-overview","title":"Architecture Overview","text":"<pre><code>graph TD\n    T[Telemetry] --&gt; D[TelemetryDigest]\n    D --&gt; P[AdaptiveProposer/SPSA]\n    P --&gt; |Proposal| E[SafetyExecutor]\n    E --&gt; |Check| G[Guardrails]\n    E --&gt; |Check| CS[ControlSafety]\n    E --&gt; |Apply| AC[AtomicConfig]\n    E --&gt; |Log| AQ[AuditQueue]\n    E --&gt; |Rollback| RP[RollbackPolicy]</code></pre>"},{"location":"documentation/reference/hotpath/#safetyexecutor","title":"SafetyExecutor","text":"<p>File: <code>executor.rs</code> Constitution: II.17 \u2014 Safety Executor Contract</p> <p>The <code>SafetyExecutor</code> is the SOLE actuator that may modify production config. Every proposal passes through guardrails before apply.</p>"},{"location":"documentation/reference/hotpath/#struct","title":"Struct","text":"<pre><code>pub struct SafetyExecutor {\n    config: Arc&lt;AtomicConfig&gt;,\n    guardrails: Guardrails,\n    control_safety: ControlSafety,\n    rollback_policy: RollbackPolicy,\n    baseline: Option&lt;ConfigSnapshot&gt;,\n    audit_queue: AuditQueue,\n    // ... internal state\n}\n</code></pre>"},{"location":"documentation/reference/hotpath/#trait-safeexecutor","title":"Trait: SafeExecutor","text":"<pre><code>pub trait SafeExecutor {\n    /// Apply a proposal through safety guardrails.\n    fn apply(&amp;mut self, proposal: Proposal) -&gt; Result&lt;ApplyReceipt, Violation&gt;;\n\n    /// Rollback to baseline configuration.\n    fn rollback(&amp;mut self) -&gt; Result&lt;RollbackReceipt, Violation&gt;;\n\n    /// Set current config as baseline for future rollbacks.\n    fn set_baseline(&amp;mut self);\n\n    /// Get current config snapshot (zero-copy).\n    fn snapshot(&amp;self) -&gt; ConfigSnapshot;\n}\n</code></pre>"},{"location":"documentation/reference/hotpath/#usage","title":"Usage","text":"<pre><code>use hotpath::{SafetyExecutor, Guardrails, AtomicConfig, Proposal, ParamVec};\nuse std::sync::Arc;\n\nlet config = Arc::new(AtomicConfig::new(ParamVec::from_slice(&amp;[0.5, 0.5])));\nlet mut executor = SafetyExecutor::new(config.clone(), Guardrails::default());\n\n// Set baseline for rollback\nexecutor.set_baseline();\n\n// Apply a proposal\nlet proposal = Proposal::Update {\n    iteration: 1,\n    delta: ParamVec::from_slice(&amp;[0.01, -0.01]),\n    gradient_estimate: ParamVec::from_slice(&amp;[0.1, -0.1]),\n};\n\nmatch executor.apply(proposal) {\n    Ok(receipt) =&gt; println!(\"Applied, gen={}\", receipt.new_generation),\n    Err(violation) =&gt; println!(\"Rejected: {:?}\", violation),\n}\n</code></pre>"},{"location":"documentation/reference/hotpath/#guardrails","title":"Guardrails","text":"<p>File: <code>executor.rs</code></p> <p>Guardrails define the safety envelope for parameter updates.</p>"},{"location":"documentation/reference/hotpath/#struct_1","title":"Struct","text":"<pre><code>pub struct Guardrails {\n    /// Maximum delta per parameter per step (fraction: 0.0-1.0)\n    pub max_delta_per_step: f64,\n\n    /// Maximum updates per second\n    pub max_updates_per_second: f64,\n\n    /// Minimum interval between updates (microseconds)\n    pub min_interval_us: u64,\n\n    /// Maximum direction flips per dimension per minute\n    pub direction_flip_limit: u32,\n\n    /// Cooldown after hitting flip limit (microseconds)\n    pub cooldown_after_flip_us: u64,\n\n    /// Maximum cumulative delta per dimension per minute\n    pub max_cumulative_delta_per_minute: f64,\n\n    /// Consecutive regressions before SafeMode\n    pub regression_count_limit: u32,\n\n    /// Per-parameter bounds: [(min, max), ...]\n    pub bounds: Option&lt;Vec&lt;(f64, f64)&gt;&gt;,\n}\n</code></pre>"},{"location":"documentation/reference/hotpath/#presets","title":"Presets","text":"Preset <code>max_delta</code> <code>updates/s</code> <code>min_interval</code> <code>flip_limit</code> <code>Conservative</code> 0.05 2 500ms 2 <code>Balanced</code> (default) 0.10 10 100ms 3 <code>Aggressive</code> 0.20 20 50ms 5 <pre><code>let guardrails = Guardrails::preset_conservative();\nlet guardrails = Guardrails::preset_balanced();\nlet guardrails = Guardrails::preset_aggressive();\n</code></pre>"},{"location":"documentation/reference/hotpath/#rollbackpolicy","title":"RollbackPolicy","text":"<p>File: <code>executor.rs</code></p> <p>Defines when to automatically revert to baseline.</p>"},{"location":"documentation/reference/hotpath/#struct_2","title":"Struct","text":"<pre><code>pub struct RollbackPolicy {\n    /// Roll back after N consecutive worse results\n    pub max_consecutive_regressions: u32,\n\n    /// Circuit breaker: max rollbacks per hour\n    pub max_rollbacks_per_hour: u32,\n\n    /// Must be stable for N \u03bcs before new updates\n    pub min_stable_time_us: u64,\n}\n</code></pre>"},{"location":"documentation/reference/hotpath/#presets_1","title":"Presets","text":"Preset <code>max_regressions</code> <code>rollbacks/hour</code> <code>stable_time</code> <code>Conservative</code> 2 2 30s <code>Balanced</code> 3 4 5s <code>Aggressive</code> 5 10 1s"},{"location":"documentation/reference/hotpath/#violation","title":"Violation","text":"<p>File: <code>executor.rs</code></p> <p>Reasons why a proposal was rejected.</p> <pre><code>pub enum Violation {\n    /// Delta exceeds max_delta_per_step\n    DeltaTooLarge,\n\n    /// Update rate exceeded\n    RateLimitExceeded,\n\n    /// Direction changed too many times\n    DirectionFlipViolation,\n\n    /// Cumulative change too large\n    CumulativeDeltaViolation,\n\n    /// System in safe mode\n    InSafeMode,\n\n    /// Internal: audit queue is full\n    AuditQueueFull,\n\n    /// No baseline set for rollback\n    NoBaseline,\n}\n</code></pre>"},{"location":"documentation/reference/hotpath/#proposal","title":"Proposal","text":"<p>File: <code>proposer.rs</code></p> <p>The output of the adaptive proposer.</p> <pre><code>pub enum Proposal {\n    /// No change needed\n    NoChange { reason: NoChangeReason },\n\n    /// Apply +\u0394 perturbation (SPSA phase 1)\n    ApplyPlus {\n        perturbation_id: u64,\n        delta: ParamVec\n    },\n\n    /// Apply \u2212\u0394 perturbation (SPSA phase 2)\n    ApplyMinus {\n        perturbation_id: u64,\n        delta: ParamVec\n    },\n\n    /// Final update after SPSA gradient estimation\n    Update {\n        iteration: u64,\n        delta: ParamVec,\n        gradient_estimate: ParamVec\n    },\n}\n</code></pre>"},{"location":"documentation/reference/hotpath/#spsa-simultaneous-perturbation-stochastic-approximation","title":"SPSA (Simultaneous Perturbation Stochastic Approximation)","text":"<p>File: <code>spsa.rs</code> Constitution: II.16 \u2014 SPSA MUST use \u00b11 Bernoulli perturbations, ChaCha8Rng</p> <p>SPSA is the gradient-free optimizer for real-time control.</p>"},{"location":"documentation/reference/hotpath/#state-machine","title":"State Machine","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; Ready\n    Ready --&gt; WaitingPlus: generate_perturbation()\n    WaitingPlus --&gt; WaitingMinus: complete_eval_window()\n    WaitingMinus --&gt; Ready: complete_eval_window() \u2192 gradient</code></pre>"},{"location":"documentation/reference/hotpath/#spsastate","title":"SpsaState","text":"<pre><code>pub enum SpsaState {\n    /// Ready to start new iteration\n    Ready,\n\n    /// Applied +\u0394, collecting objective samples\n    WaitingPlus {\n        perturbation_id: u64,\n        delta: ParamVec,\n        accumulated: Vec&lt;f64&gt;,\n    },\n\n    /// Applied \u2212\u0394, collecting objective samples\n    WaitingMinus {\n        perturbation_id: u64,\n        delta: ParamVec,\n        y_plus: f64,\n        accumulated: Vec&lt;f64&gt;,\n    },\n}\n</code></pre>"},{"location":"documentation/reference/hotpath/#spsaconfig","title":"SpsaConfig","text":"<pre><code>pub struct SpsaConfig {\n    /// Minimum digests to collect per perturbation\n    pub eval_window_digests: usize,    // Default: 5\n\n    /// Maximum time to wait for digests (\u03bcs)\n    pub eval_window_us: u64,            // Default: 500_000\n\n    /// Settle time after apply before counting (\u03bcs)\n    pub settle_time_us: u64,            // Default: 10_000\n\n    /// Learning rate decay exponent: a_k = a\u2080 / (k+1+A)^\u03b1\n    pub alpha: f64,                      // Default: 0.602\n\n    /// Perturbation decay exponent: c_k = c\u2080 / (k+1)^\u03b3\n    pub gamma: f64,                      // Default: 0.101\n\n    /// Stability constant A\n    pub stability_a: f64,                // Default: 10.0\n}\n</code></pre>"},{"location":"documentation/reference/hotpath/#key-methods","title":"Key Methods","text":"<pre><code>impl Spsa {\n    /// Create new SPSA optimizer\n    pub fn new(\n        seed: u64,\n        num_params: usize,\n        learning_rate: f64,\n        perturbation_scale: f64,\n        config: SpsaConfig,\n    ) -&gt; Self;\n\n    /// Generate \u00b11 Bernoulli perturbation vector\n    pub fn generate_perturbation(&amp;mut self) -&gt; ParamVec;\n\n    /// Record objective value from current window\n    pub fn record_objective(&amp;mut self, value: f64);\n\n    /// Check if eval window has enough samples\n    pub fn has_enough_samples(&amp;self) -&gt; bool;\n\n    /// Complete window, compute gradient if in WaitingMinus\n    pub fn complete_eval_window(&amp;mut self) -&gt; Option&lt;(ParamVec, ParamVec)&gt;;\n\n    /// Current learning rate for iteration k\n    pub fn learning_rate(&amp;self, k: u64) -&gt; f64;\n\n    /// Current perturbation scale for iteration k\n    pub fn perturbation_scale(&amp;self, k: u64) -&gt; f64;\n}\n</code></pre>"},{"location":"documentation/reference/hotpath/#adaptiveengine","title":"AdaptiveEngine","text":"<p>File: <code>orchestrator.rs</code> Constitution: II.16-23 \u2014 Tier 2 Adaptive Engine</p> <p>The high-level orchestrator combining SPSA, Proposer, and Executor.</p>"},{"location":"documentation/reference/hotpath/#struct_3","title":"Struct","text":"<pre><code>pub struct AdaptiveEngine {\n    proposer: SpsaProposer,\n    config: Arc&lt;AtomicConfig&gt;,\n    executor: SafetyExecutor,\n}\n</code></pre>"},{"location":"documentation/reference/hotpath/#adaptiveengineconfig","title":"AdaptiveEngineConfig","text":"<pre><code>pub struct AdaptiveEngineConfig {\n    pub spsa: SpsaConfig,\n    pub guardrails: Guardrails,\n    pub seed: u64,\n    pub learning_rate: f64,\n    pub perturbation_scale: f64,\n}\n</code></pre>"},{"location":"documentation/reference/hotpath/#usage_1","title":"Usage","text":"<pre><code>use hotpath::{AdaptiveEngine, AdaptiveEngineConfig, ParamVec, TelemetryDigest};\n\nlet config = AdaptiveEngineConfig::default();\nlet initial_params = ParamVec::from_slice(&amp;[0.5, 0.5]);\nlet mut engine = AdaptiveEngine::new(config, initial_params);\n\n// Control loop\nloop {\n    let digest = TelemetryDigest::new(latency_us, objective, sample_count);\n\n    match engine.observe(digest) {\n        Ok(Proposal::Update { delta, .. }) =&gt; {\n            engine.apply(Proposal::Update { ... })?;\n        }\n        Ok(Proposal::NoChange { .. }) =&gt; continue,\n        Err(e) =&gt; eprintln!(\"Error: {:?}\", e),\n    }\n}\n</code></pre>"},{"location":"documentation/reference/hotpath/#telemetrydigest","title":"TelemetryDigest","text":"<p>File: <code>telemetry.rs</code></p> <p>Compressed telemetry snapshot passed to proposer.</p> <pre><code>pub struct TelemetryDigest {\n    pub window_us: u64,        // Observation window duration\n    pub objective_value: f64,  // Mean objective in window\n    pub sample_count: u64,     // Number of samples\n}\n\nimpl TelemetryDigest {\n    pub fn new(window_us: u64, objective_value: f64, sample_count: u64) -&gt; Self;\n}\n</code></pre>"},{"location":"documentation/reference/hotpath/#atomicconfig","title":"AtomicConfig","text":"<p>File: <code>config_atomic.rs</code></p> <p>Lock-free, atomically swappable configuration.</p> <pre><code>pub struct AtomicConfig {\n    // Uses Arc swap for lock-free reads\n}\n\nimpl AtomicConfig {\n    pub fn new(initial: ParamVec) -&gt; Self;\n    pub fn snapshot(&amp;self) -&gt; Arc&lt;ConfigSnapshot&gt;;\n    pub fn update(&amp;self, new_params: ParamVec) -&gt; u64;  // Returns new generation\n}\n\npub struct ConfigSnapshot {\n    pub generation: u64,\n    pub params: ParamVec,\n}\n</code></pre>"},{"location":"documentation/reference/hotpath/#auditqueue","title":"AuditQueue","text":"<p>File: <code>audit.rs</code></p> <p>Lock-free queue for audit events.</p> <pre><code>pub struct AuditQueue {\n    // Bounded, lock-free queue using crossbeam\n}\n\nimpl AuditQueue {\n    pub fn new(capacity: usize) -&gt; Self;\n    pub fn enqueue(&amp;self, event: AuditEvent) -&gt; EnqueueResult;\n    pub fn try_dequeue(&amp;self) -&gt; Option&lt;AuditEvent&gt;;\n}\n\npub struct AuditEvent {\n    pub timestamp_us: u64,\n    pub event_type: EventType,\n    pub generation: u64,\n    pub details: String,\n}\n</code></pre>"},{"location":"documentation/reference/hotpath/#performance-characteristics","title":"Performance Characteristics","text":"Operation Latency Lock-free <code>snapshot()</code> O(1) \u2705 <code>apply()</code> ~100\u03bcs \u26a0\ufe0f CAS loop <code>enqueue()</code> O(1) \u2705 <code>generate_perturbation()</code> O(n_params) \u2705"},{"location":"documentation/reference/hotpath/#next-steps","title":"Next Steps","text":"<ul> <li>Safety Concepts \u2014 High-level safety patterns</li> <li>Strategies \u2014 PCR optimizer strategies</li> <li>Rust Core API \u2014 High-level Solver API</li> </ul>"},{"location":"documentation/reference/observability/","title":"Observability","text":"<p>ArqonHPO provides comprehensive observability through structured logs, Prometheus metrics, and real-time dashboards.</p>"},{"location":"documentation/reference/observability/#structured-logs","title":"Structured Logs","text":"<p>The CLI uses <code>tracing</code> and emits structured logs to stderr.</p>"},{"location":"documentation/reference/observability/#enable-json-output","title":"Enable JSON Output","text":"<pre><code>arqonhpo --log-format json --log-level info &lt;command&gt;\n</code></pre>"},{"location":"documentation/reference/observability/#log-levels","title":"Log Levels","text":"Level Content <code>error</code> Failures only <code>warn</code> Violations, guardrail triggers <code>info</code> Ask/tell events, phase changes <code>debug</code> Strategy decisions, proposal details <code>trace</code> SPSA iterations, config snapshots"},{"location":"documentation/reference/observability/#log-fields","title":"Log Fields","text":"Field Description <code>command</code> Current CLI command <code>config</code> Path to config file <code>state</code> Path to state file <code>artifact</code> Path to artifact file <code>phase</code> Current PCR phase <code>iteration</code> SPSA iteration count <code>generation</code> Config generation number"},{"location":"documentation/reference/observability/#prometheus-metrics","title":"Prometheus Metrics","text":"<p>Enable metrics endpoint:</p> <pre><code>arqonhpo --metrics-addr 127.0.0.1:9898 &lt;command&gt;\n\n# Or with dashboard\narqonhpo dashboard --state state.json --metrics-addr 127.0.0.1:9898\n</code></pre> <p>Scrape at <code>http://127.0.0.1:9898/metrics</code>.</p>"},{"location":"documentation/reference/observability/#counters","title":"Counters","text":"Metric Labels Description <code>arqonhpo_ask_calls_total</code> \u2014 Total ask() invocations <code>arqonhpo_tell_calls_total</code> \u2014 Total tell() invocations <code>arqonhpo_candidates_emitted_total</code> \u2014 Total candidates generated <code>arqonhpo_results_ingested_total</code> \u2014 Total results processed <code>arqonhpo_violations_total</code> <code>type</code> Safety violations by type <code>arqonhpo_rollbacks_total</code> \u2014 Rollback operations"},{"location":"documentation/reference/observability/#gauges","title":"Gauges","text":"Metric Labels Description <code>arqonhpo_history_len</code> \u2014 Current history size <code>arqonhpo_budget_remaining</code> \u2014 Remaining evaluation budget <code>arqonhpo_best_value</code> \u2014 Current best objective value <code>arqonhpo_config_generation</code> \u2014 Current config generation <code>arqonhpo_spsa_iteration</code> \u2014 Current SPSA iteration <code>arqonhpo_safe_mode_active</code> \u2014 1 if in safe mode, 0 otherwise"},{"location":"documentation/reference/observability/#histograms","title":"Histograms","text":"Metric Buckets Description <code>arqonhpo_eval_duration_seconds</code> 0.001, 0.01, 0.1, 1, 10 Evaluation latency <code>arqonhpo_ask_duration_seconds</code> 0.0001, 0.001, 0.01, 0.1 Ask latency <code>arqonhpo_apply_duration_seconds</code> 0.00001, 0.0001, 0.001 Config apply latency"},{"location":"documentation/reference/observability/#example-queries-promql","title":"Example Queries (PromQL)","text":"<pre><code># Average evaluations per second\nrate(arqonhpo_tell_calls_total[5m])\n\n# 99th percentile eval latency\nhistogram_quantile(0.99, rate(arqonhpo_eval_duration_seconds_bucket[5m]))\n\n# Violation rate by type\nrate(arqonhpo_violations_total[5m])\n\n# Config update frequency\nrate(arqonhpo_config_generation[1m])\n\n# Safe mode duration\nchanges(arqonhpo_safe_mode_active[1h])\n</code></pre>"},{"location":"documentation/reference/observability/#grafana-dashboard","title":"Grafana Dashboard","text":"<p>Import this JSON or build from these panels:</p>"},{"location":"documentation/reference/observability/#recommended-panels","title":"Recommended Panels","text":"<ol> <li>Throughput \u2014 <code>rate(arqonhpo_tell_calls_total[5m])</code></li> <li>Best Value \u2014 <code>arqonhpo_best_value</code></li> <li>Eval Latency p99 \u2014 <code>histogram_quantile(0.99, ...)</code></li> <li>Violations \u2014 <code>rate(arqonhpo_violations_total[5m])</code> by type</li> <li>Budget Remaining \u2014 <code>arqonhpo_budget_remaining</code></li> <li>Safe Mode Status \u2014 <code>arqonhpo_safe_mode_active</code></li> </ol>"},{"location":"documentation/reference/observability/#alert-rules","title":"Alert Rules","text":"<pre><code>groups:\n  - name: arqonhpo\n    rules:\n      - alert: HighViolationRate\n        expr: rate(arqonhpo_violations_total[5m]) &gt; 0.1\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High violation rate in ArqonHPO\"\n\n      - alert: SafeModeActive\n        expr: arqonhpo_safe_mode_active == 1\n        for: 1m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"ArqonHPO entered safe mode\"\n</code></pre>"},{"location":"documentation/reference/observability/#tracing-spans","title":"Tracing Spans","text":"<p>When <code>log-level=trace</code>, spans are emitted:</p> Span Parent Description <code>ask</code> \u2014 Full ask() operation <code>probe</code> <code>ask</code> Probe phase sampling <code>classify</code> <code>ask</code> Landscape classification <code>refine</code> <code>ask</code> Strategy execution <code>tell</code> \u2014 Full tell() operation <code>apply</code> <code>tell</code> Config application <code>guardrails</code> <code>apply</code> Safety checks"},{"location":"documentation/reference/observability/#opentelemetry-planned","title":"OpenTelemetry (Planned)","text":"<p>OTel export planned for v0.4. Track: Issue #XX</p>"},{"location":"documentation/reference/observability/#tui-monitoring","title":"TUI Monitoring","text":"<p>Real-time terminal dashboard:</p> <pre><code>arqonhpo tui --state state.json --events events.jsonl\n</code></pre> <p>See TUI Reference for details.</p>"},{"location":"documentation/reference/observability/#web-dashboard","title":"Web Dashboard","text":"<p>Browser-based monitoring:</p> <pre><code>arqonhpo dashboard --state state.json --addr 127.0.0.1:3030\n</code></pre> <p>See Dashboard Reference for API endpoints.</p>"},{"location":"documentation/reference/observability/#audit-events","title":"Audit Events","text":"<p>All safety-relevant events are logged to the audit trail:</p> Event Trigger <code>apply_success</code> Config update applied <code>apply_rejected</code> Proposal violated guardrails <code>rollback</code> Reverted to baseline <code>safe_mode_enter</code> Entered safe mode <code>safe_mode_exit</code> Exited safe mode <code>baseline_set</code> New baseline established <p>Access via:</p> <ul> <li>Dashboard API: <code>GET /api/events</code></li> <li>CLI export: <code>arqonhpo export --state state.json</code></li> </ul>"},{"location":"documentation/reference/observability/#next-steps","title":"Next Steps","text":"<ul> <li>Dashboard \u2014 Web UI reference</li> <li>Hotpath API \u2014 Internal telemetry APIs</li> <li>Safety \u2014 Understanding violations</li> </ul>"},{"location":"documentation/reference/python/","title":"Python API Reference","text":"<p>::: arqonhpo</p>"},{"location":"documentation/reference/python/#arqonsolver","title":"ArqonSolver","text":"<p>The main entry point for optimization.</p>"},{"location":"documentation/reference/python/#constructor","title":"Constructor","text":"<pre><code>ArqonSolver(config_json: str) -&gt; ArqonSolver\n</code></pre> <p>Parameters:</p> <ul> <li><code>config_json</code>: JSON string with solver configuration.</li> </ul> <p>Config Schema:</p> Field Type Required Default Description <code>seed</code> int \u2713 - RNG seed for reproducibility <code>budget</code> int \u2713 - Max number of evaluations <code>bounds</code> dict \u2713 - Parameter bounds (see below) <code>probe_ratio</code> float \u2717 0.2 Fraction of budget for probing <code>strategy_params</code> dict \u2717 null Strategy-specific config <p>Bounds Format:</p> <pre><code>{\n  \"param_name\": {\n    \"min\": 0.0,\n    \"max\": 1.0,\n    \"scale\": \"Linear\" // or \"Log\"\n  }\n}\n</code></pre>"},{"location":"documentation/reference/python/#methods","title":"Methods","text":""},{"location":"documentation/reference/python/#ask-listdict-none","title":"<code>ask() -&gt; list[dict] | None</code>","text":"<p>Returns the next batch of candidate parameters, or <code>None</code> if optimization is complete.</p>"},{"location":"documentation/reference/python/#tellresults_json-str-none","title":"<code>tell(results_json: str) -&gt; None</code>","text":"<p>Report evaluation results back to the solver.</p> <p>Results Schema:</p> <pre><code>[\n  {\n    \"eval_id\": 0,\n    \"params\": { \"x\": 1.0, \"y\": 2.0 },\n    \"value\": 0.5,\n    \"cost\": 1.0\n  }\n]\n</code></pre>"},{"location":"documentation/reference/python/#seedseed_json-str-none","title":"<code>seed(seed_json: str) -&gt; None</code>","text":"<p>Inject historical evaluations into the solver for warm-starting. The solver assigns internal <code>eval_id</code>s automatically.</p> <p>Use Cases:</p> <ul> <li>Warm-starting: Resume optimization from a previous run's data</li> <li>Streaming/Online optimization: External systems generate evaluations</li> </ul> <p>Seed Data Schema:</p> <pre><code>[\n  {\n    \"params\": { \"x\": 1.0, \"y\": 2.0 },\n    \"value\": 0.5,\n    \"cost\": 1.0\n  }\n]\n</code></pre> <p>Note: Unlike <code>tell()</code>, the seed data does not require <code>eval_id</code> fields.</p> <p>Example:</p> <pre><code>import json\nfrom arqonhpo import ArqonSolver\n\nconfig = {\n    \"seed\": 42,\n    \"budget\": 100,\n    \"bounds\": {\"x\": {\"min\": -5.0, \"max\": 5.0, \"scale\": \"Linear\"}},\n    \"probe_ratio\": 0.2\n}\nsolver = ArqonSolver(json.dumps(config))\n\n# Seed with historical data from a previous run\nhistorical = [\n    {\"params\": {\"x\": 0.5}, \"value\": 10.0, \"cost\": 1.0},\n    {\"params\": {\"x\": 1.5}, \"value\": 5.0, \"cost\": 1.0}\n]\nsolver.seed(json.dumps(historical))\n\n# Next ask() will be informed by seeded data\nbatch = solver.ask()\n</code></pre> <p>Probe Budget</p> <p>To trigger phase transition to Classify\u2192Refine, seed at least <code>budget \u00d7 probe_ratio</code> points (default: 20% of budget).</p>"},{"location":"documentation/reference/python/#get_history_len-int","title":"<code>get_history_len() -&gt; int</code>","text":"<p>Returns the current number of evaluations in the solver's history. Useful for verifying seeding or tracking progress.</p>"},{"location":"documentation/reference/python/#ask_one-dict-none","title":"<code>ask_one() -&gt; dict | None</code>","text":"<p>Returns a single candidate for online/real-time optimization.</p> <p>Unlike <code>ask()</code> which returns a batch for the PCR workflow, <code>ask_one()</code>:</p> <ol> <li>Skips Probe/Classify phases</li> <li>Uses TPE strategy directly</li> <li>Returns exactly 1 candidate per call</li> </ol> <p>Use Case: Real-time control loops, streaming optimization.</p> <p>Example:</p> <pre><code>from arqonhpo import ArqonSolver\nimport json\n\nconfig = {\n    \"seed\": 42,\n    \"budget\": 100,\n    \"bounds\": {\"kp\": {\"min\": 0.1, \"max\": 10.0}}\n}\nsolver = ArqonSolver(json.dumps(config))\n\nwhile True:\n    candidate = solver.ask_one()\n    if candidate is None:\n        break\n\n    # Evaluate single candidate\n    value = evaluate(candidate)\n\n    # Immediately feed back\n    solver.seed(json.dumps([{\n        \"params\": candidate,\n        \"value\": value,\n        \"cost\": 1.0\n    }]))\n</code></pre> <p>See Batch vs Online Mode for details.</p>"},{"location":"documentation/reference/python/#arqonprobe","title":"ArqonProbe","text":"<p>Stateless Low-Discrepancy Sequence sampler for distributed sampling.</p>"},{"location":"documentation/reference/python/#constructor_1","title":"Constructor","text":"<pre><code>ArqonProbe(config_json: str, seed: int = 42) -&gt; ArqonProbe\n</code></pre> <p>Parameters:</p> <ul> <li><code>config_json</code>: JSON string with bounds configuration.</li> <li><code>seed</code>: RNG seed (default: 42).</li> </ul>"},{"location":"documentation/reference/python/#methods_1","title":"Methods","text":""},{"location":"documentation/reference/python/#sample_atindex-int-dict","title":"<code>sample_at(index: int) -&gt; dict</code>","text":"<p>Generate a single LDS point at the given global index. Stateless \u2014 the same index always returns the same point.</p> <pre><code>from arqonhpo import ArqonProbe\nimport json\n\nconfig = json.dumps({\n    \"bounds\": {\n        \"x\": {\"min\": 0, \"max\": 1},\n        \"y\": {\"min\": 0, \"max\": 1}\n    }\n})\n\nprobe = ArqonProbe(config, seed=42)\n\n# Same index \u2192 same point\npoint_0 = probe.sample_at(0)      # {\"x\": 0.5, \"y\": 0.5}\npoint_100 = probe.sample_at(100)  # Different point\n\n# Deterministic\nassert probe.sample_at(0) == probe.sample_at(0)  # \u2713\n</code></pre>"},{"location":"documentation/reference/python/#sample_rangestart-int-count-int-listdict","title":"<code>sample_range(start: int, count: int) -&gt; list[dict]</code>","text":"<p>Generate a range of LDS points from index <code>start</code> to <code>start + count - 1</code>.</p> <p>Use Case: Zero-coordination sharding across workers.</p> <pre><code># Worker 0: points 0-999\npoints_w0 = probe.sample_range(0, 1000)\n\n# Worker 1: points 1000-1999\npoints_w1 = probe.sample_range(1000, 1000)\n\n# No coordination needed \u2014 ranges are deterministic and non-overlapping\n</code></pre>"},{"location":"documentation/reference/python/#sharding-pattern","title":"Sharding Pattern","text":"<pre><code>import json\nfrom arqonhpo import ArqonProbe\nfrom multiprocessing import Pool\n\nconfig = json.dumps({\n    \"bounds\": {\"x\": {\"min\": 0, \"max\": 1}, \"y\": {\"min\": 0, \"max\": 1}}\n})\n\ndef worker(worker_id):\n    probe = ArqonProbe(config, seed=42)  # Same seed everywhere\n    chunk_size = 1000\n    start = worker_id * chunk_size\n    return probe.sample_range(start, chunk_size)\n\n# All workers produce deterministic, non-overlapping points\nwith Pool(4) as p:\n    all_points = p.map(worker, range(4))\n    # 4000 unique, deterministic points\n</code></pre> <p>See Determinism for more details.</p>"},{"location":"documentation/reference/rust/","title":"Rust API Reference","text":"<p>Full API documentation is available via <code>cargo doc</code>.</p> <pre><code>cd ArqonHPO\ncargo doc --open\n</code></pre>"},{"location":"documentation/reference/rust/#crate-overview","title":"Crate Overview","text":"Crate Description <code>arqonhpo_core</code> High-level Solver, Strategies, Classifier <code>arqonhpo_hotpath</code> Low-level SafetyExecutor, SPSA, Telemetry"},{"location":"documentation/reference/rust/#core-crate-arqonhpo_core","title":"Core Crate (<code>arqonhpo_core</code>)","text":""},{"location":"documentation/reference/rust/#solver","title":"<code>Solver</code>","text":"<p>The core state machine with probe-classify-refine pipeline.</p> <pre><code>use arqonhpo_core::machine::Solver;\nuse arqonhpo_core::config::SolverConfig;\n\nlet config: SolverConfig = serde_json::from_str(r#\"{\n    \"seed\": 42,\n    \"budget\": 100,\n    \"bounds\": {\n        \"x\": {\"min\": -5.0, \"max\": 5.0, \"scale\": \"Linear\"},\n        \"y\": {\"min\": 0.01, \"max\": 10.0, \"scale\": \"Log\"}\n    }\n}\"#)?;\n\n// Standard PCR mode (recommended)\nlet mut solver = Solver::pcr(config);\n\nloop {\n    match solver.ask() {\n        Some(candidates) =&gt; {\n            let results = evaluate_batch(&amp;candidates);\n            solver.tell(results);\n        }\n        None =&gt; break,\n    }\n}\n\nprintln!(\"Best: {:?}\", solver.best());\n</code></pre>"},{"location":"documentation/reference/rust/#constructor-variants","title":"Constructor Variants","text":"Method Mode Use Case <code>Solver::new(config)</code> MVP mode Testing, simple problems <code>Solver::pcr(config)</code> PCR production Production use (recommended)"},{"location":"documentation/reference/rust/#solverconfig","title":"<code>SolverConfig</code>","text":"<pre><code>pub struct SolverConfig {\n    /// RNG seed for reproducibility\n    pub seed: u64,\n\n    /// Maximum evaluations\n    pub budget: u64,\n\n    /// Parameter bounds\n    pub bounds: HashMap&lt;String, Domain&gt;,\n\n    /// Fraction of budget for probe phase (0.0-1.0)\n    pub probe_ratio: f64,\n\n    /// Optional batch size override\n    pub batch_size: Option&lt;u64&gt;,\n\n    /// Force specific strategy (bypasses classifier)\n    pub strategy: Option&lt;StrategyType&gt;,\n\n    /// Strategy-specific parameters\n    pub strategy_params: Option&lt;HashMap&lt;String, f64&gt;&gt;,\n}\n</code></pre>"},{"location":"documentation/reference/rust/#domain","title":"<code>Domain</code>","text":"<p>Defines parameter bounds and scaling.</p> <pre><code>pub struct Domain {\n    pub min: f64,\n    pub max: f64,\n    pub scale: Scale,\n}\n\npub enum Scale {\n    Linear,\n    Log,\n    Periodic { period: f64 },\n}\n</code></pre> <p>Example:</p> <pre><code>use arqonhpo_core::config::{Domain, Scale};\n\nlet domain = Domain {\n    min: 0.001,\n    max: 1.0,\n    scale: Scale::Log,\n};\n</code></pre>"},{"location":"documentation/reference/rust/#evaltrace","title":"<code>EvalTrace</code>","text":"<p>A single evaluation result.</p> <pre><code>pub struct EvalTrace {\n    pub eval_id: u64,\n    pub params: HashMap&lt;String, f64&gt;,\n    pub value: f64,\n    pub cost: f64,\n}\n</code></pre>"},{"location":"documentation/reference/rust/#pcr-algorithm-components","title":"PCR Algorithm Components","text":""},{"location":"documentation/reference/rust/#residualdecayclassifier","title":"<code>ResidualDecayClassifier</code>","text":"<p>Classifies the landscape based on residual decay.</p> <pre><code>use arqonhpo_core::classify::{ResidualDecayClassifier, Classify, Landscape};\n\nlet classifier = ResidualDecayClassifier::new(0.5); // \u03b1 threshold\n\nlet (landscape, alpha) = classifier.classify(&amp;history);\n\nmatch landscape {\n    Landscape::Structured =&gt; println!(\"Use Nelder-Mead\"),\n    Landscape::Chaotic =&gt; println!(\"Use TPE\"),\n}\n</code></pre>"},{"location":"documentation/reference/rust/#primeindexprobe","title":"<code>PrimeIndexProbe</code>","text":"<p>Low-discrepancy sequence sampling using prime ratios.</p> <pre><code>use arqonhpo_core::probe::{PrimeIndexProbe, Probe};\n\nlet probe = PrimeIndexProbe::new(seed);\nlet candidates = probe.sample(&amp;config, batch_size);\n</code></pre>"},{"location":"documentation/reference/rust/#strategies","title":"Strategies","text":""},{"location":"documentation/reference/rust/#neldermead","title":"<code>NelderMead</code>","text":"<p>Simplex-based optimizer for structured landscapes.</p> <pre><code>use arqonhpo_core::strategies::nelder_mead::NelderMead;\n\nlet nm = NelderMead::new(\n    dim,\n    reflection_coeff,   // \u03b1 = 1.0\n    expansion_coeff,    // \u03b3 = 2.0\n    contraction_coeff,  // \u03c1 = 0.5\n    shrink_coeff,       // \u03c3 = 0.5\n);\n</code></pre>"},{"location":"documentation/reference/rust/#multistartnm","title":"<code>MultiStartNM</code>","text":"<p>Multi-start Nelder-Mead for multimodal optimization.</p> <pre><code>use arqonhpo_core::strategies::multi_start_nm::MultiStartNM;\n\nlet msnm = MultiStartNM::new(dim, n_starts, seed);\n</code></pre>"},{"location":"documentation/reference/rust/#tpe","title":"<code>TPE</code>","text":"<p>Tree-structured Parzen Estimator for noisy/chaotic landscapes.</p> <pre><code>use arqonhpo_core::strategies::tpe::{TPE, BandwidthRule};\n\nlet tpe = TPE::with_bandwidth_rule(dim, BandwidthRule::Scott);\n// Scott's Rule: \u03c3 = 1.06 \u00d7 stddev \u00d7 n^(-1/5)\n</code></pre>"},{"location":"documentation/reference/rust/#bandwidthrule","title":"<code>BandwidthRule</code>","text":"Rule Formula Use Case <code>Scott</code> 1.06 \u00d7 \u03c3 \u00d7 n^(-1/5) General (default) <code>Silverman</code> 0.9 \u00d7 min(\u03c3, IQR/1.34) \u00d7 n^(-1/5) Outlier-robust <code>Fixed(bw)</code> User-specified Custom"},{"location":"documentation/reference/rust/#seeding-warm-start","title":"Seeding (Warm-Start)","text":""},{"location":"documentation/reference/rust/#seedingconfig","title":"<code>SeedingConfig</code>","text":"<p>Configure how probe history seeds refiners.</p> <pre><code>use arqonhpo_core::seeding::{SeedingConfig, SeedingStrategy};\n\nlet config = SeedingConfig {\n    strategy: SeedingStrategy::TopK { k: 10 },\n    budget_fraction: 0.1,\n};\n</code></pre>"},{"location":"documentation/reference/rust/#seedingstrategy","title":"<code>SeedingStrategy</code>","text":"Strategy Description <code>TopK { k }</code> Top k best points from probe <code>AllProbe</code> All probe history <code>Random { n }</code> Random n points"},{"location":"documentation/reference/rust/#hotpath-crate","title":"Hotpath Crate","text":"<p>For low-level safety-critical APIs (SafetyExecutor, SPSA, Telemetry), see:</p> <p>\u2192 Hotpath API Reference</p>"},{"location":"documentation/reference/rust/#feature-flags","title":"Feature Flags","text":"Flag Description <code>python</code> Enable Python bindings via PyO3 <code>metrics</code> Enable Prometheus metrics <code>tracing</code> Enable tracing spans <pre><code>[dependencies]\narqonhpo_core = { version = \"0.3\", features = [\"metrics\"] }\n</code></pre>"},{"location":"documentation/reference/rust/#next-steps","title":"Next Steps","text":"<ul> <li>Hotpath API \u2014 SafetyExecutor, SPSA, Guardrails</li> <li>Python API \u2014 Python bindings</li> <li>Strategies \u2014 Algorithm comparison</li> </ul>"},{"location":"documentation/reference/tui/","title":"Terminal User Interface (TUI)","text":"<p>Optimization happens fast. Sometimes, you need to see it unfold without leaving your terminal.</p> <p>The ArqonHPO TUI is a zero-latency, high-visibility monitor for your optimization runs. Whether you're debugging a local script or monitoring a job over SSH, the TUI gives you an instant pulse on your solver's progress using a modern, responsive interface.</p> <p></p>"},{"location":"documentation/reference/tui/#why-use-the-tui","title":"Why Use the TUI?","text":"<ul> <li>Zero Overhead: runs directly in your terminal; no browser required.</li> <li>Instant Feedback: Watch the solver explore, converge, and react in real-time.</li> <li>Remote Ready: Perfect for monitoring headless servers or SSH sessions where web ports aren't forwarded.</li> </ul>"},{"location":"documentation/reference/tui/#the-interface-explained","title":"The Interface Explained","text":"<p>The TUI is divided into three logical panels, designed to give you the complete picture at a glance:</p>"},{"location":"documentation/reference/tui/#1-summary-phase-top","title":"1. Summary Phase (Top)","text":"<p>The Pulse. This panel shows the high-level health of your run.</p> <ul> <li>Run ID: The unique identifier for this optimization session (useful for tracking logs).</li> <li>Budget: How many evaluations are left before the solver stops.</li> <li>History: The total number of points evaluated so far.</li> </ul>"},{"location":"documentation/reference/tui/#2-recent-evaluations-middle","title":"2. Recent Evaluations (Middle)","text":"<p>The Action. This is where the work happens. It lists the most recent parameter combinations the solver has tried, along with their results.</p> <ul> <li>Value: The objective function result (lower is better for minimization).</li> <li>Params: The hyperparameters chosen for that evaluation (e.g., <code>learning_rate</code>, <code>batch_size</code>).</li> <li>Color Coding:</li> <li>Green values indicate a new best finding.</li> <li>Standard white/gray values indicate exploration or non-optimal points.</li> </ul>"},{"location":"documentation/reference/tui/#3-events-stream-bottom","title":"3. Events Stream (Bottom)","text":"<p>The Narrative. While evaluations show what happened, events tell you why.</p> <ul> <li>Convergence Warnings: When the solver detects it's stuck in a local minima.</li> <li>Phase Shifts: When the algorithm switches strategies (e.g., from \"Probe\" to \"Refine\").</li> <li>Errors: Immediate feedback on script failures or guardrail violations.</li> </ul>"},{"location":"documentation/reference/tui/#starting-the-tui","title":"Starting the TUI","text":"<p>To launch the TUI, point it at your solver's state file:</p> <pre><code>arqonhpo tui --state state.json\n</code></pre> <p>If you also want to see the live event stream (highly recommended for debugging), include the events file:</p> <pre><code>arqonhpo tui --state state.json --events events.jsonl\n</code></pre> Flag Description <code>--state</code> Required. Path to the JSON state file updated by <code>arqonhpo ask/tell</code>. <code>--events</code> Optional. Path to the JSONL events log for rich narrative feedback. <code>--refresh-ms</code> Update frequency (default: 500ms). Increase for slow SSH connections."},{"location":"documentation/reference/tui/#controls-keybindings","title":"Controls &amp; Keybindings","text":"<p>Navigate the interface without touching your mouse.</p> Key Action Context <code>q</code> or <code>Esc</code> Quit Exit the TUI immediately. <code>r</code> Force Refresh Manually reload the state and events files. <code>p</code> Pause Freeze auto-refresh to inspect a specific value. <code>\u2191</code> / <code>\u2193</code> Scroll Scroll through history or logs when paused."},{"location":"documentation/reference/tui/#configuration-performance","title":"configuration &amp; Performance","text":""},{"location":"documentation/reference/tui/#refresh-rate","title":"Refresh Rate","text":"<p>By default, the TUI polls for changes every 500 milliseconds.</p> <ul> <li>Local Development: Lower it to <code>100</code>ms for a smoother, \"matrix-like\" feel.</li> </ul> <pre><code>arqonhpo tui --state state.json --refresh-ms 100\n</code></pre> <ul> <li>High-Latency SSH: Raise it to <code>2000</code>ms (2 seconds) to reduce bandwidth usage.   <pre><code>arqonhpo tui --state state.json --refresh-ms 2000\n</code></pre></li> </ul>"},{"location":"documentation/reference/tui/#data-sources","title":"Data Sources","text":"<p>The TUI is stateless. It simply visualizes the files on disk. This means:</p> <ol> <li>You can stop/start the TUI without affecting the running optimization.</li> <li>You can run multiple TUI instances watching the same file (e.g., one on a big screen, one on your laptop).</li> </ol>"},{"location":"documentation/reference/tui/#monitoring-multiple-experiments","title":"Monitoring Multiple Experiments","text":"<p>Since the TUI is bound to a single state file, it displays one run per window.</p> <p>To monitor multiple concurrent experiments:</p> <ol> <li>Ensure each experiment writes to a unique state file (e.g., <code>run_A.json</code>, <code>run_B.json</code>).</li> <li>Open separate terminal tabs or use a multiplexer like <code>tmux</code>.</li> <li>Launch a dedicated TUI instance for each run:</li> </ol> <pre><code># Terminal 1\narqonhpo tui --state run_A.json\n\n# Terminal 2\narqonhpo tui --state run_B.json\n</code></pre>"},{"location":"documentation/reference/tui/#next-steps","title":"Next Steps","text":"<ul> <li>CLI Reference: Learn how to generate the state files the TUI consumes.</li> <li>Dashboard: Prefer a browser? Check out the web-based dashboard for charts and graphs.</li> </ul>"},{"location":"project/CODE_OF_CONDUCT/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"project/CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone.</p>"},{"location":"project/CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment:</p> <ul> <li>Being respectful of differing viewpoints</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards others</li> </ul> <p>Examples of unacceptable behavior:</p> <ul> <li>Trolling, insulting or derogatory comments</li> <li>Public or private harassment</li> <li>Publishing others' private information without permission</li> <li>Other conduct which could reasonably be considered inappropriate</li> </ul>"},{"location":"project/CODE_OF_CONDUCT/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders at conduct@arqon.dev.</p>"},{"location":"project/CODE_OF_CONDUCT/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.1.</p>"},{"location":"project/CONTRIBUTING/","title":"Contributing to ArqonHPO","text":"**You're about to contribute to the future of optimization infrastructure.**  Every line of code you write here will help engineers around the world make their systems faster, safer, and smarter.  **Welcome to something meaningful**"},{"location":"project/CONTRIBUTING/#why-contribute","title":"\ud83d\udca1 Why Contribute?","text":""},{"location":"project/CONTRIBUTING/#your-impact","title":"Your Impact","text":"What You Build Who You Help A faster algorithm The ML engineer waiting 3 days for HPO to finish A clearer doc page The new developer at 2am trying to tune their first model A bug fix The SRE whose production system just learned to heal itself A test case Every future contributor who won't break what you protected"},{"location":"project/CONTRIBUTING/#what-you-get","title":"What You Get","text":"<ul> <li>\ud83c\udfc6 Recognition \u2014 Contributors credited in releases and CHANGELOG</li> <li>\ud83c\udf93 Learning \u2014 Work with cutting-edge Rust, optimization algorithms, and systems design</li> <li>\ud83e\udd1d Community \u2014 Join a team that actually reviews PRs thoroughly and kindly</li> <li>\ud83d\udcc8 Portfolio \u2014 Your name on production-grade, battle-tested code</li> </ul>"},{"location":"project/CONTRIBUTING/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"project/CONTRIBUTING/#5-minutes-to-your-first-contribution","title":"5 Minutes to Your First Contribution","text":"<pre><code># 1. Fork on GitHub, then:\ngit clone https://github.com/YOUR_USERNAME/ArqonHPO.git\ncd ArqonHPO\n\n# 2. Build everything\njust build\n\n# 3. Run tests (they should all pass)\njust test\n\n# 4. Make your change, then\njust check  # Format + lint\njust test   # Verify nothing broke\n\n# 5. Push and open a PR!\n</code></pre>"},{"location":"project/CONTRIBUTING/#dont-have-just","title":"Don't Have <code>just</code>?","text":"<pre><code>cargo install just\n# or on macOS: brew install just\n</code></pre>"},{"location":"project/CONTRIBUTING/#where-to-start","title":"\ud83c\udfaf Where to Start","text":""},{"location":"project/CONTRIBUTING/#good-first-issues","title":"Good First Issues","text":"<p>We specifically label issues for new contributors:</p> Label Meaning <code>good first issue</code> Perfect for your first PR <code>help wanted</code> We actively want help here <code>docs</code> Documentation improvements <code>tests</code> Test coverage gaps <p>Browse Good First Issues \u2192</p>"},{"location":"project/CONTRIBUTING/#contribution-ideas-by-skill","title":"Contribution Ideas by Skill","text":"\ud83e\udd80 Rust Developer <li>Implement new optimization strategies (CMA-ES, SMAC)</li> <li>Optimize hot path performance (we love benchmarks!)</li> <li>Add GPU acceleration (CUDA/Metal)</li> <li>Improve error handling and edge cases</li> \ud83d\udc0d Python Developer <li>Expand Python bindings with new features</li> <li>Add integration examples (PyTorch, JAX, etc.)</li> <li>Write cookbook recipes</li> <li>Improve type hints and docstrings</li> \ud83d\udcdd Technical Writer <li>Improve existing documentation clarity</li> <li>Add more code examples</li> <li>Create tutorials and guides</li> <li>Translate docs to other languages</li> \ud83e\uddea QA/Testing <li>Add edge case tests</li> <li>Improve test coverage</li> <li>Property-based testing with `proptest`</li> <li>Fuzz testing critical paths</li> \ud83c\udfa8 Designer <li>Improve TUI layout and UX</li> <li>Dashboard UI enhancements</li> <li>Documentation diagrams</li> <li>Logo and branding</li>"},{"location":"project/CONTRIBUTING/#development-workflow","title":"\ud83d\udccb Development Workflow","text":""},{"location":"project/CONTRIBUTING/#1-create-a-branch","title":"1. Create a Branch","text":"<pre><code>git checkout -b type/short-description\n# Examples:\n# feat/multi-objective-optimization\n# fix/tpe-bandwidth-edge-case\n# docs/kubernetes-guide\n</code></pre>"},{"location":"project/CONTRIBUTING/#2-make-your-changes","title":"2. Make Your Changes","text":"<p>Write code. Write tests. Write docs. In that order.</p>"},{"location":"project/CONTRIBUTING/#3-run-the-quality-gauntlet","title":"3. Run the Quality Gauntlet","text":"<pre><code># The full check (what CI runs)\njust check       # Format (rustfmt, ruff)\njust lint        # Lint (clippy, ruff, mypy)\njust test        # All tests\njust coverage    # Coverage report\n\n# Quick iteration\njust quick       # Fast format + test\n</code></pre>"},{"location":"project/CONTRIBUTING/#4-commit-with-meaning","title":"4. Commit with Meaning","text":"<p>We use Conventional Commits:</p> <pre><code>&lt;type&gt;(&lt;scope&gt;): &lt;description&gt;\n\n[optional body]\n\n[optional footer]\n</code></pre> <p>Types:</p> Type Use For <code>feat</code> New features <code>fix</code> Bug fixes <code>docs</code> Documentation <code>test</code> Test additions <code>refactor</code> Code refactoring <code>perf</code> Performance improvements <code>ci</code> CI/CD changes <code>chore</code> Maintenance <p>Examples:</p> <pre><code>feat(core): add CMA-ES strategy\n\nImplements the Covariance Matrix Adaptation Evolution Strategy\nfor high-dimensional continuous optimization.\n\n- Adds CmaEs struct with standard parameters\n- Integrates with existing Strategy trait\n- Includes 15 unit tests\n\nCloses #42\n</code></pre> <pre><code>fix(bindings): handle empty parameter bounds\n\nThe Python bindings would panic when given an empty bounds dict.\nNow returns a clear ValueError with guidance.\n\nFixes #123\n</code></pre>"},{"location":"project/CONTRIBUTING/#5-open-a-pull-request","title":"5. Open a Pull Request","text":"<ul> <li>Fill out the PR template completely</li> <li>Link related issues</li> <li>Add screenshots/recordings for UI changes</li> <li>Request review from maintainers</li> </ul>"},{"location":"project/CONTRIBUTING/#architecture-overview","title":"\ud83c\udfd7\ufe0f Architecture Overview","text":"<p>Understanding the codebase:</p> <pre><code>ArqonHPO/\n\u251c\u2500\u2500 crates/\n\u2502   \u251c\u2500\u2500 core/           # \ud83e\udde0 Solver, strategies, PCR algorithm\n\u2502   \u2502   \u251c\u2500\u2500 machine.rs      # Main state machine\n\u2502   \u2502   \u251c\u2500\u2500 strategies/     # NM, TPE, Multi-start\n\u2502   \u2502   \u251c\u2500\u2500 classify.rs     # Landscape classifier\n\u2502   \u2502   \u2514\u2500\u2500 probe.rs        # LDS sampling\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 hotpath/        # \u26a1 Safety-critical real-time code\n\u2502   \u2502   \u251c\u2500\u2500 executor.rs     # SafetyExecutor\n\u2502   \u2502   \u251c\u2500\u2500 spsa.rs         # SPSA optimizer\n\u2502   \u2502   \u2514\u2500\u2500 telemetry.rs    # Ring buffers\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 cli/            # \ud83d\udda5\ufe0f Command-line interface\n\u2502       \u251c\u2500\u2500 main.rs         # Entry point\n\u2502       \u251c\u2500\u2500 tui.rs          # Terminal UI\n\u2502       \u2514\u2500\u2500 dashboard.rs    # Web UI\n\u2502\n\u251c\u2500\u2500 bindings/\n\u2502   \u2514\u2500\u2500 python/         # \ud83d\udc0d PyO3 bindings\n\u2502\n\u2514\u2500\u2500 docs/               # \ud83d\udcda MkDocs documentation\n</code></pre>"},{"location":"project/CONTRIBUTING/#key-concepts","title":"Key Concepts","text":"Concept File What It Does PCR Pipeline <code>machine.rs</code> Probe\u2192Classify\u2192Refine flow Safety Executor <code>executor.rs</code> Guardrails + rollback LDS Sampling <code>probe.rs</code> Low-discrepancy sequences Landscape Classification <code>classify.rs</code> Structured vs chaotic"},{"location":"project/CONTRIBUTING/#code-standards","title":"\ud83d\udccf Code Standards","text":""},{"location":"project/CONTRIBUTING/#rust","title":"Rust","text":"<pre><code>// \u2705 Good: Clear, documented, tested\n/// Computes the adaptive learning rate for iteration k.\n///\n/// Uses the SPSA decay schedule: a_k = a\u2080 / (k + 1 + A)^\u03b1\n///\n/// # Arguments\n/// * `k` - Current iteration (0-indexed)\n///\n/// # Returns\n/// Learning rate for this iteration\npub fn learning_rate(&amp;self, k: u64) -&gt; f64 {\n    self.initial_rate / (k as f64 + 1.0 + self.stability).powf(self.alpha)\n}\n\n// \u274c Bad: Magic numbers, no docs\npub fn lr(&amp;self, k: u64) -&gt; f64 {\n    self.a / (k as f64 + 11.0).powf(0.602)\n}\n</code></pre>"},{"location":"project/CONTRIBUTING/#python","title":"Python","text":"<pre><code># \u2705 Good: Typed, docstring, examples\ndef sample_at(self, index: int) -&gt; dict[str, float]:\n    \"\"\"Generate a deterministic sample at the given index.\n\n    Args:\n        index: Global LDS index (0 to 2^64-1)\n\n    Returns:\n        Parameter dict with values in bounds\n\n    Example:\n        &gt;&gt;&gt; probe = ArqonProbe(config)\n        &gt;&gt;&gt; probe.sample_at(0)\n        {'x': 0.5, 'y': 0.5}\n    \"\"\"\n    ...\n\n# \u274c Bad: No types, no docs\ndef sample(self, i):\n    return self._inner.sample(i)\n</code></pre>"},{"location":"project/CONTRIBUTING/#tests","title":"Tests","text":"<p>Every PR should include tests. We aim for:</p> <ul> <li>Unit tests for individual functions</li> <li>Integration tests for module interactions</li> <li>Property tests for invariants (use <code>proptest</code>)</li> <li>Edge cases explicitly tested</li> </ul> <pre><code>#[test]\nfn test_learning_rate_decays_monotonically() {\n    let spsa = Spsa::new(42, 3, 0.1, 0.01, SpsaConfig::default());\n\n    let rates: Vec&lt;f64&gt; = (0..100).map(|k| spsa.learning_rate(k)).collect();\n\n    for window in rates.windows(2) {\n        assert!(window[0] &gt; window[1], \"Learning rate should decay\");\n    }\n}\n\n#[test]\nfn test_empty_history_returns_none() {\n    let classifier = ResidualDecayClassifier::default();\n    let result = classifier.classify(&amp;[]);\n    assert!(result.is_none());\n}\n</code></pre>"},{"location":"project/CONTRIBUTING/#the-constitution","title":"\ud83d\udd12 The Constitution","text":"<p>ArqonHPO operates under a Constitution that defines inviolable principles:</p> <p>\"Code that violates the Constitution will not be merged.\"</p> <p>Key principles:</p> <ol> <li>No Happy Path Testing \u2014 Every edge case must have a test</li> <li>No Silent Failures \u2014 All errors must surface with context</li> <li>Zero Unbounded Growth \u2014 Memory and CPU must be bounded</li> <li>Audit Everything \u2014 Every state change must be logged</li> </ol> <p>If your PR touches safety-critical code, expect thorough review. This is a feature, not a bug.</p>"},{"location":"project/CONTRIBUTING/#communication","title":"\ud83d\udcac Communication","text":""},{"location":"project/CONTRIBUTING/#before-starting-major-work","title":"Before Starting Major Work","text":"<p>Open an issue or discussion first! We want to:</p> <ul> <li>Ensure the feature aligns with our roadmap</li> <li>Provide early design feedback</li> <li>Prevent duplicate work</li> </ul>"},{"location":"project/CONTRIBUTING/#getting-help","title":"Getting Help","text":"Channel Use For GitHub Discussions Questions, ideas, design discussions Issue Comments Specific issue discussion PR Comments Code review, implementation details"},{"location":"project/CONTRIBUTING/#response-times","title":"Response Times","text":"<ul> <li>Issues: Usually within 48 hours</li> <li>PRs: Initial review within 72 hours</li> <li>Discussions: We try to respond same-day</li> </ul>"},{"location":"project/CONTRIBUTING/#recognition","title":"\ud83c\udf96\ufe0f Recognition","text":""},{"location":"project/CONTRIBUTING/#all-contributors","title":"All Contributors","text":"<p>Every contributor is recognized:</p> <ul> <li>Listed in <code>CONTRIBUTORS.md</code></li> <li>Mentioned in release notes</li> <li>GitHub contributor badge</li> </ul>"},{"location":"project/CONTRIBUTING/#core-contributors","title":"Core Contributors","text":"<p>Sustained contributors may be invited to:</p> <ul> <li>Join the maintainer team</li> <li>Get write access to the repository</li> <li>Participate in roadmap planning</li> </ul>"},{"location":"project/CONTRIBUTING/#license","title":"\ud83d\udcdc License","text":"<p>ArqonHPO is licensed under the Apache License, Version 2.0.</p> <p>By contributing, you agree that your contributions will be licensed under the same terms.</p> <pre><code>                              Apache License\n                        Version 2.0, January 2004\n                     http://www.apache.org/licenses/\n\nCopyright 2024-2026 Novel Byte Labs\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n</code></pre>"},{"location":"project/CONTRIBUTING/#developer-certificate-of-origin","title":"Developer Certificate of Origin","text":"<p>We use the Developer Certificate of Origin (DCO). By submitting a PR, you certify that you wrote the code or have the right to submit it under the Apache 2.0 license.</p>"},{"location":"project/CONTRIBUTING/#thank-you","title":"\ud83d\ude4f Thank You","text":"<p>Open source is built by people like you, in moments stolen from busy lives, driven by the belief that we can make something better together.</p> <p>Every contribution matters. Every test you write. Every typo you fix. Every question you ask that helps us improve our docs.</p> <p>You're not just writing code. You're building the foundation for the next generation of intelligent systems.</p> <p>Welcome to ArqonHPO. We're glad you're here.</p>   **Ready to contribute?**  [Browse Issues](https://github.com/novelbytelabs/ArqonHPO/issues) \u2022 [Read the Docs](https://novelbytelabs.github.io/ArqonHPO) \u2022 [Join Discussions](https://github.com/novelbytelabs/ArqonHPO/discussions)"},{"location":"project/SECURITY/","title":"Security Policy","text":""},{"location":"project/SECURITY/#supported-versions","title":"Supported Versions","text":"Version Supported 0.1.x"},{"location":"project/SECURITY/#reporting-a-vulnerability","title":"Reporting a Vulnerability","text":"<p>Do NOT open a public issue for security vulnerabilities.</p> <p>Email: security@arqon.dev</p> <p>We aim to respond within 48 hours and will work with you to understand and address the issue.</p>"},{"location":"project/SECURITY/#security-practices","title":"Security Practices","text":"<ul> <li>SLSA Level 3: Build provenance for all releases.</li> <li>SBOM: CycloneDX Software Bill of Materials for each release.</li> <li>Fuzzing: Continuous fuzzing of config parsing via <code>cargo-fuzz</code>.</li> <li>Dependency Auditing: <code>cargo audit</code> in CI.</li> </ul>"},{"location":"project/about/","title":"About ArqonHPO","text":"<p>ArqonHPO is developed by NovelByte Labs.</p>"},{"location":"project/about/#mission","title":"Mission","text":"<p>Make optimization as reliable as infrastructure.</p> <p>Traditional HPO libraries treat optimization as an afterthought \u2014 something you \"pip install, run for 3 days, hope for the best.\"</p> <p>We reject this. ArqonHPO is built from the ground up for production:</p> <ul> <li>Microsecond overhead \u2014 Use it in control loops</li> <li>Deterministic execution \u2014 Reproduce any result</li> <li>Constitutional safety \u2014 Every update through guardrails</li> <li>Observable \u2014 Know exactly what's happening</li> </ul>"},{"location":"project/about/#the-philosophy","title":"The Philosophy","text":"<p>\"Optimization is infrastructure. It should be as reliable as a database and as fast as a cache lookup.\"</p>"},{"location":"project/about/#principles","title":"Principles","text":"<ol> <li>Speed is a feature \u2014 &lt;3ms overhead means real-time is possible</li> <li>Safety is non-negotiable \u2014 Guardrails, rollback, audit trail</li> <li>Determinism is default \u2014 Same seed = same sequence</li> <li>Observability is built-in \u2014 Not an afterthought</li> </ol>"},{"location":"project/about/#the-constitution","title":"The Constitution","text":"<p>This project operates under a strict Constitution that mandates:</p> Principle Meaning No Happy Path Testing Every edge case must be tested No Silent Failures All errors must surface with context Zero Unbounded Growth Memory/CPU must be bounded Audit Everything Every state change is logged <p>Values are enforced by CI, not just written in docs.</p>"},{"location":"project/about/#history","title":"History","text":"Version Date Milestone v0.1 2025-06 Initial release, Nelder-Mead only v0.2 2025-09 PCR algorithm, Python bindings v0.3 2026-01 Safety Executor, TPE, Dashboard v0.4 2026-Q1 (Planned) Helm, OTel, Docker v1.0 2026-Q2 (Planned) GPU, distributed"},{"location":"project/about/#team","title":"Team","text":"<p>ArqonHPO is developed by NovelByte Labs with contributions from the open source community.</p>"},{"location":"project/about/#next-steps","title":"Next Steps","text":"<ul> <li>Roadmap \u2014 What's coming</li> <li>Constitution \u2014 Our principles</li> <li>Contributing \u2014 How to help</li> </ul>"},{"location":"project/changelog/","title":"Changelog","text":"<p>All notable changes to ArqonHPO will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"project/changelog/#030-2026-01-09","title":"[0.3.0] - 2026-01-09","text":""},{"location":"project/changelog/#added","title":"Added","text":"<ul> <li>Safety Executor \u2014 Centralized config updates with guardrails</li> <li>Guardrails presets \u2014 Conservative, Balanced, Aggressive</li> <li>Rollback Policy \u2014 Automatic revert on regressions</li> <li>Dashboard API \u2014 REST endpoints for monitoring</li> <li>TUI \u2014 Terminal interface for real-time monitoring</li> <li>TPE Strategy \u2014 Tree-structured Parzen Estimator</li> <li>ArqonProbe.sample_range() \u2014 Batch LDS sampling</li> <li>ask_one() \u2014 Single candidate for online mode</li> </ul>"},{"location":"project/changelog/#changed","title":"Changed","text":"<ul> <li><code>probe_budget</code> config \u2192 <code>probe_ratio</code> (breaking)</li> <li>Default batch size 4 \u2192 auto-scaled by budget</li> <li>Improved SPSA gradient estimation with trimmed mean</li> </ul>"},{"location":"project/changelog/#fixed","title":"Fixed","text":"<ul> <li>Memory leak in TPE kernel caching</li> <li>Race condition in audit queue flush</li> </ul>"},{"location":"project/changelog/#documentation","title":"Documentation","text":"<ul> <li>Comprehensive reference docs (40+ pages)</li> <li>TUI/Dashboard screenshots</li> <li>Integration guides (K8s, FastAPI, Ray)</li> </ul>"},{"location":"project/changelog/#020-2025-09-15","title":"[0.2.0] - 2025-09-15","text":""},{"location":"project/changelog/#added_1","title":"Added","text":"<ul> <li>PCR Algorithm \u2014 Probe-Classify-Refine pipeline</li> <li>Python bindings \u2014 <code>ArqonSolver</code>, <code>ArqonProbe</code></li> <li>ResidualDecayClassifier \u2014 Landscape classification</li> <li>Multi-Start Nelder-Mead \u2014 Multimodal optimization</li> <li>Scott's Rule TPE Bandwidth \u2014 Adaptive kernel bandwidth</li> <li>CLI commands: <code>ask</code>, <code>tell</code>, <code>interactive</code>, <code>validate</code></li> </ul>"},{"location":"project/changelog/#changed_1","title":"Changed","text":"<ul> <li>Renamed CLI: <code>arqon</code> \u2192 <code>arqonhpo</code></li> <li>Renamed package: <code>arqon</code> \u2192 <code>arqonhpo</code></li> </ul>"},{"location":"project/changelog/#documentation_1","title":"Documentation","text":"<ul> <li>Initial MkDocs site</li> <li>Quickstart guide</li> <li>Python/Rust reference</li> </ul>"},{"location":"project/changelog/#010-2025-06-01","title":"[0.1.0] - 2025-06-01","text":""},{"location":"project/changelog/#added_2","title":"Added","text":"<ul> <li>Initial release</li> <li>Nelder-Mead simplex optimizer</li> <li>Basic CLI: <code>run</code> command</li> <li>Deterministic RNG with ChaCha8</li> <li>State persistence (JSON)</li> <li>Prometheus metrics endpoint</li> </ul>"},{"location":"project/changelog/#upgrade-notes","title":"Upgrade Notes","text":""},{"location":"project/changelog/#02-03","title":"0.2 \u2192 0.3","text":"<ul> <li>Rename <code>probe_budget</code> to <code>probe_ratio</code> in config</li> <li>Update imports: <code>from arqonhpo import ArqonSolver</code></li> <li>Re-export artifacts (schema change)</li> </ul> <p>See Migration Guide for details.</p>"},{"location":"project/changelog/#01-02","title":"0.1 \u2192 0.2","text":"<ul> <li>Complete config rewrite \u2014 recreate configs</li> <li>Package renamed \u2014 update pip install</li> </ul>"},{"location":"project/changelog/#links","title":"Links","text":"<ul> <li>GitHub Releases</li> <li>PyPI</li> <li>Roadmap</li> </ul>"},{"location":"project/ci_cd/","title":"CI/CD Runbook","text":"<p>This guide details the Continuous Integration and Deployment (CI/CD) pipeline for ArqonHPO, managed via GitHub Actions.</p>"},{"location":"project/ci_cd/#quick-reference","title":"\ud83d\udc4b Quick Reference","text":"Action Command / Trigger Run Tests Locally <code>cargo test --workspace</code> Check MSRV <code>manual check required</code> (see below) Fix Formatting <code>cargo fmt --all</code> Run Clippy <code>cargo clippy --workspace</code> Trigger Dependabot Comment <code>@dependabot rebase</code> on PR Cut a Release <code>git tag v0.2.x &amp;&amp; git push origin v0.2.x</code>"},{"location":"project/ci_cd/#pipeline-architecture","title":"\ud83c\udfd7 Pipeline Architecture","text":"<p>Our pipeline (<code>.github/workflows/ci.yml</code>) enforces quality gates on every Pull Request and merge to <code>main</code>.</p>"},{"location":"project/ci_cd/#1-cross-platform-rust-matrix","title":"1. Cross-Platform Rust Matrix","text":"<p>We compile and test on native runners to ensure OS compatibility:</p> <ul> <li>Linux (<code>ubuntu-latest</code>)</li> <li>macOS (<code>macos-latest</code>)</li> <li>Windows (<code>windows-latest</code>)</li> </ul>"},{"location":"project/ci_cd/#2-minimum-supported-rust-version-msrv","title":"2. Minimum Supported Rust Version (MSRV)","text":"<ul> <li>Current MSRV: <code>1.82.0</code></li> <li>Check: Builds <code>cargo build</code> using strict version 1.82 to prevent accidental usage of newer features.</li> <li>Troubleshooting: If this fails but stable passes, you likely used a new Rust feature or updated a dependency to a version that requires a newer Rust.</li> <li>Fix: Downgrade the dependency or pin it (e.g., <code>criterion = \"=0.5.1\"</code>).</li> </ul>"},{"location":"project/ci_cd/#3-python-compatibility-matrix","title":"3. Python Compatibility Matrix","text":"<p>We test bindings against supported Python versions:</p> <ul> <li><code>3.10</code></li> <li><code>3.11</code></li> <li><code>3.12</code></li> </ul>"},{"location":"project/ci_cd/#4-code-quality-benchmarks","title":"4. Code Quality &amp; Benchmarks","text":"<ul> <li>Coverage: Runs <code>cargo tarpaulin</code> and uploads to Codecov. (Excludes <code>arqonhpo</code> bindings due to FFI limits).</li> <li>Benchmarks: Runs <code>cargo bench</code> to detect performance regressions.</li> <li>Docs: Builds the MkDocs site to ensure no broken links or missing plugins.</li> </ul>"},{"location":"project/ci_cd/#dependabot-runbook","title":"\ud83e\udd16 Dependabot Runbook","text":"<p>Dependabot automatically opens PRs to update dependencies.</p>"},{"location":"project/ci_cd/#how-to-rebase","title":"\ud83d\udd04 How to Rebase","text":"<p>If a Dependabot PR is showing red checks because <code>main</code> has changed:</p> <ol> <li>Open the PR.</li> <li>Comment:    <pre><code>@dependabot rebase\n</code></pre></li> <li>Wait for it to rebuild.</li> </ol>"},{"location":"project/ci_cd/#dealing-with-msrv-conflicts","title":"\u274c Dealing with MSRV Conflicts","text":"<p>Sometimes Dependabot bumps a crate to a version that drops support for our MSRV (e.g., bumping <code>criterion</code> to <code>0.8.1</code> which needs Rust 1.86).</p> <p>Solution:</p> <ol> <li>Identify: The CI failure will explicitly say <code>package requires rustc X.XX</code>.</li> <li>Pin: Explicitly pin the older version in <code>Cargo.toml</code>.    <pre><code>[dev-dependencies]\ncriterion = \"=0.5.1\"  # Pinned for MSRV 1.82 compatibility\n</code></pre></li> <li>Close: Manually close the Dependabot PR.</li> </ol>"},{"location":"project/ci_cd/#release-process","title":"\ud83d\ude80 Release Process","text":"<p>Releases are automated via <code>.github/workflows/release.yml</code>.</p>"},{"location":"project/ci_cd/#steps","title":"Steps:","text":"<ol> <li>Update Version: Bump version in <code>Cargo.toml</code> and run <code>cargo build</code> to update <code>Cargo.lock</code>.</li> <li>Commit: Merge version bump to <code>main</code>.</li> <li>Tag: <pre><code>git tag v0.3.0\ngit push origin v0.3.0\n</code></pre></li> <li>Automation: GitHub Actions will:</li> <li>Build binaries for Linux, macOS, and Windows.</li> <li>Build Python wheels (manylinux, macos, windows).</li> <li>Generate SLSA Provenance attestation.</li> <li>Generate SBOM (Software Bill of Materials).</li> <li>Create a GitHub Release with artifacts attached.</li> </ol>"},{"location":"project/ci_cd/#security","title":"Security","text":"<ul> <li>SLSA Level 3: We generate provenance for all build artifacts to prevent supply chain attacks.</li> <li>SBOM: A CycloneDX Software Bill of Materials is generated for every release.</li> </ul>"},{"location":"project/ci_cd/#hard-learned-cicd-notes","title":"\u2705 Hard-Learned CI/CD Notes","text":"<ul> <li>Unique release asset names: Release uploads must have unique basenames. If multiple artifacts are named the same (e.g., <code>arqonhpo</code>), <code>action-gh-release</code> can fail or overwrite assets.</li> <li>SLSA subjects are required: The SLSA generator needs <code>base64-subjects</code>; generate a <code>sha256sum</code> list of artifacts and pass it to the provenance job.</li> <li>Publish after release creation: If provenance or other jobs upload assets, avoid doing so before the GitHub Release exists. Otherwise uploads can fail.</li> <li>PyPI is the canonical channel: Publish Python packages to PyPI for the standard install path.</li> <li>Tag triggers matter: Release/publish workflows trigger on tags. If you fix a workflow, move the tag to the new commit and push the tag.</li> </ul>"},{"location":"project/ci_cd/#local-development-commands","title":"\ud83d\udee0 Local Development Commands","text":"<p>Before pushing, run the full checklist below (CI assumes these are clean):</p> <pre><code># 1. Format code\ncargo fmt --all\n\n# 2. Catch common mistakes\ncargo clippy --workspace --all-targets -- -D warnings\n\n# 3. Run tests\ncargo test --workspace\n\n# 4. MSRV check (mirrors CI stable job)\n# Run this before merging to catch dependency issues early.\n# The `ship` crate is excluded due to heavy transitive deps.\ncargo check --workspace --exclude ship\n\n# 5. Run documentation site locally\nmkdocs serve\n</code></pre>"},{"location":"project/ci_cd/#local-code-coverage-testing","title":"Local Code Coverage Testing","text":"<p>Before pushing, verify test coverage locally to catch gaps before CI reports them. This uses <code>cargo-llvm-cov</code> for accurate coverage measurement.</p>"},{"location":"project/ci_cd/#setup-one-time","title":"Setup (one-time)","text":"<pre><code># Install cargo-llvm-cov\ncargo install cargo-llvm-cov\n\n# Install llvm-tools (required component)\nrustup component add llvm-tools-preview\n</code></pre>"},{"location":"project/ci_cd/#running-coverage-locally","title":"Running Coverage Locally","text":"<pre><code># Quick summary (text output)\ncargo llvm-cov --workspace --exclude ship\n\n# Detailed HTML report (opens in browser)\ncargo llvm-cov --workspace --exclude ship --html --open\n\n# Show uncovered lines for specific files\ncargo llvm-cov --workspace --exclude ship --show-missing-lines\n\n# Check only specific crate\ncargo llvm-cov -p arqonhpo-cli --show-missing-lines\n</code></pre>"},{"location":"project/ci_cd/#coverage-pre-push-checklist","title":"Coverage Pre-Push Checklist","text":"<p>Before pushing code changes, especially new features:</p> <ol> <li>Run coverage: <code>cargo llvm-cov --workspace --exclude ship --show-missing-lines</code></li> <li>Check for uncovered lines: Focus on new/modified files</li> <li>Add tests for gaps: Target functions with 0% coverage</li> <li>Re-run to verify: Ensure coverage improves</li> <li>Then push: <code>git push origin HEAD</code></li> </ol>"},{"location":"project/ci_cd/#coverage-targets","title":"Coverage Targets","text":"Component Target Current Core crate &gt;80% ~75% CLI crate &gt;60% ~45% Hotpath crate &gt;70% ~70% Ship crate &gt;50% ~40%"},{"location":"project/constitution/","title":"Constitution","text":""},{"location":"project/constitution/#arqonhpo-constitution","title":"ArqonHPO Constitution","text":"<p>Version: 1.4.1 Ratification Date: 2025-12-13 Last Amended: 2025-12-17</p> <p>This document defines the non-negotiable principles that govern how ArqonHPO is designed, evolved, and maintained.</p> <p>It exists to protect ArqonHPO from accidental bloat, regression, silent breakage, and \u201cclever\u201d shortcuts that erode trust.</p> <p>If a decision conflicts with this constitution, the decision is wrong.</p> <p>Spec Kit Note: This constitution is the hard sandbox for all <code>/speckit.*</code> commands. Specs, plans, and tasks must not violate the constraints in Sections II\u2013XI.</p>"},{"location":"project/constitution/#ultimate-integrity-covenant","title":"ULTIMATE INTEGRITY COVENANT","text":"<p>This constitution is a hard constraint on all engineering work. It exists to prevent the failure modes that destroy real systems:</p> <ul> <li>\u201cHappy path\u201d engineering that collapses under real inputs</li> <li>Pseudocode / placeholders / stubs presented as completion</li> <li>Tests that \u201ccheck boxes\u201d but don\u2019t model production reality</li> <li>Fake evidence (invented logs, benchmarks, screenshots, coverage, results)</li> <li>Unnamed technical debt that silently becomes permanent</li> <li>Silent failure handling and silent security degradation</li> <li>Undocumented complexity and unreadable \u201cclever\u201d code</li> <li>Non-reproducible builds, non-deterministic behavior, and flaky verification</li> <li>Work products that are narrative-only, vague, or unverifiable</li> </ul> <p>If a decision conflicts with this covenant, the decision is wrong.</p>"},{"location":"project/constitution/#a-the-only-acceptable-meaning-of-done-the-8-pillar-standard","title":"A. The Only Acceptable Meaning of \u201cDONE\u201d (The 8-Pillar Standard)","text":"<p>A change is NOT DONE until all eight pillars are true:</p> <ol> <li>Implementation</li> <li>Real code exists (not pseudocode). It compiles, runs, and handles edge cases.</li> <li>Invalid states are rejected; invariants are enforced.</li> <li> <p>Failure behavior is explicit: timeouts, retries, backpressure, cancellation, and partial failures are defined.</p> </li> <li> <p>Verification</p> </li> <li>Automated tests cover normal + failure + adversarial + concurrency/ordering behavior.</li> <li>Tests model production complexity, not toy inputs.</li> <li> <p>Where appropriate: property-based tests, fuzzing, chaos/fault injection, and regression tests exist.</p> </li> <li> <p>Documentation</p> </li> <li>In-repo docs explain: architecture, usage, invariants, data contracts, and \u201cwhat can go wrong.\u201d</li> <li>Operational caveats are explicit: limits, failure modes, rollback strategy, and safety constraints.</li> <li> <p>Every public behavior change updates docs and/or changelog.</p> </li> <li> <p>Evidence</p> </li> <li>Reproducible proof exists (CI artifacts, logs, traces, coverage reports, benchmarks).</li> <li>Evidence is not implied; it is attached or linkable to a specific commit/run.</li> <li> <p>If there is no evidence, the claim is false.</p> </li> <li> <p>Traceability</p> </li> <li>Each requirement / acceptance criterion maps to:<ul> <li>code locations,</li> <li>test locations,</li> <li>documentation locations,</li> <li>evidence artifacts.</li> </ul> </li> <li> <p>No orphan requirements. No orphan code. No untested requirements.</p> </li> <li> <p>Operational Readiness</p> </li> <li>Safe defaults, explicit configuration validation, and clear failure signals exist.</li> <li>Observability exists: structured logs + metrics + tracing (or an equivalent breadcrumb system).</li> <li> <p>Rollout/rollback exists where relevant; migrations are reversible or explicitly irreversible.</p> </li> <li> <p>Security &amp; Safety Readiness</p> </li> <li>Threat assumptions are stated. Privilege boundaries are validated.</li> <li>Secrets are not logged; sensitive data is redacted.</li> <li> <p>Fail-closed behavior is defined for safety/security modules (no silent \u201callow\u201d).</p> </li> <li> <p>Task Completeness</p> </li> <li>Work is decomposed into a concrete task list (not vague bullets).</li> <li>Each task includes acceptance criteria, a test hook, and an evidence hook.</li> <li>If a task is not done, the work is not done.</li> </ol> <p>Rule: Declaring \u201cdone\u201d without satisfying every pillar is deception.</p>"},{"location":"project/constitution/#b-the-anti-half-ass-rules-merge-blocking-by-definition","title":"B. The Anti-Half-Ass Rules (Merge-Blocking by Definition)","text":""},{"location":"project/constitution/#b1-no-pseudocode-as-deliverable","title":"B1. No Pseudocode-as-Deliverable","text":"<ul> <li>Pseudocode may exist only as clearly labeled design notes.</li> <li>Pseudocode cannot be the \u201csolution,\u201d cannot substitute for tests, and cannot be used to claim completion.</li> </ul>"},{"location":"project/constitution/#b2-no-placeholders-no-stubs-no-later","title":"B2. No Placeholders / No Stubs / No \u201cLater\u201d","text":"<p>Forbidden in production paths:</p> <ul> <li><code>TODO</code>, <code>FIXME</code>, <code>pass</code>, <code>todo!()</code>, empty handlers, commented-out behavior, \u201cmock later,\u201d \u201chardening later,\u201d \u201cedge cases later.\u201d   If incomplete behavior must exist temporarily, it must:</li> <li>be feature-flagged OFF by default,</li> <li>be isolated so it cannot affect production behavior,</li> <li>have a <code>TD-###</code> record with TTL (see Debt Policy).</li> </ul>"},{"location":"project/constitution/#b3-no-fake-data-no-toy-inputs-no-lazy-synthetics","title":"B3. No Fake Data, No Toy Inputs, No Lazy Synthetics","text":"<ul> <li>Tests and examples must use production-like complexity: realistic IDs, nested payloads, boundary sizes, malformed variants, weird unicode/whitespace, and adversarial inputs.</li> <li>Ban list (unless the test is explicitly about these literals): <code>foo</code>, <code>bar</code>, <code>user_1</code>, <code>test123</code>, \u201chello world.\u201d</li> </ul>"},{"location":"project/constitution/#b4-no-happy-path-testing","title":"B4. No Happy Path Testing","text":"<p>For any externally coupled feature (filesystem, subprocesses, network, storage, package backends), tests must cover:</p> <ul> <li>timeouts, retries, partial failures, malformed responses, permission failures, cancellation, overload/backpressure, and out-of-order/duplicate events where relevant.</li> </ul>"},{"location":"project/constitution/#b5-no-silent-failures","title":"B5. No Silent Failures","text":"<ul> <li>Swallowing errors is forbidden. Every error must be handled, logged with context, or propagated.</li> <li>\u201cFallback to success\u201d behavior without explicit documentation and tests is forbidden.</li> </ul>"},{"location":"project/constitution/#b6-warnings-are-errors","title":"B6. Warnings Are Errors","text":"<ul> <li>Compiler, linter, formatter, typechecker warnings block merge. \u201cIt builds on my machine\u201d is irrelevant.</li> </ul>"},{"location":"project/constitution/#b7-no-unbounded-risk","title":"B7. No Unbounded Risk","text":"<ul> <li>Unbounded queues, unbounded memory growth, unbounded metric cardinality, unbounded retries, and unbounded timeouts are forbidden.</li> <li>If something can grow, it must have a cap. If it can retry, it must have a budget. If it can wait, it must have a timeout.</li> </ul>"},{"location":"project/constitution/#c-technical-debt-policy-zero-debt-unless-named-owned-expiring","title":"C. Technical Debt Policy (Zero Debt Unless Named + Owned + Expiring)","text":"<p>Technical debt is forbidden by default. If debt must exist, it must be explicit, bounded, and temporary.</p> <p>Debt is valid only if it is recorded as <code>TD-###</code> and includes:</p> <ul> <li>owner,</li> <li>scope and blast radius,</li> <li>why it exists,</li> <li>the exact exit criteria (\u201cdebt is removed when\u2026\u201d),</li> <li>remediation plan,</li> <li>hard TTL date,</li> <li>tests guarding the boundary so the debt cannot silently expand.</li> </ul> <p>Rules:</p> <ul> <li>Debt without TTL is invalid.</li> <li>Debt past TTL blocks merge/release.</li> <li>\u201cWe\u2019ll fix later\u201d is not a plan.</li> <li>\u201cTemporary\u201d code paths must have an explicit sunset mechanism.</li> </ul>"},{"location":"project/constitution/#d-sdd-tdd-contract-professional-standard","title":"D. SDD + TDD Contract (Professional Standard)","text":""},{"location":"project/constitution/#d1-specification-driven-design-requirements-for-non-trivial-changes","title":"D1. Specification-Driven Design Requirements (for non-trivial changes)","text":"<p>A valid spec includes:</p> <ul> <li>intent and non-goals,</li> <li>acceptance criteria (falsifiable),</li> <li>invariants (must-always-be-true),</li> <li>failure modes and expected behavior under each,</li> <li>compatibility rules (protocol/API/schema expectations),</li> <li>performance envelope and resource bounds (when relevant),</li> <li>security/privacy assumptions and constraints,</li> <li>operational concerns (observability, rollout/rollback, migration notes).</li> </ul> <p>If the spec is ambiguous, the first task is to remove ambiguity by producing falsifiable criteria.</p>"},{"location":"project/constitution/#d2-test-driven-development-requirements","title":"D2. Test-Driven Development Requirements","text":"<ul> <li>Tests define behavior before/with implementation (TDD by default).</li> <li>Refactors require existing tests protecting behavior.</li> <li>Every bug fix includes a regression test that fails pre-fix and passes post-fix.</li> <li>Flaky tests are critical bugs; they must be fixed, not ignored.</li> </ul>"},{"location":"project/constitution/#e-verification-constitution-realism-adversarial-failure-first","title":"E. Verification Constitution (Realism + Adversarial + Failure-First)","text":"<p>Required test categories (as applicable):</p> <ul> <li>unit tests for pure logic (fast, no external deps),</li> <li>integration tests for boundaries and real dependency interactions,</li> <li>property-based tests for parsers/validators/protocol/config boundaries,</li> <li>fuzz tests for user-controlled input surfaces,</li> <li>concurrency/ordering tests for races, duplicates, replays, idempotency,</li> <li>chaos/fault injection for externally coupled behaviors,</li> <li>performance regression checks for hot paths or stated latency budgets.</li> </ul> <p>Verification must explicitly test:</p> <ul> <li>malformed inputs,</li> <li>partial reads/writes,</li> <li>timeout handling,</li> <li>retry policy and idempotency guarantees,</li> <li>permission boundaries,</li> <li>overload/backpressure behavior,</li> <li>deterministic ordering assumptions (or explicit non-guarantees).</li> </ul>"},{"location":"project/constitution/#f-the-claim-ledger-mandatory-honesty","title":"F. The Claim Ledger (Mandatory Honesty)","text":"<p>Any claim like \u201cworks,\u201d \u201cdone,\u201d \u201cfixed,\u201d \u201csecure,\u201d \u201cfast,\u201d \u201ccompatible,\u201d \u201cproduction-ready\u201d must be labeled:</p> <ul> <li>Observed: executed + evidence attached</li> <li>Derived: reasoned + assumptions listed + risks stated</li> <li>Unverified: not tested + the exact minimal experiment provided</li> </ul> <p>Presenting Derived/Unverified claims as Observed is lying.</p>"},{"location":"project/constitution/#g-minimum-acceptable-deliverable-non-negotiable-output-shape","title":"G. Minimum Acceptable Deliverable (Non-Negotiable Output Shape)","text":"<p>Any non-trivial work product must include all of:</p> <ul> <li>a concrete task list with acceptance criteria per task,</li> <li>a file-level plan (what files change/add/remove),</li> <li>implementation code,</li> <li>tests (including failure/adversarial coverage where relevant),</li> <li>documentation updates,</li> <li>an Evidence Pack (defined in the footer).</li> </ul> <p>If any part is incomplete, it must be explicitly labeled Unverified and paired with the shortest experiment that would verify it.</p>"},{"location":"project/constitution/#h-default-principles","title":"H. Default Principles","text":"<p>If a situation, decision, or design choice is not explicitly covered by this Constitution, the default principle is to:</p> <ul> <li>Adopt the most stringent, resilient, and transparent posture.</li> <li>Enforce the primacy of operational integrity, unambiguous intent, and disciplined scaling.</li> <li>Treat unresolved ambiguity as a Constitutional void, demanding immediate and formal amendment.</li> </ul>"},{"location":"project/constitution/#i-vision-and-scope","title":"I. Vision and Scope","text":""},{"location":"project/constitution/#1-the-vision","title":"1. The Vision","text":"<p>ArqonHPO is a probe-gated optimization engine for time-to-target\u2014and a runtime control primitive for microsecond-latency adaptation.</p> <p>It is built to be clearly competitive for two product-aligned use cases:</p> <ol> <li>Fast simulation tuning: expensive evaluations (milliseconds to seconds) where reaching a useful threshold quickly matters.</li> <li>Sklearn-style model tuning: moderate-cost evaluations where optimizer overhead is material and \"good-enough quickly\" often wins.</li> </ol> <p>Control Primitive Posture: Once the decision loop operates at microseconds, optimization is treated as a feedback control primitive. The system's job is to steer toward homeostasis under changing conditions (drift, load, hardware throttling) using bounded changes. This is achieved through:</p> <ul> <li>Discovery Offline, Adaptation Online: Offline discovery (Tier \u03a9) generates and evaluates candidates; online adaptation (Tier 2) selects among approved variants and proposes bounded deltas.</li> <li>Law Control: Online tuning of \"physics knobs\" (diffusion, noise, decay, damping, constraint weights) within allowlisted parameters and strict safety envelopes.</li> <li>Microsecond Latency: ArqonHPO is designed for 1\u201310ms decision latency, enabling embedding in live control loops without blocking the dataplane.</li> </ul>"},{"location":"project/constitution/#2-the-scope","title":"2. The Scope","text":"<p>To achieve this vision, we must be ruthless about what ArqonHPO is and what it is not.</p>"},{"location":"project/constitution/#21-in-scope-the-core-product","title":"2.1 In Scope (The Core Product)","text":"<p>ArqonHPO is probe-gated optimization and runtime adaptation. It is responsible for:</p> <ul> <li>The Probe Phase: Deterministic sampling to gather an initial signal and candidates.</li> <li>The Classification Phase: A fixed-size test that labels the landscape (e.g., structured vs chaotic) and produces a score.</li> <li>The Mode Selection Phase: Selecting a refinement strategy based on the classification result.</li> <li>The Refinement Phase: Executing the chosen optimizer within the remaining budget.</li> <li>Audit Artifacts: Schema-versioned run artifacts sufficient for replay and accountability.</li> <li>Systems/Infrastructure Knobs: Tuning database parameters, connection pools, cache sizes, and runtime configurations in bounded, safe, auditable ways.</li> <li>Runtime Law Tuning: Adjusting simulation/physics parameters (e.g., diffusion rates, constraint weights) within safety envelopes during online operation.</li> </ul>"},{"location":"project/constitution/#22-out-of-scope-the-boundaries","title":"2.2 Out of Scope (The Boundaries)","text":"<p>ArqonHPO is not:</p> <ul> <li>A general-purpose ML training framework. It tunes; it does not train end-to-end pipelines.</li> <li>A distributed execution platform. It may integrate with external evaluators, but it does not provide a cluster runtime.</li> <li>A \u201cguaranteed best on all objectives\u201d optimizer. Claims must be scoped to the benchmark suite and use cases.</li> </ul>"},{"location":"project/constitution/#3-the-strategic-horizon","title":"3. The Strategic Horizon","text":"<p>We define evolution in three distinct epochs. Engineering decisions must align with the current epoch while reserving capacity for the next.</p> <ul> <li>Epoch 1: The Foundation (Deterministic probe-gated core).</li> <li>Focus: determinism, bounded overhead, artifact auditability, and time-to-target benchmarking.</li> <li>Goal: be measurably competitive on the two target use cases.</li> <li>Epoch 2: The Platform (Composable strategies).</li> <li>Focus: pluggable backends, richer classification signals, replay tooling.</li> <li>Goal: support multiple strategies without breaking contracts.</li> <li>Epoch 3: The Research Frontier (Optional).</li> <li>Focus: experimental samplers, meta-controllers, and novel structural probes.</li> <li>Goal: enable experimentation without contaminating production defaults.</li> </ul>"},{"location":"project/constitution/#ii-core-principles","title":"II. Core Principles","text":"<p>This section defines the engineering laws that govern ArqonHPO. These are not guidelines; they are constraints. Code that violates these principles will be rejected during Review.</p>"},{"location":"project/constitution/#1-architectural-invariance-the-gate-pattern","title":"1. Architectural Invariance (The Gate Pattern)","text":"<p>The system is composed of four non-negotiable phases. Strict adherence to the probe-gated pipeline is required to prevent coupling and ensure reproducibility.</p> <p>The Phases:</p> <ul> <li>Probe: deterministic sampling; gathers initial candidates and signal.</li> <li>Classify: fixed-size classification; emits score + label.</li> <li>Select: chooses refinement mode based on classification.</li> <li>Refine: executes the chosen optimizer within the remaining budget.</li> </ul> <p>The Bypass Ban:</p> <p>No phase may be skipped because it is \u201cconvenient.\u201d</p> <ul> <li>Forbidden: Selecting a refinement mode without running classification.</li> <li>Forbidden: Adding hidden objective calls that do not count against budget.</li> <li>Forbidden: Silent fallbacks that change mode/behavior without artifacts and tests.</li> </ul>"},{"location":"project/constitution/#2-statelessness-state-explicit-ness","title":"2. Statelessness &amp; State Explicit-ness","text":"<p>To ensure runs can be reproduced and audited, we adhere to a Stateless Where Possible philosophy.</p> <ul> <li>Run Ephemerality: Any process must be able to crash and restart without corrupting an ongoing run artifact.</li> <li>State Explicitness: All non-trivial solver state must be explicit, serializable, and captured in artifacts if it affects decisions.</li> <li>Seed Sovereignty: All randomness must come from explicit seeds; hidden global RNG use is forbidden.</li> </ul>"},{"location":"project/constitution/#3-contract-sovereignty-typed-inputs-versioned-artifacts","title":"3. Contract Sovereignty (Typed Inputs, Versioned Artifacts)","text":"<p>We enforce a strict separation between machine-stable contracts and human-readable debugging.</p> <p>Typed Contracts:</p> <p>Configuration and run inputs must be expressed in typed structures. The config contract is the single source of truth for defaults and validation.</p> <p>Artifact Reservations:</p> <p>Artifacts are schema-versioned and must be stable and replayable. Logs are diagnostics and must not be required for replay.</p>"},{"location":"project/constitution/#4-future-proofing-hooks-the-moonshot-mandate","title":"4. Future-Proofing Hooks (The Moonshot Mandate)","text":"<p>To enable future experimentation without requiring a rewrite, v1.0 must reserve capacity for:</p> <ul> <li>Backend Hook: Ability to select a refinement backend via a stable interface.</li> <li>Classifier Hook: Ability to extend classification signals while preserving the fixed-size gating contract.</li> <li>Objective Guard Hook: Ability to wrap objectives for timeouts/redaction without changing the solver core.</li> <li>Replay Hook: Ability to replay decisions from artifacts.</li> </ul>"},{"location":"project/constitution/#5-semantic-versioning-compatibility","title":"5. Semantic Versioning &amp; Compatibility","text":"<p>We adhere to strict Semantic Versioning regarding the Public API and Artifact Schemas.</p> <p>Versioning Rules:</p> <ul> <li>MAJOR: Breaking changes to solver public API, artifact schema, or core behavior.</li> <li>MINOR: New modes, additive fields (optional), new telemetry, or non-breaking enhancements.</li> <li>PATCH: Bug fixes, performance improvements, and clarifications.</li> </ul> <p>Stealth Ban:</p> <p>There shall be no \"stealth\" breaking changes in MINOR or PATCH versions. Ever.</p>"},{"location":"project/constitution/#6-data-isolation-privacy-the-bulkhead","title":"6. Data Isolation &amp; Privacy (The Bulkhead)","text":"<p>Optimization objectives may embed sensitive information.</p> <ul> <li>Isolation: Objective payloads are treated as sensitive by default.</li> <li>Redaction: Logs/artifacts must not leak secrets or tenant data.</li> <li>Sharing Safety: Artifacts intended for sharing must support redaction without breaking replayability guarantees.</li> </ul>"},{"location":"project/constitution/#7-security-by-design","title":"7. Security by Design","text":"<p>Security is a baseline constraint, not a feature.</p> <ul> <li>Zero Trust: The solver does not trust the objective; it validates inputs and guards execution.</li> <li>Fail Closed: If a safety/guard module fails, times out, or crashes, the run is failed explicitly. It is never \"allowed by default.\"</li> <li>Secure Defaults: Unsafe execution modes must be opt-in and auditable.</li> </ul>"},{"location":"project/constitution/#8-programmable-safety-guards","title":"8. Programmable Safety (Guards)","text":"<p>We reject hardcoded, silent safety logic. Safety requirements vary by environment.</p> <ul> <li>Guard Middleware: Objective guards (timeouts, resource caps, redaction) must be composable.</li> <li>Fail Closed Mandate: If a guard times out, crashes, or returns an error, execution is blocked and surfaced.</li> <li>Bounded Execution: All guards must have strict, non-negotiable limits.</li> </ul>"},{"location":"project/constitution/#9-run-as-artifact-the-capsule-principle","title":"9. Run-as-Artifact (The Capsule Principle)","text":"<p>Runs are not just ephemeral computations. They must produce replayable artifacts.</p> <ul> <li>Digital DNA: The system is optimized to transport the potential (seed + config + bounds + decisions), not just the result.</li> <li>Replayability: A run can be reconstructed from the artifact plus the objective.</li> </ul>"},{"location":"project/constitution/#10-delta-first-evidence","title":"10. Delta-First Evidence","text":"<p>Computation cost and audit burden scale with change ($\\Delta$).</p> <ul> <li>Diff over Snapshot: Prefer per-eval traces and incremental evidence over opaque summaries.</li> <li>Causal Integrity: Decisions and their inputs must be recorded in order.</li> </ul>"},{"location":"project/constitution/#11-circuit-first-benchmarking","title":"11. Circuit-First Benchmarking","text":"<p>Benchmarks are declarative.</p> <ul> <li>Bench Suites are Circuits: Benchmark suites define objectives, budgets, targets, and seed suites as configuration.</li> <li>Decoupled Objectives: Objectives remain oblivious to optimizer internals.</li> </ul>"},{"location":"project/constitution/#12-probe-algorithm-specification","title":"12. Probe Algorithm Specification","text":"<p>Production probes MUST use mathematically validated low-discrepancy sequences.</p> <ul> <li>Default Algorithm: Kronecker/Weyl sequences with irrational slopes derived from prime square roots (e.g., <code>PrimeSqrtSlopesRotProbe</code>).</li> <li>Banned Patterns: The <code>p/1000</code> heuristic and rational-slope sequences are forbidden due to collision and striping artifacts.</li> <li>Anytime Property: Probe quality of first K samples MUST NOT depend on total N.</li> <li>Randomization: Cranley-Patterson (CP) shifts are the approved QMC randomization mechanism. Global RNG injection into base sequences is forbidden.</li> <li>Robustness Hedge: A configurable <code>random_spice_ratio</code> (default 10%) of uniform random points hedges against multimodal fragility.</li> </ul>"},{"location":"project/constitution/#13-dimension-type-contract","title":"13. Dimension Type Contract","text":"<p>Optimization geometry must respect dimension semantics.</p> Scale Arithmetic Contract Linear Euclidean Standard distance, mean Log Log-space Euclidean Transform \u2192 operate \u2192 inverse Periodic Circular/Toroidal <code>wrap01</code>, <code>diff01</code>, <code>circular_mean01</code> <ul> <li>NM on Periodic: Reflection, expansion, and contraction operations MUST use circular arithmetic (wrap at bounds).</li> <li>Probe on Periodic: Samples MUST respect toroidal topology (no edge bias).</li> <li>Canonical Helpers: <code>wrap01(x)</code>, <code>diff01(a,b)</code>, <code>circular_mean01(values)</code> are the canonical implementations.</li> </ul>"},{"location":"project/constitution/#14-multi-start-strategy-contract","title":"14. Multi-Start Strategy Contract","text":"<p>Refinement strategies may use parallel starts for diversity.</p> <ul> <li>K-Parallel Starts: Multi-start strategies run K independent NM instances from diverse seed points.</li> <li>Diversity Seeding: Farthest-point selection from top-K\u00d7(dim+1) pool. Clustered seeding is forbidden.</li> <li>Triage Budget: Each start gets a bounded triage budget before commitment decisions.</li> <li>Stall Detection: Stall threshold triggers start rotation; unbounded stalling is forbidden.</li> </ul>"},{"location":"project/constitution/#15-parallel-sharding-contract","title":"15. Parallel Sharding Contract","text":"<p>Probes must support stateless parallel execution.</p> <ul> <li>Stateless Sharding: A probe MUST produce identical samples for (seed, index) regardless of worker count.</li> <li>Collision-Free: Disjoint index ranges MUST produce disjoint samples.</li> <li>SDK Parity: <code>ArqonProbe</code> (Python) MUST expose identical behavior to Rust core.</li> <li>Verification: Bitwise hash of sorted sample coordinates MUST match single-worker vs multi-worker configurations.</li> </ul>"},{"location":"project/constitution/#16-adaptive-engine-specification","title":"16. Adaptive Engine Specification","text":"<p>Online parameter adaptation MUST use validated optimization algorithms with mandatory safety layers.</p> Aspect Requirement Default Algorithm SPSA (Simultaneous Perturbation Stochastic Approximation) \u2014 2 evaluations per gradient estimate, regardless of dimension Banned Patterns Finite-difference gradients (O(n) evals), unbounded learning rates, global step sizes without decay Decay Schedule <code>a_k = a\u2080/(k+1+A)^\u03b1</code> and <code>c_k = c\u2080/(k+1)^\u03b3</code> with standard exponents (\u03b1=0.602, \u03b3=0.101) Perturbation \u00b11 Bernoulli (symmetric) ONLY; Gaussian perturbations are forbidden due to heavy tails Determinism Same (seed, iteration) MUST produce identical perturbation vectors State Machine Ready \u2192 WaitingPlus \u2192 WaitingMinus \u2192 Ready (strict 2-eval cycle) <ul> <li>Canonical Implementation: <code>Spsa</code> struct with <code>ChaCha8Rng</code> for deterministic perturbations.</li> <li>Budget Enforcement: Each adaptation cycle MUST complete within <code>budget_us</code> microseconds.</li> </ul>"},{"location":"project/constitution/#17-safety-executor-contract","title":"17. Safety Executor Contract","text":"<p>All configuration updates MUST pass through <code>SafetyExecutor</code>. Direct writes to live config are forbidden.</p> Guardrail Default Contract <code>max_delta_per_step</code> 0.1 (10%) Absolute parameter change cap per update <code>max_updates_per_second</code> 10.0 Rate limit for stability <code>min_interval_us</code> 100,000 (100ms) Minimum cooldown between updates <p>Violation Types (MUST block, not just log):</p> Violation Trigger <code>DeltaTooLarge</code> Change exceeds <code>max_delta_per_step</code> <code>RateLimitExceeded</code> Updates exceed <code>max_updates_per_second</code> <code>OutOfBounds</code> Proposed value outside domain bounds <code>UnknownParameter</code> Parameter not in allowlist (allowlist pattern mandatory) <ul> <li>Rollback Requirement: Every config swap MUST preserve a baseline for rollback. Rollback-free execution is forbidden.</li> <li>Fail Closed: If <code>validate_delta()</code> returns <code>Err(Violation)</code>, the update is rejected entirely\u2014partial application is forbidden.</li> </ul>"},{"location":"project/constitution/#18-atomic-configuration-contract","title":"18. Atomic Configuration Contract","text":"<p>Configuration swaps MUST be atomic with no torn reads in the control loop.</p> Requirement Implementation Atomicity Arc-swap semantics with RwLock or true atomic primitives Generation Counter Monotonically increasing <code>u64</code>, observable by readers Zero-Allocation Hot Path <code>snapshot()</code> MUST NOT allocate (cheap Arc clone only) No Mutex Contention Writers MUST NOT block readers in steady state <ul> <li>Canonical Types: <code>AtomicConfig</code> (container) and <code>ConfigSnapshot</code> (immutable view with params + generation).</li> <li>Thread Safety: All methods on <code>AtomicConfig</code> MUST be <code>Send + Sync</code>.</li> </ul>"},{"location":"project/constitution/#19-telemetry-digest-contract","title":"19. Telemetry Digest Contract","text":"<p>Streaming telemetry MUST be compact, fixed-schema, and lock-free in the push path.</p> Field Type Required <code>timestamp_us</code> u64 \u2713 <code>objective_value</code> f64 \u2713 <code>latency_p99_us</code> Option \u2014 <code>throughput_rps</code> Option \u2014 <code>error_rate</code> Option \u2014 <code>constraint_margin</code> Option \u2014 <ul> <li>Ring Buffer: Fixed-capacity <code>TelemetryRingBuffer</code>, overflow evicts oldest. No dynamic allocation in <code>push()</code>.</li> <li>Size Budget: <code>TelemetryDigest</code> MUST fit in \u2264128 bytes for cache efficiency.</li> <li>Minimal Helpers: <code>TelemetryDigest::objective(value)</code> and <code>TelemetryDigest::with_timestamp(ts, value)</code> are the canonical constructors.</li> </ul>"},{"location":"project/constitution/#20-tier-architecture-model","title":"20. Tier Architecture Model","text":"<p>ArqonHPO operates with a strict three-tier architecture. These tiers are non-optional and govern all runtime behavior.</p> Tier Role Responsibilities Prohibitions Tier 1 (Safe Executor) Sole actuator AtomicConfig swap, allowlist enforcement, bounds checking, max-delta limits, rate limits, rollback/snapback, audit emission Cannot skip guardrails; cannot apply unevaluated proposals Tier 2 (Adaptive Engine) Proposal generator Reads telemetry digests, proposes bounded deltas, selects among approved variants Cannot mutate production state directly; must be deterministic and time-budgeted Tier \u03a9 (Offline Discovery) Candidate generator Runs continuously or periodically, generates new law families / architecture candidates, outputs diagnostic artifacts Never in the hot path; outputs are candidates only, not direct actions <p>Tier 1 Contract:</p> <ul> <li>The only component allowed to apply changes to production state.</li> <li>Enforces allowlist (unknown parameters \u2192 rejection), bounds (out-of-bounds \u2192 rejection), max-delta (per-step change cap), rate limits, and rollback requirements.</li> <li>Must be deterministic: same (config, proposal) \u2192 same outcome.</li> </ul> <p>Tier 2 Contract:</p> <ul> <li>Reads compact telemetry digests from Tier 1's observation surface.</li> <li>Proposes deltas or selects among approved variants.</li> <li>All proposals go through Tier 1's guardrails before application.</li> <li>Must complete within <code>budget_us</code> microseconds.</li> </ul> <p>Tier \u03a9 Contract:</p> <ul> <li>Runs in background / batch mode, never blocking the control loop.</li> <li>Outputs candidates that must pass offline evaluation and promotion gates before entering the Approved Variant Catalog.</li> <li>Outputs are labeled \"diagnostic\" or \"candidate,\" never \"decision.\"</li> </ul>"},{"location":"project/constitution/#21-merge-blocking-tier-rules","title":"21. Merge-Blocking Tier Rules","text":"<p>The following are merge-blocking rules. Pull requests violating these MUST NOT be merged.</p> Rule Violation Tier-2 cannot mutate production state Any code path where Tier 2 writes to AtomicConfig without going through Tier 1 Tier-1 is sole actuator Any direct config mutation outside SafetyExecutor Tier-\u03a9 outputs are candidates only Any code path where \u03a9 output is applied to production without promotion gate Tier boundaries are explicit Tier logic mixed without clear module separation"},{"location":"project/constitution/#22-variant-catalog-contract","title":"22. Variant Catalog Contract","text":"<p>The Approved Variant Catalog is the safety boundary for discrete configuration choices.</p> <p>Lifecycle States:</p> State Description Online Eligible Draft Initial candidate, not yet evaluated \u274c Evaluated Offline evaluation completed, results documented \u274c Approved Passed promotion gate, eligible for production selection \u2705 Promoted Currently active in production selection pool \u2705 Archived Retired from active use, retained for replay \u274c <p>Promotion Requirements:</p> <ul> <li>Offline evaluation evidence (benchmark results, safety metrics)</li> <li>Documented constraints (bounds, applicability conditions)</li> <li>Rollback plan (how to revert if issues arise)</li> <li>Evidence pack attached to promotion record</li> </ul> <p>Selection Rules:</p> <ul> <li>Runtime MUST only select among <code>Approved</code> or <code>Promoted</code> variants.</li> <li><code>Draft</code> and <code>Evaluated</code> variants are NEVER eligible for online selection.</li> <li>Online \"NAS-like\" behavior is selection among approved variants, not live invention.</li> </ul> <p>Schema Requirements:</p> <ul> <li>Variants must have unique IDs, version numbers, and creation timestamps.</li> <li>Variants must be tied to reproducible artifacts and replay seeds.</li> <li>Variant transitions must be audited (who, when, why).</li> </ul>"},{"location":"project/constitution/#23-safety-semantics-for-co-evolving-laws","title":"23. Safety Semantics for Co-evolving Laws","text":"<p>Clarification: \"Laws\" and \"physics\" in this constitution refer to simulation/runtime update-rule parameters (e.g., diffusion rates, noise schedules, constraint weights), NOT real-world physical laws.</p> <p>Explicit Invariants:</p> Invariant Requirement No unbounded exploration online All online search is bounded by approved catalog and delta limits No uncontrolled oscillation Anti-thrashing rules required: cooldowns, hysteresis, confidence gating Homeostasis recovery Must be demonstrable with shock tests (inject perturbation \u2192 observe recovery) <p>Homeostatic Mode Caching:</p> <ul> <li>The runtime MAY cache \"homeostatic modes\" (stable configurations that achieve target SLOs).</li> <li>Cached modes enable fast re-entry without re-optimization.</li> <li>Cached modes MUST be versioned, audited, and constrained by the same guardrails as live proposals.</li> <li>Mode cache eviction policy MUST be explicit (LRU, TTL, or capacity-based).</li> </ul>"},{"location":"project/constitution/#tier-scope-applies-to-sections-2029","title":"Tier \u03a9 Scope (Applies to Sections 20\u201329)","text":"<p>Sections 12\u201321 govern Tier \u03a9 (Experimental) features only.</p> <p>Tier 1 (Production) behavior must continue to satisfy all Core Principles in:</p> <ul> <li>Section II.1\u201311 (Pipeline integrity, determinism, contracts, privacy, boundedness),</li> <li>Section VIII (Performance &amp; Hot-Path Invariants),</li> <li>Section IX (Observability &amp; Telemetry Contracts), and</li> <li>Section X (Data Governance &amp; Retention),</li> </ul> <p>regardless of any Tier \u03a9 configuration. No Tier \u03a9 behavior may weaken or bypass those invariants.</p>"},{"location":"project/constitution/#12-bounded-emergence-tier-only","title":"12. Bounded Emergence (Tier \u03a9 Only)","text":"<p>We consciously work only inside the Engineerable Sub-Space.</p> <ul> <li>Tier \u03a9 Only: Even in experimental regimes, we serve systems where we retain control (budget, timeouts, caps).</li> <li>Chaos Ban (Default): Highly chaotic or poorly characterized regimes are considered out of scope for production claims and live only in research sandboxes.</li> <li>Core Invariant Link: All Tier \u03a9 work remains subject to Determinism (II.2), Privacy (II.6), Safety (II.7\u20138), and Boundedness (VIII.1\u20132).</li> </ul>"},{"location":"project/constitution/#13-temporal-sovereignty-tier-only","title":"13. Temporal Sovereignty (Tier \u03a9 Only)","text":"<p>Time-varying structure (adaptive schedules, time-to-target controllers) is a first-class control mechanism.</p> <ul> <li>Dynamic Schedules: We assume control can be restored through well-designed temporal programs, not just static settings.</li> </ul>"},{"location":"project/constitution/#14-mathematical-rigor-algebraic-preference-tier-only","title":"14. Mathematical Rigor (Algebraic Preference, Tier \u03a9 Only)","text":"<ul> <li>Solvers over Heuristics: If a problem can be solved by a matrix operation or algebraic solver, do not use a neural net or heuristic.</li> <li>Explicit Control: Controllers must be explicit and observable. Hidden control loops are forbidden.</li> <li>Structured Sampling: Prefer deterministic low-discrepancy / structured grids over naive random sweeps for discovery loops.</li> </ul>"},{"location":"project/constitution/#15-the-omega-tier-risk-classification-tier-only","title":"15. The Omega Tier (Risk Classification, Tier \u03a9 Only)","text":"<p>Strategies are classified by risk profile:</p> <ul> <li>Tier 1 (Production): Safe, bounded, and deterministic for benchmark claims.</li> <li>Tier \u03a9 (Experimental): Permitted to explore complex behavior but must be strictly confined and never become default by accident.</li> </ul>"},{"location":"project/constitution/#16-diagnostic-segregation-tier-only","title":"16. Diagnostic Segregation (Tier \u03a9 Only)","text":"<ul> <li>Signals vs Decisions: Outputs from \u03a9-tier probes are treated as Diagnostic Signals, not direct decision-makers in production defaults.</li> </ul>"},{"location":"project/constitution/#17-the-4-layer-hierarchy-tier-only","title":"17. The 4-Layer Hierarchy (Tier \u03a9 Only)","text":"<p>Complex systems follow the standard Substrate \u2192 Observer \u2192 Controller \u2192 Architect hierarchy.</p> <ul> <li>Explicit Roles: Components must implicitly or explicitly fulfill one of these roles.</li> <li>Recursive Operators: Recursive strategies must explicitly declare recursion depth limits and halt conditions.</li> <li>Meta-Optimizers: Meta-optimizers whose output is the configuration of other optimizers are subject to strict evidence and safety gates.</li> </ul>"},{"location":"project/constitution/#18-probability-engines-tier-only","title":"18. Probability Engines (Tier \u03a9 Only)","text":"<p>The system may support probability-shaping engines where outputs are distributions, not scalars.</p> <ul> <li>Superposition: Decisions may be probabilistic until explicitly collapsed by a deterministic selection rule.</li> </ul>"},{"location":"project/constitution/#19-temporal-physics-tier-only","title":"19. Temporal Physics (Tier \u03a9 Only)","text":"<ul> <li>Phased Operation: Systems may explicitly declare phases (e.g., <code>[   \"probe\",   \"classify\",   \"refine\" ]</code>). Control policies must adapt to the active phase.</li> </ul>"},{"location":"project/constitution/#20-the-reality-factory-tier-only","title":"20. The Reality Factory (Tier \u03a9 Only)","text":"<p>The system may manage governed experiment namespaces (\u201cRealities\u201d) as first-class lifecycle objects.</p> <ul> <li>Lifecycle States: Experiments must track lifecycle state (<code>Draft</code> \u2192 <code>Running</code> \u2192 <code>Promoted</code> \u2192 <code>Archived</code>) with explicit transition gates.</li> </ul>"},{"location":"project/constitution/#21-strong-emergence-patterns-tier-only","title":"21. Strong Emergence Patterns (Tier \u03a9 Only)","text":"<ul> <li>Homeostatic Override: Controllers must have the authority to force reset when error thresholds are breached.</li> <li>Curiosity Metrics: \u201cSurprise\u201d is a valid optimization signal for discovery-only operators.</li> </ul>"},{"location":"project/constitution/#iii-code-quality-engineering-standards","title":"III. Code Quality &amp; Engineering Standards","text":""},{"location":"project/constitution/#1-the-boring-code-manifesto","title":"1. The \"Boring Code\" Manifesto","text":"<p>We value clarity over cleverness. ArqonHPO must be readable by a junior engineer at 3 AM.</p> <ul> <li>Readability First: If a \"clever\" one-liner creates cognitive load, expand it.</li> <li>Explicit over Implicit: Magic behavior, monkey-patching, and hidden control flow are forbidden.</li> <li>Standard Tooling: We adhere strictly to community standards (formatters, linters, type checkers).</li> </ul>"},{"location":"project/constitution/#2-asynchronous-boundaries","title":"2. Asynchronous Boundaries","text":"<p>If concurrency/parallel evaluation exists, it must not destroy determinism.</p> <ul> <li>Purity Mandate: Core decision logic must remain synchronous and pure where possible.</li> <li>Timeout Mandate: No external call (objective, subprocess, IO) shall exist without a configured timeout.</li> </ul>"},{"location":"project/constitution/#3-error-handling-philosophy","title":"3. Error Handling Philosophy","text":"<p>Errors are data, not exceptions. They must be handled explicitly.</p> <ul> <li>Fail Loud (Developer Errors): Logic errors and invariant violations must crash or hard-fail immediately.</li> <li>Fail Soft (Runtime Errors): External failures must be handled via explicit rejection or controlled degradation.</li> <li>The \"Swallow\" Ban: Silent discard of errors is forbidden.</li> </ul>"},{"location":"project/constitution/#4-logging-observability","title":"4. Logging &amp; Observability","text":"<ul> <li>Structured Only: Logs must be structured and include correlation identifiers (e.g., <code>run_id</code>).</li> <li>Level Discipline: <code>ERROR</code> means operator intervention is required. <code>WARN</code> means handled anomaly. <code>INFO</code> is lifecycle.</li> <li>Security Redaction: Logs must never contain sensitive objective payloads at <code>INFO</code> or above.</li> </ul>"},{"location":"project/constitution/#5-configuration-discipline","title":"5. Configuration Discipline","text":"<ul> <li>Config Over Code: Operational thresholds (timeouts, budgets, caps) must be configurable, not magic numbers.</li> <li>Validation on Startup: Invalid configuration must fail fast with explicit errors.</li> </ul>"},{"location":"project/constitution/#6-deterministic-state-contract-correctness","title":"6. Deterministic State &amp; Contract Correctness","text":"<p>Optimization systems die when state becomes ambiguous.</p> <ul> <li>State Machine Contracts: Phase transitions and mode decisions must be explicit.</li> <li>Determinism: Same seed + same env + same objective \u2192 same decisions and results (within defined tolerances).</li> <li>Artifact Contracts: Artifact schema is a compatibility surface.</li> </ul>"},{"location":"project/constitution/#7-contract-first-definition","title":"7. Contract-First Definition","text":"<ul> <li>Typed config and artifact schemas are the source of truth.</li> <li>Untyped ad-hoc dictionaries/maps in core paths are prohibited.</li> </ul>"},{"location":"project/constitution/#8-memory-safety-resource-guarantees","title":"8. Memory Safety &amp; Resource Guarantees","text":"<ul> <li>Resource Caps: Every subsystem must define caps for memory, retries, and timeouts.</li> </ul>"},{"location":"project/constitution/#9-concurrency-safety-ordering","title":"9. Concurrency Safety &amp; Ordering","text":"<ul> <li>Ordering Invariants: The solver must never assume ordering unless it enforces it.</li> </ul>"},{"location":"project/constitution/#10-performance-discipline","title":"10. Performance Discipline","text":"<ul> <li>Hot Path Hygiene: Avoid unnecessary allocations and logging inside per-eval loops.</li> <li>Latency Budgets: If a latency budget exists (time-to-target), it must be measured and guarded.</li> </ul>"},{"location":"project/constitution/#11-api-interface-stability","title":"11. API &amp; Interface Stability","text":"<ul> <li>Boundary Contracts: Internal modules communicate via stable interfaces.</li> </ul>"},{"location":"project/constitution/#12-dependency-hygiene","title":"12. Dependency Hygiene","text":"<ul> <li>Admission Rules: New dependencies are guilty until proven innocent.</li> <li>Pinning: Benchmark-critical dependencies must be version-pinned.</li> </ul>"},{"location":"project/constitution/#13-documentation-standards","title":"13. Documentation Standards","text":"<ul> <li>Docs as Code: Documentation must live in the repo.</li> <li>Decision Records: Significant decisions must be captured (ADR or equivalent).</li> </ul>"},{"location":"project/constitution/#14-build-artifact-integrity","title":"14. Build &amp; Artifact Integrity","text":"<ul> <li>Reproducibility: Builds and benchmark runs must be reproducible.</li> <li>Binary/Package Hygiene: Produced artifacts must be traceable to a commit and environment.</li> </ul>"},{"location":"project/constitution/#15-mathematical-rigor-algebraic-preference","title":"15. Mathematical Rigor (Algebraic Preference)","text":"<ul> <li>Solvers over Heuristics: Prefer explicit solvers where applicable.</li> <li>Explicit Control: Hidden control loops are forbidden.</li> <li>Structured Sampling: Prefer deterministic sampling schemes where it improves time-to-target and reproducibility.</li> </ul>"},{"location":"project/constitution/#iv-testing-strategy-quality-gates","title":"IV. Testing Strategy &amp; Quality Gates","text":""},{"location":"project/constitution/#1-tdd-as-the-working-standard","title":"1. TDD as the Working Standard","text":"<p>Test-Driven Development (TDD) is the default and expected workflow for all ArqonHPO components.</p> <ul> <li>The Workflow:</li> <li>Specify: Define behavior in <code>/specs/</code> (SDD-first).</li> <li>Test: Write or extend tests that express that behavior.</li> <li>Implement: Write the code that satisfies the tests.</li> <li>Refactor: Optimize while keeping the suite green.</li> </ul>"},{"location":"project/constitution/#2-coverage-expectations-per-subsystem","title":"2. Coverage Expectations (Per Subsystem)","text":"<p>Coverage is about behavioral exhaustiveness, not raw percentages.</p> <ul> <li>Solver Core: Must cover probe, classify, mode select, refine, and budget accounting.</li> <li>Artifact Layer: Must cover schema versioning, determinism, replay-critical fields.</li> <li>Benchmark Harness: Must cover time-to-target measurement and reporting.</li> </ul>"},{"location":"project/constitution/#3-test-discipline-requirements","title":"3. Test Discipline Requirements","text":"<ul> <li>Unit Tests: Must run fast with zero external services.</li> <li>Integration Tests: Must run end-to-end with real dependencies where relevant.</li> <li>Flaky Tests: Flaky tests are Critical Bugs.</li> <li>Determinism: Tests must avoid random sleeps and time-dependent logic; use controlled clocks.</li> </ul>"},{"location":"project/constitution/#4-quality-gates","title":"4. Quality Gates","text":"<p>A PR may not be merged if any of the following are true:</p> <ul> <li>Determinism Gate: nondeterministic behavior without explicit labeling and tests.</li> <li>Evidence Gate: benchmark/perf claims without reproducible evidence.</li> <li>Artifact Gate: schema changes without versioning and compatibility notes.</li> <li>Spec Gate: behavior implemented without a Spec, or Spec not updated to match Code.</li> <li>Technical Debt Gate: new <code>TODO</code>s without <code>TD-###</code> and TTL.</li> </ul>"},{"location":"project/constitution/#5-probe-guardrail-tests","title":"5. Probe Guardrail Tests","text":"<p>Probe changes require passing the following mandatory test classes:</p> Test Class Requirement <code>TestProbeOnlyQuality</code> New probe beats legacy on shifted instances. <code>TestStructuredRouting</code> NM wins on structured landscapes (mode selection). <code>TestMultimodalGuardrail</code> Probe is robust on Rastrigin-class objectives. <code>TestGeometryRegression</code> Probe geometry is deterministic and reproducible. <code>TestStructuredNMCorrectness</code> NM periodic arithmetic is correct. <code>TestTimeToQuality</code> Time-to-target metrics are computed and reported. <p>Reference implementation: <code>benchmarks/test_probe_guardrails.py</code></p>"},{"location":"project/constitution/#v-lifecycle-automation","title":"V. Lifecycle &amp; Automation","text":"<p>ArqonHPO does not \u201cship code\u201d; it manufactures artifacts through a controlled factory.</p>"},{"location":"project/constitution/#1-the-factory-mandate","title":"1. The Factory Mandate","text":"<p>Manual releases are forbidden for production claims. CI is the source of truth.</p> <ul> <li>The Pipeline is Sovereign: If it did not pass CI, it does not exist.</li> </ul>"},{"location":"project/constitution/#2-immutable-reproducible-artifacts","title":"2. Immutable &amp; Reproducible Artifacts","text":"<ul> <li>Immutable Artifacts: Release artifacts must be identifiable by content hash.</li> <li>Reproducible Builds: The same commit must build reproducibly in the canonical environment.</li> </ul>"},{"location":"project/constitution/#3-supply-chain-security","title":"3. Supply Chain Security","text":"<ul> <li>Dependency Locking: No floating versions for benchmark-critical paths.</li> <li>Provenance: Artifact origin must be traceable (commit, branch, CI run).</li> </ul>"},{"location":"project/constitution/#vi-operational-excellence","title":"VI. Operational Excellence","text":"<p>ArqonHPO is correctness-sensitive infrastructure for optimization. The way it behaves under real objectives is as important as the way it behaves in tests.</p>"},{"location":"project/constitution/#1-performance-capacity-invariants","title":"1. Performance &amp; Capacity Invariants","text":"<ul> <li>Boundedness: No unbounded loops. Budget and timeouts are mandatory.</li> <li>Overhead Discipline: Policy updates and bookkeeping must remain bounded and low overhead.</li> </ul>"},{"location":"project/constitution/#2-observability-audit","title":"2. Observability &amp; Audit","text":"<ul> <li>Reconstructability: Logs + artifacts must allow reconstruction of what happened in a run.</li> <li>No Silent Recovery: Any fallback must be visible and test-covered.</li> </ul>"},{"location":"project/constitution/#vii-governance-amendment","title":"VII. Governance &amp; Amendment","text":"<p>Governance defines how ArqonHPO protects its mission and how this Constitution itself may change.</p>"},{"location":"project/constitution/#1-scope-protection","title":"1. Scope Protection","text":"<p>ArqonHPO is probe-gated optimization for the two target use cases. Scope creep is a bug.</p>"},{"location":"project/constitution/#2-complexity-budget","title":"2. Complexity Budget","text":"<p>Complexity is technical debt with compound interest.</p> <ul> <li>Adding major dependencies or new execution modes requires explicit review and an ADR.</li> </ul>"},{"location":"project/constitution/#3-amendments","title":"3. Amendments","text":"<p>This Constitution is living but intentionally hard to change.</p> <ul> <li>Amendments require a documented proposal (rationale + impact) and a version bump.</li> </ul>"},{"location":"project/constitution/#viii-performance-hot-path-invariants","title":"VIII. Performance &amp; Hot-Path Invariants","text":"<p>Performance is not an optimization; it is a correctness property.</p>"},{"location":"project/constitution/#1-boundedness-as-law","title":"1. Boundedness as Law","text":"<p>Unbounded anything is a denial-of-service vector.</p> <ul> <li>No Unbounded Work: Every loop must have a budget.</li> <li>CPU Boundaries: Heavy work must not block the per-eval control loop without explicit design.</li> </ul>"},{"location":"project/constitution/#2-hot-path-constraints","title":"2. Hot-Path Constraints","text":"<ul> <li>O(1) or Amortized O(1): Per-eval policy decisions must be O(1) or amortized O(1).</li> <li>No Hidden I/O: Do not write artifacts inside the inner loop unless explicitly buffered.</li> </ul>"},{"location":"project/constitution/#3-hot-path-parameter-representation-determinism-v141-merge-blocking","title":"3. Hot-Path Parameter Representation &amp; Determinism (v1.4.1, merge-blocking)","text":"<p>This section defines non-negotiable architectural invariants for parameter storage in Tier-1/Tier-2 hot paths. Violations are merge blockers.</p> <p>Hot Path Definition (Normative): \"Hot Path\" means any code executing inside the Tier-2 decision window or Tier-1 apply window, specifically: all functions and their transitive callees executed during:</p> <ol> <li><code>T2_decision_us</code> (start: digest popped \u2192 end: proposal emitted)</li> <li><code>T1_apply_us</code> (start: proposal received \u2192 end: in-memory config swap completed)</li> </ol> <p>Hot Path includes: Tier-2 observe/decision loop, SPSA step math, guardrail validation, delta application, atomic swap, telemetry ingest, audit enqueue (non-blocking), and any per-tick scheduling within these windows.</p>"},{"location":"project/constitution/#a-hot-path-disallowed-types-merge-blocking","title":"A. Hot-Path Disallowed Types (Merge-Blocking)","text":"<p>In Hot Path code, the following are FORBIDDEN:</p> <ul> <li><code>std::collections::HashMap</code></li> <li><code>hashbrown::HashMap</code></li> <li>Any map/dictionary keyed by strings (or heap-owned identifiers) used to store parameters or deltas.</li> </ul> <p>Reason: Hot Path must use dense indexed representations (<code>ParamVec</code>/<code>DeltaVec</code>) for determinism, locality, and zero-allocation guarantees.</p>"},{"location":"project/constitution/#b-hot-path-representation-rule-required","title":"B. Hot-Path Representation Rule (Required)","text":"<p>Tier-1 and Tier-2 parameter values and deltas MUST be represented as:</p> <ul> <li>ParamVec = dense ordered numeric vector (<code>SmallVec&lt;[f64; N]&gt;</code> or <code>Vec&lt;f64&gt;</code>)</li> <li>DeltaVec = same dense ordered numeric vector type.</li> </ul> <p>Tier-1/Tier-2 public APIs MUST NOT accept or return named-parameter maps.</p>"},{"location":"project/constitution/#c-no-escape-hatches-merge-blocking","title":"C. No Escape Hatches (Merge-Blocking)","text":"<p>In Hot Path modules/crates:</p> <ul> <li><code>#[allow(clippy::disallowed_types)]</code> is FORBIDDEN.</li> <li>Any allow/override of the Hot Path disallowed-type rules is FORBIDDEN.</li> </ul> <p>Exception: Boundary modules only (CLI/IO/artifact serialization) may use named maps, but must never be linked into Hot Path timing windows.</p>"},{"location":"project/constitution/#d-enforcement-requirements-ci-merge-blocking","title":"D. Enforcement Requirements (CI Merge-Blocking)","text":"<p>CI MUST enforce Hot Path type constraints using:</p> <ul> <li><code>cargo clippy --all-targets --all-features -- -D warnings</code></li> <li><code>#![deny(clippy::disallowed_types)]</code> in the Hot Path crate/module root</li> <li><code>clippy.toml</code> specifying disallowed types, at minimum:</li> <li><code>std::collections::HashMap</code></li> <li><code>hashbrown::HashMap</code></li> </ul> <p>Any violation is a MERGE BLOCKER.</p>"},{"location":"project/constitution/#e-constructorapi-rule-required","title":"E. Constructor/API Rule (Required)","text":"<p>All Tier-1/Tier-2 constructors and runtime methods MUST accept only dense types:</p> <ul> <li>Engine initialization MUST accept <code>(ParamRegistry, ParamVec)</code> (or a single struct containing them).</li> <li>Hot Path runtime loops MUST NOT accept <code>NamedParams</code> or any <code>HashMap&lt;String, _&gt;</code> type (directly or indirectly).</li> <li>All boundary conversion from named\u2192dense MUST occur once at initialization or boundary serialization only.</li> </ul>"},{"location":"project/constitution/#f-paramregistry-contract-required-for-audit-replay","title":"F. ParamRegistry Contract (Required for Audit + Replay)","text":"<ul> <li>Existence REQUIRED: A <code>ParamRegistry</code> (or equivalent) MUST exist to provide:</li> <li>Stable mapping: <code>name \u2194 id/index</code></li> <li>Deterministic ordering (consistent across runs with same schema)</li> <li>Schema/version identity</li> <li>Immutability REQUIRED: The mapping MUST be immutable during a run for Tier-1/Tier-2 operation.</li> </ul>"},{"location":"project/constitution/#g-deterministic-replay-artifact-contract-required","title":"G. Deterministic Replay Artifact Contract (Required)","text":"<p>Artifacts MUST include the following fields (exact keys):</p> <ul> <li><code>seed</code>: <code>u64</code></li> <li><code>registry_hash64</code>: <code>u64</code></li> <li><code>registry_names</code>: <code>[String]</code> (stable ordered list)</li> <li><code>param_len</code>: <code>usize</code></li> <li><code>params_vec</code>: <code>[f64]</code> (dense ordered values)</li> </ul> <p>Optional (derived for readability only):</p> <ul> <li><code>params_named</code>: <code>{ String: f64 }</code></li> </ul> <p>Rule: <code>params_named</code> MUST be derivable from <code>registry_names</code> + <code>params_vec</code> and MUST NOT be required for replay. Replay MUST NOT require string hashing to reconstruct the decision path.</p>"},{"location":"project/constitution/#h-tier-exception-policy-explicitly-bounded","title":"H. Tier \u03a9 Exception Policy (Explicitly Bounded)","text":"<ul> <li>Sandbox Exploration Allowed: Tier \u03a9 (experimental) MAY explore dynamic parameter sets.</li> <li>Production Invariants Preserved: Tier-1/Tier-2 invariants remain non-bypassable even when Tier \u03a9 is active.</li> <li>Promotion Gate: Promotion from Tier \u03a9 to production REQUIRES passing all hot-path invariant tests and freezing a registry.</li> </ul>"},{"location":"project/constitution/#i-performance-enforcement-mergeship-blockers","title":"I. Performance Enforcement (Merge/Ship Blockers)","text":"<ul> <li>No-Alloc Test REQUIRED: CI MUST include a \"no-alloc hot path\" test for Tier-1 apply and Tier-2 observe/decision paths (release mode).</li> <li><code>observe()</code> allocs == 0</li> <li><code>apply()</code> allocs == 0</li> <li>Benchmark Gate REQUIRED: CI MUST include a benchmark regression gate for <code>T2_decision_us</code> and <code>T1_apply_us</code> (release mode) consistent with VIII.5 timing budgets.</li> <li>Budgets Checked: Budgets are checked in release mode and FAIL CI if exceeded.</li> </ul> <p>Evidence Requirement:</p> <ul> <li>Any latency claim MUST attach evidence (Observed) including: build mode, CPU model, benchmark method, and p50/p99/max.</li> <li>Allocation claims MUST be measured (Observed via instrumentation or allocator hook) or the claim is false.</li> </ul>"},{"location":"project/constitution/#4-time-to-target-metrics","title":"4. Time-to-Target Metrics","text":"<p>The canonical quality-time tradeoff measurements are:</p> <ul> <li>Evals-to-Threshold: Number of evaluations to first reach a target quality threshold.</li> <li>Hit-by-N: Binary success metric\u2014did the run reach threshold within N evals?</li> <li>Median-Best-at-Horizon: Median of best-seen value at a fixed eval count across seeds.</li> </ul> <p>These metrics MUST be reported per-objective in benchmark artifacts.</p>"},{"location":"project/constitution/#5-timing-window-contracts","title":"5. Timing Window Contracts","text":"<p>For microsecond-latency operation, the following timing windows are canonical:</p> Timing Window Definition Typical Budget <code>T2_decision_us</code> Digest popped from ring buffer \u2192 proposal emitted by Tier 2 \u22641,000 \u00b5s <code>T1_apply_us</code> Proposal received by Tier 1 \u2192 guardrails validated + atomic swap completed \u2264100 \u00b5s <code>E2E_visible_us</code> Digest available \u2192 dataplane observes new config \u22642,000 \u00b5s <p>Measurement Requirements:</p> <ul> <li>Latency claims MUST specify: build mode (debug/release), hardware (CPU model, memory), and measurement method (wall clock, flamegraph, tracing).</li> <li>Benchmarks MUST include p50, p99, and max latencies.</li> <li>Regression guards MUST exist for all timing budgets (CI fails if exceeded).</li> </ul>"},{"location":"project/constitution/#6-hot-path-non-blocking-audit","title":"6. Hot Path Non-Blocking Audit","text":"<p>Audit-to-disk MUST be explicitly decoupled from the critical path.</p> <ul> <li>Ring Buffer / Async Writer: Audit events are pushed to a lock-free ring buffer; a background thread persists to disk.</li> <li>No Blocking I/O: Disk I/O (file writes, network calls) is FORBIDDEN in the apply critical path.</li> <li>Overflow Policy: If the ring buffer is full, the overflow policy MUST be explicit (drop oldest, block, or signal backpressure).</li> </ul>"},{"location":"project/constitution/#7-zero-allocation-critical-path","title":"7. Zero-Allocation Critical Path","text":"<p>The critical path (<code>T1_apply_us</code> window) MUST remain zero-allocation:</p> <ul> <li>No Heap Allocations: Use pre-allocated buffers, arena allocators, or stack allocation.</li> <li>No Blocking Syscalls: No <code>malloc</code>, <code>mmap</code>, file I/O, or network I/O.</li> <li>Arc Clone Only: <code>snapshot()</code> operations use cheap Arc clone, not deep copy.</li> </ul>"},{"location":"project/constitution/#ix-observability-telemetry-contracts","title":"IX. Observability &amp; Telemetry Contracts","text":"<p>What cannot be observed cannot be governed.</p>"},{"location":"project/constitution/#1-logs-metrics-traces-as-first-class-citizens","title":"1. Logs, Metrics, Traces as First-Class Citizens","text":"<ul> <li>Structured Logs Only: Must include <code>run_id</code> and phase markers.</li> <li>Telemetry for Mode Decisions: Mode selection and classification results must be observable.</li> </ul>"},{"location":"project/constitution/#2-structured-events-correlation-ids","title":"2. Structured Events &amp; Correlation IDs","text":"<p>For the Adaptive Engine control loop, the following event types are REQUIRED:</p> Event Type Trigger Required Fields <code>digest</code> New telemetry digest pushed <code>run_id</code>, <code>timestamp_us</code>, <code>digest_id</code>, <code>objective_value</code> <code>proposal</code> Tier 2 emits a proposal <code>run_id</code>, <code>proposal_id</code>, <code>config_version</code>, <code>delta_summary</code> <code>apply</code> Tier 1 successfully applies config <code>run_id</code>, <code>proposal_id</code>, <code>new_config_version</code>, <code>apply_latency_us</code> <code>rollback</code> Tier 1 triggers rollback <code>run_id</code>, <code>proposal_id</code>, <code>rollback_reason</code>, <code>reverted_to_version</code> <code>promotion</code> Variant promoted to Approved/Promoted <code>run_id</code>, <code>variant_id</code>, <code>old_state</code>, <code>new_state</code>, <code>evidence_ref</code> <p>Correlation ID Requirements:</p> <ul> <li>All events in a single adaptation cycle MUST share the same <code>run_id</code>.</li> <li>Proposals MUST have unique <code>proposal_id</code> for traceability.</li> <li>Config versions MUST use monotonic <code>config_version</code> counters.</li> </ul>"},{"location":"project/constitution/#x-data-governance-retention","title":"X. Data Governance &amp; Retention","text":"<p>ArqonHPO may handle sensitive objective data. Data is an asset and a liability.</p>"},{"location":"project/constitution/#1-data-classification","title":"1. Data Classification","text":"<ul> <li>Run Artifacts: schema-versioned run outputs.</li> <li>Objective Data: treated as sensitive by default.</li> </ul>"},{"location":"project/constitution/#2-retention","title":"2. Retention","text":"<ul> <li>Explicit Retention: No infinite retention by accident; retention policies must be explicit.</li> </ul>"},{"location":"project/constitution/#xi-internal-service-contracts-complexity-escalation","title":"XI. Internal Service Contracts &amp; Complexity Escalation","text":"<p>The internal structure must remain understandable, evolvable, and safe.</p>"},{"location":"project/constitution/#1-internal-contracts","title":"1. Internal Contracts","text":"<ul> <li>Versioned Contracts: Internal boundaries must have explicit, versioned contracts (types + schemas).</li> </ul>"},{"location":"project/constitution/#2-complexity-budget-escalation","title":"2. Complexity Budget &amp; Escalation","text":"<ul> <li>Introducing a new core dependency or major execution mode requires a design review document and ADR.</li> </ul>"},{"location":"project/constitution/#3-benchmark-schema-contract","title":"3. Benchmark Schema Contract","text":"<p>Benchmark artifacts MUST follow a declarative schema:</p> <ul> <li>Objective Suite (minimum): sphere_smooth_shift, rosenbrock_smooth_shift, rastrigin_torus.</li> <li>Cost Regimes: cheap (1ms), expensive (20ms+).</li> <li>Output Schema: CSV with columns [run_id, eval_id, best_so_far, elapsed_ms, params].</li> <li>Plots: best_vs_time.png, cdf_time_to_threshold.png per objective.</li> </ul>"},{"location":"project/constitution/#4-sdk-binding-compliance","title":"4. SDK Binding Compliance","text":"<p>Python bindings MUST maintain parity with Rust core:</p> <ul> <li>Determinism Parity: <code>ArqonProbe</code> and <code>ArqonSolver</code> (Python) MUST produce identical results to Rust core for same (seed, config).</li> <li>Sharding Verification: Bitwise hash of sorted samples MUST match single-worker vs multi-worker configurations.</li> <li>Binding Changes: Require parity tests in CI before merge.</li> </ul>"},{"location":"project/constitution/#5-strategy-parameter-governance","title":"5. Strategy Parameter Governance","text":"<p>Strategy parameters require explicit governance:</p> <ul> <li>K (parallel starts): MUST have documented default and rationale.</li> <li>Triage Budget: MUST be bounded; unbounded triage is forbidden.</li> <li>Stall Threshold: MUST trigger rotation; silent stalling is forbidden.</li> <li>Spice Ratio: MUST be configurable with documented default (10%).</li> </ul> <p>Changes to defaults require an ADR with benchmark evidence.</p>"},{"location":"project/constitution/#xii-glossary-canonical-definitions","title":"XII. Glossary &amp; Canonical Definitions","text":"<p>To prevent interpretation drift (especially for Spec Kit agents), we define core vocabulary used throughout this Constitution.</p> Term Definition ArqonHPO The probe-gated optimization engine described by this Constitution. Probe Deterministic initial sampling phase to gather candidates and signal. Classify Fixed-size test producing a label and score to drive mode selection. Mode The chosen refinement strategy family (structured vs chaotic). Time-to-Target Time/evals to reach a specified objective threshold. Tier 1 (Safe Executor) The sole actuator for production state; enforces all guardrails before applying changes. Tier 2 (Adaptive Engine) Reads telemetry, proposes deltas or variant selections; cannot mutate production state directly. Tier \u03a9 (Offline Discovery) Experimental/background loop that generates candidates; never in hot path, outputs are diagnostic only. Homeostasis A stable operating regime the adaptive engine steers toward under varying conditions. Law knobs Runtime/simulation parameters (diffusion, noise, decay, constraint weights) tunable within safety envelopes. Variant Catalog Registry of approved configuration variants with lifecycle states (Draft \u2192 Evaluated \u2192 Approved \u2192 Promoted \u2192 Archived). Promotion Gate Evidence pack + offline evaluation + rollback plan required to promote a variant to Approved state. E2E_visible_us Time from digest availability to dataplane observing new config (microseconds). T2_decision_us Time from digest popped to proposal emitted by Tier 2 (microseconds). T1_apply_us Time from proposal received to atomic swap completed by Tier 1 (microseconds). ParamVec Dense parameter storage (<code>SmallVec&lt;[f64; 16]&gt;</code>) used in Tier-1/Tier-2 hot paths. FORBIDDEN to use HashMap. (v1.4.0) ParamRegistry Stable mapping between human-readable parameter names and dense array indices. Immutable during a run. (v1.4.0) Boundary Any interface layer where human-readable names exist (CLI/SDK/artifacts/wire protocol). HashMap allowed only here. (v1.4.0) Hot Path Code executed per-tick/per-decision/per-apply with strict latency budgets (&lt;1ms). No heap allocation, no string ops. (v1.4.0)"},{"location":"project/constitution/#xiv-ultimate-integrity-attestation-evidence-pack","title":"XIV. ULTIMATE INTEGRITY ATTESTATION &amp; EVIDENCE PACK","text":"<p>This section is the merge/ship gate. It exists so \u201cdone\u201d is not a feeling\u2014it is a reproducible fact.</p>"},{"location":"project/constitution/#1-mergeship-attestation-required","title":"1) Merge/Ship Attestation (Required)","text":"<p>By merging or shipping, the author(s) and reviewer(s) attest:</p> <ul> <li>No placeholders exist in production paths (no TODOs, stubs, pseudocode-as-work, \u201clater hardening\u201d).</li> <li>No fake evidence is presented (no invented logs, benchmarks, screenshots, coverage, or results).</li> <li>No happy-path-only verification exists for critical behaviors.</li> <li>No silent failure handling exists; errors are handled/logged/propagated with context.</li> <li>Warnings were treated as errors (clean lint/typecheck/compile).</li> <li>Any technical debt is recorded as <code>TD-###</code> with owner + TTL + exit criteria and is bounded by tests.</li> <li>All claims are labeled Observed/Derived/Unverified, and Observed claims have attached evidence.</li> </ul> <p>If you cannot honestly attest to every item above, you must not merge/ship.</p>"},{"location":"project/constitution/#2-evidence-pack-attach-or-link-required","title":"2) Evidence Pack (Attach or Link; Required)","text":"<p>A change is invalid without a reproducible Evidence Pack. The Evidence Pack must be tied to a specific commit and must be reproducible by another engineer.</p>"},{"location":"project/constitution/#21-build-proof","title":"2.1 Build Proof","text":"<ul> <li>CI run or local output showing:</li> <li>clean build,</li> <li>clean lint/typecheck/format,</li> <li>warnings treated as errors.</li> </ul>"},{"location":"project/constitution/#22-test-proof","title":"2.2 Test Proof","text":"<ul> <li>Results for:</li> <li>unit tests,</li> <li>integration tests (where applicable),</li> <li>property/fuzz tests (where required by input boundaries),</li> <li>concurrency/ordering tests (where applicable).</li> <li>A short note listing what is not covered and why (explicitly, not implicitly).</li> </ul>"},{"location":"project/constitution/#23-failure-matrix-proof-where-the-bad-paths-live","title":"2.3 Failure Matrix Proof (Where the bad paths live)","text":"<p>For each externally coupled feature, list:</p> <ul> <li>failure scenarios tested (timeouts, retries, malformed responses, permission failures, overload/backpressure, partial failures),</li> <li>test file(s) and test names (or equivalent pointers).</li> </ul>"},{"location":"project/constitution/#24-traceability-proof-truth-table","title":"2.4 Traceability Proof (Truth Table)","text":"<p>Provide a \u201ctruth table\u201d mapping:</p> <ul> <li>requirement / acceptance criteria \u2192 implementation location(s) \u2192 test location(s) \u2192 documentation location(s) \u2192 evidence artifact(s).</li> </ul> <p>Rule: If a requirement has no test, it is untested. If a test has no requirement, it is suspicious.</p>"},{"location":"project/constitution/#25-runtime-proof-when-applicable","title":"2.5 Runtime Proof (When Applicable)","text":"<ul> <li>example run logs demonstrating:</li> <li>normal behavior,</li> <li>at least one failure mode behaving correctly.</li> <li>proof of observability works:</li> <li>correlation IDs exist,</li> <li>metrics/traces exist (or equivalent breadcrumbs).</li> </ul>"},{"location":"project/constitution/#26-performance-resource-proof-when-relevant","title":"2.6 Performance / Resource Proof (When Relevant)","text":"<ul> <li>baseline numbers + method + environment,</li> <li>a regression guard (benchmark test, threshold check, or documented budget),</li> <li>proof of bounded behavior (caps, backpressure, shedding policy).</li> </ul>"},{"location":"project/constitution/#27-reproduction-commands","title":"2.7 Reproduction Commands","text":"<ul> <li>one-command verification (examples):</li> <li><code>pytest</code>, <code>python -m build</code>, etc.</li> <li>environment notes:</li> <li>pinned toolchains/dependencies,</li> <li>seed control for deterministic tests.</li> </ul>"},{"location":"project/constitution/#28-canonical-environment-mandate","title":"2.8 Canonical Environment Mandate","text":"<p>To ensure absolute reproducibility, all development and CI operations MUST use the canonical Conda environment: <code>helios-gpu-118</code>.</p> <p>Paths:</p> <ul> <li>Python: <code>/home/irbsurfer/miniconda3/envs/helios-gpu-118/bin/python</code></li> <li>Cargo: <code>/home/irbsurfer/miniconda3/envs/helios-gpu-118/bin/cargo</code></li> </ul> <p>Rules:</p> <ul> <li>Do NOT rely on system <code>python</code> or <code>cargo</code>.</li> <li>Scripts and tools MUST resolve these absolute paths or explicitly activate the environment.</li> </ul>"},{"location":"project/constitution/#3-debt-register-enforcement-td-","title":"3) Debt Register Enforcement (TD-###)","text":"<p>If any <code>TD-###</code> exists in the change:</p> <ul> <li>TTL date and owner are mandatory.</li> <li>The debt boundary must be protected by tests so it cannot silently expand.</li> <li>The exit criteria must be concrete.</li> <li>Debt past TTL is a release/merge blocker.</li> </ul>"},{"location":"project/constitution/#4-professional-review-checklist-hard-questions-only","title":"4) Professional Review Checklist (Hard Questions Only)","text":"<p>Review must answer \u201cyes\u201d with evidence:</p> <ul> <li>Does this handle failure modes explicitly (not \u201cassumed\u201d)?</li> <li>Are tests realistic, adversarial, and non-trivial (no lazy synthetics)?</li> <li>Are there concurrency/ordering hazards, and are they tested or explicitly ruled out?</li> <li>Is behavior observable (logs/metrics/traces/breadcrumbs)?</li> <li>Are resource bounds explicit (timeouts, caps, retry budgets, queue bounds)?</li> <li>Is the code readable under pressure (3 AM standard)?</li> <li>Is documentation updated to match behavior and constraints?</li> <li>Can another engineer reproduce the Evidence Pack from scratch?</li> </ul> <p>If any answer is \u201cno,\u201d the change is not complete.</p>"},{"location":"project/constitution/#5-claim-ledger-summary-required-when-stating-status","title":"5) Claim Ledger Summary (Required When Stating Status)","text":"<p>If a deliverable claims completion or correctness, it must include:</p> <ul> <li>Observed claims: link evidence</li> <li>Derived claims: list assumptions + risks + how to verify</li> <li>Unverified claims: list the minimal experiment to verify</li> </ul> <p>Rule: If it cannot be reproduced from the Evidence Pack, it is not true. Rule: If it is not true, it is not done.</p>"},{"location":"project/constitution/#implementation-substrate-sdk-contract","title":"Implementation Substrate &amp; SDK Contract","text":"<ul> <li>Core implementation MUST be a Rust library crate exposing the probe-gated solver API.</li> <li>CLI MUST be a thin Rust binary crate that delegates to the core.</li> <li>SDKs (for example, Python) MUST be thin bindings over the same core, not reimplementing solver logic.</li> <li>Artifacts MUST be language-agnostic (JSON) and serve as the compatibility contract between surfaces.</li> </ul> <p>Version: 1.0.0 Ratified: 2025-12-13 Last Amended: 2025-12-13</p>"},{"location":"project/roadmap/","title":"Roadmap","text":"<p>ArqonHPO follows semantic versioning. This document outlines our vision, planned features, and development priorities.</p>"},{"location":"project/roadmap/#current-v03x-stable","title":"Current: v0.3.x (Stable)","text":"<p>Status: \u2705 Released (January 2026)</p> <p>The production-ready foundation for real-time hyperparameter optimization.</p>"},{"location":"project/roadmap/#core-capabilities","title":"Core Capabilities","text":"<ul> <li>PCR Algorithm \u2014 The Probe-Classify-Refine pipeline automatically selects strategies based on landscape structure</li> <li>Python Bindings \u2014 <code>ArqonSolver</code> for batch optimization, <code>ArqonProbe</code> for distributed LDS sampling</li> <li>CLI &amp; Observability \u2014 TUI, web Dashboard, Prometheus metrics, structured logging</li> <li>Safety Executor \u2014 Constitutional guarantees with Guardrails, Rollback Policy, and audit trail</li> <li>91% Test Coverage \u2014 Comprehensive unit and integration tests</li> </ul>"},{"location":"project/roadmap/#what-makes-v03-production-ready","title":"What Makes v0.3 Production-Ready","text":"Requirement Status Deterministic execution \u2705 ChaCha8Rng Bounded memory \u2705 Ring buffers Recoverable state \u2705 Snapshot + rollback Observable \u2705 Metrics, traces, audit Documented \u2705 50+ pages"},{"location":"project/roadmap/#next-v040-q1-2026","title":"Next: v0.4.0 (Q1 2026)","text":"<p>Status: \ud83d\udd28 In Development</p> <p>The \"Infrastructure Phase\" \u2014 making ArqonHPO deployable anywhere with comprehensive observability.</p>"},{"location":"project/roadmap/#new-features","title":"New Features","text":""},{"location":"project/roadmap/#adaptive-nelder-mead-with-restart-detection","title":"Adaptive Nelder-Mead with Restart Detection","text":"<p>The current Nelder-Mead implementation can stall when the simplex degenerates. v0.4 adds automatic restart detection:</p> <pre><code>// Detects when simplex volume collapses below threshold\n// Automatically reinitializes with exploration phase\nlet nm = NelderMead::with_restart(config, restart_threshold);\n</code></pre> <ul> <li>Problem: Simplex can collapse to a line in high dimensions</li> <li>Solution: Monitor simplex volume, trigger restart when degenerate</li> <li>Benefit: More robust convergence on ill-conditioned surfaces</li> </ul>"},{"location":"project/roadmap/#multi-objective-optimization-moo","title":"Multi-Objective Optimization (MOO)","text":"<p>Support for Pareto-front optimization with multiple objectives:</p> <pre><code>config = {\n    \"objectives\": [\"latency\", \"throughput\"],  # Both minimize\n    \"mode\": \"pareto\"\n}\nsolver = ArqonSolver(json.dumps(config))\ncandidates = solver.ask()  # Returns Pareto-optimal candidates\n</code></pre> <ul> <li>Algorithm: NSGA-II style dominance sorting</li> <li>Output: Pareto front with configurable size</li> <li>Trade-off: User selects from Pareto set</li> </ul>"},{"location":"project/roadmap/#arqonship-v10-self-healing-ci","title":"ArqonShip v1.0 (Self-Healing CI)","text":"<p>The ArqonShip integration reaches v1.0 with:</p> <ul> <li>Automatic rollback on CI failure</li> <li>Bisection to find breaking commits</li> <li>Artifact correlation with test results</li> <li>Slack/Discord notifications</li> </ul>"},{"location":"project/roadmap/#infrastructure","title":"Infrastructure","text":""},{"location":"project/roadmap/#docker-images","title":"Docker Images","text":"<p>Official multi-platform images:</p> <pre><code>docker pull ghcr.io/novelbytelabs/arqonhpo:0.4\ndocker pull ghcr.io/novelbytelabs/arqonhpo:0.4-slim  # ~20MB\n</code></pre> <p>Platforms: <code>linux/amd64</code>, <code>linux/arm64</code>, <code>darwin/arm64</code></p>"},{"location":"project/roadmap/#helm-chart","title":"Helm Chart","text":"<p>Production Kubernetes deployment:</p> <pre><code>helm repo add arqon https://novelbytelabs.github.io/charts\nhelm install arqon arqon/arqonhpo \\\n  --set config.budget=1000 \\\n  --set monitoring.enabled=true\n</code></pre> <p>Includes: ServiceMonitor, PodDisruptionBudget, HPA</p>"},{"location":"project/roadmap/#opentelemetry-integration","title":"OpenTelemetry Integration","text":"<p>Full OTel support for distributed tracing:</p> <pre><code>arqonhpo --otel-endpoint http://otel-collector:4317 run ...\n</code></pre> <ul> <li>Traces: ask/tell spans with parameter context</li> <li>Metrics: OTel metrics alongside Prometheus</li> <li>Logs: Structured logs with trace correlation</li> </ul>"},{"location":"project/roadmap/#future-v100-q2-2026","title":"Future: v1.0.0 (Q2 2026)","text":"<p>Status: \ud83c\udfaf Planned</p> <p>The \"Scale Phase\" \u2014 GPU acceleration and distributed optimization for massive parameter spaces.</p>"},{"location":"project/roadmap/#gpu-accelerated-strategies","title":"GPU-Accelerated Strategies","text":""},{"location":"project/roadmap/#cuda-backend","title":"CUDA Backend","text":"<p>TPE kernel density estimation on GPU:</p> <pre><code>let tpe = TPE::cuda(device_id, dim);\n// 100x speedup for high-dimensional KDE\n</code></pre> <ul> <li>Speedup: 100x for dim &gt; 100</li> <li>Memory: Configurable batch size</li> <li>Fallback: Graceful CPU fallback</li> </ul>"},{"location":"project/roadmap/#metal-backend-apple-silicon","title":"Metal Backend (Apple Silicon)","text":"<p>Native M1/M2/M3 support via Metal:</p> <pre><code>solver = ArqonSolver(config, device=\"metal\")\n</code></pre>"},{"location":"project/roadmap/#distributed-optimization","title":"Distributed Optimization","text":""},{"location":"project/roadmap/#sharded-workers","title":"Sharded Workers","text":"<p>Horizontal scaling across nodes:</p> <pre><code># arqon-distributed.yaml\nmode: distributed\ncoordinator:\n  address: arqon-coordinator:9090\nworkers:\n  count: 16\n  strategy: round_robin\nsharding:\n  probe: by_index # ArqonProbe sharding\n  refine: by_region # Spatial partitioning\n</code></pre> <ul> <li>Coordinator: Central state, Raft consensus</li> <li>Workers: Stateless evaluators</li> <li>Communication: gRPC with protobuf</li> </ul>"},{"location":"project/roadmap/#fault-tolerance","title":"Fault Tolerance","text":"<p>Automatic recovery from worker failures:</p> <ul> <li>Checkpoint every N evaluations</li> <li>Replay from last checkpoint</li> <li>Worker health checks with timeout</li> </ul>"},{"location":"project/roadmap/#full-bayesian-tpe","title":"Full Bayesian TPE","text":"<p>The current TPE uses point estimates. v1.0 adds full Bayesian treatment:</p> <pre><code>let tpe = TPE::bayesian(prior, acquisition_fn);\n</code></pre> <ul> <li>Prior: Configurable Gaussian or Student-t</li> <li>Acquisition: EI, PI, UCB, Thompson Sampling</li> <li>Uncertainty: Credible intervals on predictions</li> </ul>"},{"location":"project/roadmap/#ecosystem-integrations","title":"Ecosystem Integrations","text":"Integration Status Description Ray Tune \u2705 v0.3 Custom searcher MLflow \u2705 v0.3 Tracking plugin W&amp;B \ud83c\udfaf v1.0 Callback + sweeps Optuna \ud83c\udfaf v1.0 Sampler adapter Ax \ud83c\udfaf v1.0 Backend provider"},{"location":"project/roadmap/#long-term-vision-v20","title":"Long-Term Vision (v2.0+)","text":""},{"location":"project/roadmap/#arqonhpo-as-infrastructure","title":"ArqonHPO as Infrastructure","text":"<p>Our north star: Optimization should be as reliable as a database.</p> Database Property ArqonHPO Equivalent ACID transactions Atomic config updates Point-in-time recovery Snapshot rollback Replication Distributed coordinators Query optimization Auto-strategy selection"},{"location":"project/roadmap/#zero-configuration-optimization","title":"Zero-Configuration Optimization","text":"<p>Fully automatic strategy selection:</p> <pre><code># v2.0 vision: just specify the objective\nsolver = ArqonSolver.auto(budget=100)\n# ArqonHPO infers bounds, selects strategy, tunes hyperparams\n</code></pre>"},{"location":"project/roadmap/#sub-microsecond-overhead","title":"Sub-Microsecond Overhead","text":"<p>Target: &lt;1\u03bcs latency for <code>ask()</code> in hot path:</p> Version ask() Latency v0.3 ~3ms v0.4 ~500\u03bcs v1.0 ~100\u03bcs v2.0 &lt;1\u03bcs"},{"location":"project/roadmap/#constitutional-ai-safety","title":"Constitutional AI Safety","text":"<p>Extending constitutional safety to AI-in-the-loop:</p> <pre><code>constitution:\n  max_regression_before_human: 3\n  human_approval_required_for:\n    - production_deploy\n    - safety_override\n  audit_retention: 90d\n</code></pre>"},{"location":"project/roadmap/#what-were-not-building-anti-roadmap","title":"What We're NOT Building (Anti-Roadmap)","text":"<p>Clarity on scope:</p> Feature Why Not Neural Architecture Search Out of scope \u2014 use ArqonNAS AutoML end-to-end Arqon AutoGrokML GUI configuration CLI/API-first design Cloud-hosted service Self-hosted only (for now)"},{"location":"project/roadmap/#feature-requests-voting","title":"Feature Requests &amp; Voting","text":"<p>We prioritize based on community feedback:</p> <ol> <li>GitHub Discussions \u2014 Propose new features</li> <li>Vote on existing \u2014 \ud83d\udc4d reaction on issues</li> <li>Contribute \u2014 PRs welcome for roadmap items</li> </ol>"},{"location":"project/roadmap/#version-comparison","title":"Version Comparison","text":"Feature v0.3 v0.4 v1.0 PCR Algorithm \u2705 \u2705 \u2705 Safety Executor \u2705 \u2705 \u2705 Python Bindings \u2705 \u2705 \u2705 Docker Images \u274c \u2705 \u2705 Helm Chart \u274c \u2705 \u2705 OpenTelemetry \u274c \u2705 \u2705 Multi-Objective \u274c \u2705 \u2705 GPU Acceleration \u274c \u274c \u2705 Distributed \u274c \u274c \u2705 Bayesian TPE \u274c \u274c \u2705"},{"location":"project/roadmap/#release-timeline","title":"Release Timeline","text":"<pre><code>gantt\n    title ArqonHPO Release Timeline\n    dateFormat  YYYY-MM\n    section Releases\n    v0.3 (Current)      :done,    v03, 2026-01, 2026-01\n    v0.4 Development    :active,  v04, 2026-01, 2026-03\n    v0.4 Release        :milestone, 2026-03, 0d\n    v1.0 Development    :         v10, 2026-03, 2026-06\n    v1.0 Release        :milestone, 2026-06, 0d</code></pre>"},{"location":"project/roadmap/#next-steps","title":"Next Steps","text":"<ul> <li>Changelog \u2014 Detailed version history</li> <li>Contributing \u2014 How to help</li> <li>About \u2014 Our philosophy</li> </ul>"},{"location":"project/test_coverage/","title":"Test Coverage","text":"<p>This document covers code coverage strategy, current status, and identified gaps for the ArqonHPO project.</p>"},{"location":"project/test_coverage/#quick-reference","title":"Quick Reference","text":"Metric Value Date Overall Line Coverage 79% Jan 2026 Total Tests ~290+ Files at 100% 5"},{"location":"project/test_coverage/#how-to-measure-coverage","title":"How to Measure Coverage","text":""},{"location":"project/test_coverage/#prerequisites","title":"Prerequisites","text":"<p>Install the coverage tooling:</p> <pre><code># Install cargo-llvm-cov\ncargo install cargo-llvm-cov\n\n# Install LLVM tools (required)\nrustup component add llvm-tools-preview\n</code></pre>"},{"location":"project/test_coverage/#running-coverage","title":"Running Coverage","text":"Quick SummaryHTML ReportShow Missing LinesJSON Export <pre><code># Summary table (fastest)\ncargo llvm-cov --workspace --exclude ship\n</code></pre> <pre><code># Generate HTML report\ncargo llvm-cov --workspace --exclude ship --html --open\n</code></pre> <pre><code># Show uncovered lines\ncargo llvm-cov --workspace --exclude ship --show-missing-lines\n</code></pre> <pre><code># Export for CI integration\ncargo llvm-cov --workspace --exclude ship --json --output-path coverage.json\n</code></pre>"},{"location":"project/test_coverage/#current-coverage-status","title":"Current Coverage Status","text":""},{"location":"project/test_coverage/#files-at-100-coverage","title":"Files at 100% Coverage \u2705","text":"File Tests Notes <code>config.rs</code> 18 Unit interval arithmetic, Domain, Scale <code>lib.rs</code> 1 Re-exports and add function <code>rng.rs</code> 1 RNG wrapper <code>ffi/lib.rs</code> 2 FFI bindings <code>telemetry.rs</code> 12 Ring buffer, digest validation"},{"location":"project/test_coverage/#high-coverage-80","title":"High Coverage (80%+) \ud83d\udfe2","text":"File Coverage Tests Key Functionality <code>control_safety.rs</code> 97% 15 SafeMode, thrashing detection, budget tracking <code>orchestrator.rs</code> 85% 11 AdaptiveEngine, SpsaProposer <code>executor.rs</code> 90% 10 Guardrails, RollbackPolicy <code>spsa.rs</code> 91% 8 SPSA optimization, trimmed mean <code>audit.rs</code> 94% 6 Audit event logging <code>classify.rs</code> 89% 8 Landscape classification <code>tpe.rs</code> 83% 6 Tree-structured Parzen Estimator <code>probe.rs</code> 79% 12 Prime index probe, uniform probe"},{"location":"project/test_coverage/#medium-coverage-60-80","title":"Medium Coverage (60-80%) \ud83d\udfe1","text":"File Coverage Gap Lines Improvement Path <code>main.rs</code> (CLI) 78% 327 TUI/dashboard server loops, stdin interactive <code>homeostasis.rs</code> 77% 5 Minor edge cases <code>config_atomic.rs</code> 79% 27 Atomic config updates <code>nelder_mead.rs</code> 67% 235 Complex state machine in <code>step()</code> <code>machine.rs</code> 72% 105 <code>ask()</code> phase transitions <code>multi_start_nm.rs</code> 63% 95 Coordinate descent, phase transitions"},{"location":"project/test_coverage/#low-coverage-60","title":"Low Coverage (&lt;60%) \ud83d\udd34","text":"File Coverage Gap Lines Root Cause <code>dashboard.rs</code> 56% 51 HTTP server, TUI rendering <code>proposer.rs</code> 83% 1 Single enum variant"},{"location":"project/test_coverage/#coverage-gaps-analysis","title":"Coverage Gaps Analysis","text":""},{"location":"project/test_coverage/#1-interactiveserver-code","title":"1. Interactive/Server Code","text":"<p>Files: <code>main.rs</code>, <code>dashboard.rs</code> Gap: ~378 lines combined</p> <p>These functions require running servers or reading from stdin:</p> <ul> <li><code>run_command</code> - Executes scripts in a loop</li> <li><code>interactive_command</code> - Reads JSON commands from stdin</li> <li><code>tui_command</code> - Terminal UI with crossterm</li> <li><code>dashboard_command</code> - HTTP server + TUI</li> </ul> <p>Recommendation: These are better tested via integration tests or E2E tests rather than unit tests.</p>"},{"location":"project/test_coverage/#2-nelder-mead-state-machine","title":"2. Nelder-Mead State Machine","text":"<p>File: <code>nelder_mead.rs</code> Gap: 235 lines in <code>step()</code> function</p> <p>The <code>step()</code> function is a complex state machine with many branches:</p> <ul> <li><code>Init</code> \u2192 build simplex</li> <li><code>Reflection</code> \u2192 expansion, contraction, or shrink</li> <li><code>Expansion</code>, <code>OutsideContraction</code>, <code>InsideContraction</code></li> <li><code>Shrink</code> \u2192 evaluate all shrunk points</li> <li><code>CoordinatePrepass</code> \u2192 greedy descent</li> <li><code>SimplexBuild</code> \u2192 waiting for vertex evaluations</li> </ul> <p>Recommendation: Create integration tests that drive the full optimization loop with known test functions (Rosenbrock, Sphere, Rastrigin).</p>"},{"location":"project/test_coverage/#3-multi-start-coordination","title":"3. Multi-Start Coordination","text":"<p>File: <code>multi_start_nm.rs</code> Gap: 95 lines in <code>step()</code> and <code>run_coordinate_descent()</code></p> <p>Multi-start NM coordinates multiple Nelder-Mead instances:</p> <ul> <li>Phase transitions: <code>CoordinateDescent</code> \u2192 <code>Triage</code> \u2192 <code>Commit</code></li> <li>Stall detection and start switching</li> <li>Best start selection</li> </ul> <p>Recommendation: Test with multi-modal test functions to exercise start switching.</p>"},{"location":"project/test_coverage/#4-solver-phase-transitions","title":"4. Solver Phase Transitions","text":"<p>File: <code>machine.rs</code> Gap: 105 lines in <code>ask()</code> method</p> <p>The solver's <code>ask()</code> method manages phase transitions:</p> <ul> <li><code>Probe</code> \u2192 <code>Classify</code> \u2192 <code>Refine(Landscape)</code> \u2192 <code>Done</code></li> <li>Strategy initialization based on landscape</li> </ul> <p>Recommendation: Create end-to-end optimization tests that run through all phases.</p>"},{"location":"project/test_coverage/#pre-push-coverage-checklist","title":"Pre-Push Coverage Checklist","text":"<p>Before pushing changes, verify coverage hasn't regressed:</p> <pre><code># 1. Run all tests\ncargo test --workspace --exclude ship\n\n# 2. Check coverage summary\ncargo llvm-cov --workspace --exclude ship\n\n# 3. Verify no new 0% files\ncargo llvm-cov --workspace --exclude ship 2&gt;&amp;1 | grep \"0.00%\"\n\n# 4. (Optional) Generate HTML report for detailed review\ncargo llvm-cov --workspace --exclude ship --html --open\n</code></pre>"},{"location":"project/test_coverage/#coverage-improvement-plan","title":"Coverage Improvement Plan","text":""},{"location":"project/test_coverage/#phase-1-unit-tests-complete","title":"Phase 1: Unit Tests (Complete \u2705)","text":"<ul> <li>[x] <code>config.rs</code> - 0% \u2192 100%</li> <li>[x] <code>lib.rs</code> - 0% \u2192 100%</li> <li>[x] <code>orchestrator.rs</code> - 0% \u2192 85%</li> <li>[x] <code>control_safety.rs</code> - 68% \u2192 97%</li> <li>[x] <code>telemetry.rs</code> - 73% \u2192 100%</li> </ul>"},{"location":"project/test_coverage/#phase-2-strategy-tests-in-progress","title":"Phase 2: Strategy Tests (In Progress)","text":"<ul> <li>[x] <code>nelder_mead.rs</code> - 48% \u2192 67%</li> <li>[x] <code>multi_start_nm.rs</code> - 34% \u2192 63%</li> <li>[ ] Target: 80%+ with integration tests</li> </ul>"},{"location":"project/test_coverage/#phase-3-cli-integration-tests-planned","title":"Phase 3: CLI Integration Tests (Planned)","text":"<ul> <li>[ ] <code>ask_command</code> E2E</li> <li>[ ] <code>tell_command</code> E2E</li> <li>[ ] <code>export</code>/<code>import</code> round-trip</li> </ul>"},{"location":"project/test_coverage/#phase-4-interactive-code-deferred","title":"Phase 4: Interactive Code (Deferred)","text":"<ul> <li>[ ] TUI tests with mock terminal</li> <li>[ ] Dashboard tests with mock HTTP client</li> <li>[ ] Interactive mode with stdin pipes</li> </ul>"},{"location":"project/test_coverage/#ci-integration","title":"CI Integration","text":"<p>Coverage is automatically measured in CI via Codecov. The GitHub Actions workflow:</p> <ol> <li>Runs <code>cargo llvm-cov</code> on each PR</li> <li>Uploads results to Codecov</li> <li>Posts coverage diff as PR comment</li> </ol> <p>See CI/CD Runbook for workflow details.</p>"},{"location":"why/","title":"Product Overview","text":"<p>ArqonHPO is built on a radical premise: optimization is a control problem, not a search problem.</p>"},{"location":"why/#the-architecture-of-speed","title":"The Architecture of Speed","text":"<p>Standard HPO libraries treat your system as a black box function $f(x) \\rightarrow y$. They pause the world, run the function, and wait.</p> <p>ArqonHPO treats your system as a flow:</p> <ol> <li>Probe (Tier 0): Low-discrepancy sampling scans the landscape.</li> <li>Classify (Tier $\\Omega$): Is the signal structured (physics) or chaotic (noise)?</li> <li>Refine (Tier 2): The Adaptive Engine proposes safe deltas.</li> <li>Enforce (Tier 1): The Safety Executor applies changes atomically.</li> </ol> <p>Read about the Architecture</p>"},{"location":"why/#core-components","title":"Core Components","text":"<ul> <li>Safety Executor: The gatekeeper. Enforces rate limits, rollback contracts, and value bounds.</li> <li>Adaptive Engine: The brain. Uses SPSA or Nelder-Mead to steer parameters.</li> <li>Telemetry Ring: Lock-free, allocation-free circular buffer for observation.</li> </ul>"},{"location":"why/architecture/","title":"Architecture","text":"<p>ArqonHPO is built as a control primitive, not a search algorithm. This page explains how the pieces fit together.</p>"},{"location":"why/architecture/#system-overview","title":"System Overview","text":"<pre><code>graph LR\n    subgraph \"ArqonHPO Runtime\"\n        A[Telemetry] --&gt; B[Probe]\n        B --&gt; C[Classify]\n        C --&gt; D[Refine]\n        D --&gt; E[Safety Executor]\n        E --&gt; F[Apply]\n    end\n\n    F --&gt; G[Your System]\n    G --&gt; A</code></pre>"},{"location":"why/architecture/#the-pcr-loop","title":"The PCR Loop","text":"<p>ArqonHPO uses a Probe \u2192 Classify \u2192 Refine architecture:</p>"},{"location":"why/architecture/#1-probe-tier-0","title":"1. Probe (Tier 0)","text":"<p>Goal: Efficiently scan the parameter landscape.</p> <ul> <li>Uses Low-Discrepancy Sequences (LDS) for uniform coverage</li> <li>Prime-sqrt-slopes rotation for high-dimensional spaces</li> <li>Stateless, deterministic, shardable via <code>ArqonProbe</code></li> </ul>"},{"location":"why/architecture/#2-classify-tier","title":"2. Classify (Tier \u03a9)","text":"<p>Goal: Detect whether the landscape is structured or chaotic.</p> <ul> <li>Analyzes probe results for patterns</li> <li>Determines optimal strategy for refinement</li> <li>Detects: smooth gradients vs. noisy/multimodal surfaces</li> </ul>"},{"location":"why/architecture/#3-refine-tier-2","title":"3. Refine (Tier 2)","text":"<p>Goal: Converge to optimal parameters.</p> <p>Strategies:</p> <ul> <li>Nelder-Mead \u2014 Simplex method for smooth functions</li> <li>Multi-Start Nelder-Mead \u2014 Parallel restarts for multimodal</li> <li>TPE \u2014 Bayesian optimization for noisy landscapes</li> </ul>"},{"location":"why/architecture/#safety-layer-hotpath","title":"Safety Layer (Hotpath)","text":"<p>The Safety Executor enforces governance on every parameter update:</p> <pre><code>graph TD\n    A[Proposal] --&gt; B{Guardrails Check}\n    B --&gt;|Pass| C{Rate Limit Check}\n    B --&gt;|Fail| D[Violation]\n    C --&gt;|Pass| E{Bounds Check}\n    C --&gt;|Fail| D\n    E --&gt;|Pass| F[Apply Atomically]\n    E --&gt;|Fail| D\n    F --&gt; G[Audit Log]\n    D --&gt; G</code></pre>"},{"location":"why/architecture/#key-components","title":"Key Components","text":"Component Responsibility <code>SafetyExecutor</code> Enforces all safety rules <code>Guardrails</code> Configures bounds, rate limits, delta limits <code>RollbackPolicy</code> Defines when to revert changes <code>ControlSafety</code> Implements safe mode and exemptions <code>AuditQueue</code> Lock-free event logging"},{"location":"why/architecture/#crate-structure","title":"Crate Structure","text":"<pre><code>crates/\n\u251c\u2500\u2500 core/           # Solver, Probe, Classify, Strategies\n\u2502   \u2514\u2500\u2500 strategies/ # Nelder-Mead, Multi-Start NM, TPE\n\u251c\u2500\u2500 hotpath/        # Safety Executor, SPSA, Telemetry, Audit\n\u251c\u2500\u2500 cli/            # CLI, TUI, Dashboard\n\u251c\u2500\u2500 ffi/            # C FFI bindings\n\u2514\u2500\u2500 ship/           # ArqonShip DevSecOps tool\n\nbindings/\n\u2514\u2500\u2500 python/         # PyO3 bindings (ArqonSolver, ArqonProbe)\n</code></pre>"},{"location":"why/architecture/#data-flow","title":"Data Flow","text":"<ol> <li>User calls <code>ask()</code> \u2192 Solver returns candidate parameters</li> <li>User evaluates candidates \u2192 calls <code>tell()</code> with results</li> <li>Solver updates internal state, refines strategy</li> <li>Repeat until budget exhausted</li> </ol> <p>For online mode, use <code>ask_one()</code> + <code>seed()</code> for single-candidate flow.</p>"},{"location":"why/architecture/#performance-characteristics","title":"Performance Characteristics","text":"Metric Value Overhead per trial ~3ms Throughput ~33,000 trials/sec Memory O(history_size) Deterministic Yes (with fixed seed)"},{"location":"why/architecture/#next-steps","title":"Next Steps","text":"<ul> <li>Quickstart \u2014 Get running in 5 minutes</li> <li>Safety Deep Dive \u2014 Guardrails and rollback</li> <li>Strategies \u2014 When to use each</li> </ul>"}]}