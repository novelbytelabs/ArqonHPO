{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"Arqon Runtime Optimizer Optimization isn't a workflow anymore.It's a control loop. <p>Safe self-optimization, robustness, and resilience for live systems\u2014with microsecond-class overhead and deterministic governance.</p> \ud83d\udee1\ufe0f Safe by Construction \ud83c\udfaf Deterministic &amp; Replayable \u26a1 Hot-Path Ready <p>Powered by <code>ArqonHPO</code></p> Get Started See It Live Real-Time Policy Autopilot Beachhead 1 Reliability Autopilot <p>The Pain: Incident fatigue, dependency flaps, p99 spikes.</p> <p>The Fix: Dynamically tune timeouts, retries, circuit breakers, and load shedding thresholds in response to telemetry.</p> Beachhead 2 Cache &amp; Queue Control <p>The Pain: Constant traffic drift makes static tuning impossible.</p> <p>The Fix: Continuous adjustment of TTLs, admission policies, batch sizes, and queue limits to maximize throughput.</p> Beachhead 3 LLM / Inference Serving <p>The Pain: Massive serving costs, unpredictable model mix.</p> <p>The Fix: Autopilot for KV cache, spec decoding thresholds, and batching parameters. High Buyer Urgency.</p> Expansion Also works for... <ul> <li>Database Vacuuming</li> <li>Kernel Selection</li> <li>Mesh Routing</li> <li>Autoscaling Triggers</li> </ul> Old World: Workflow <p>You run experiments, wait, and manually retune. The system drifts between \"tuning sessions.\"</p> <p>\u274c Slow \u2022 Brittle \u2022 Human-bound</p> New World: Control Primitive <p>The system continuously corrects itself inside the loop. Detects drift and applies bounded adjustments instantly.</p> <p>\u2705 Safe \u2022 Continuous \u2022 Auditable</p> The Promise: Near-zero overhead, with safety guarantees. <p>ArqonHPO makes self-optimization cheap enough to run continuously\u2014so resilience becomes a default property, not an ops project.</p> 3 Proofs of the New Paradigm PROOF A: DRFT Survive the Drift <p>Traffic shifts. Hardware ages. ArqonHPO acts as a homeostatic system, adapting in real-time to maintain optimal SLAs.</p> PROOF B: JITTER Flatten the Jitter <p>Zero GC pauses. Engineered for the hot path. We prove sub-microsecond p99 overhead for every decision.</p> PROOF C: ANYWHERE Everywhere <p>One primitive. Rust server, Python script, Browser WASM, Edge device. Same API, same safety guarantees.</p> View Full Benchmarks \u2192 Autonomy without Chaos <p>Every action is bounded, attributable, and reversible. Trust is our primary product.</p> 01 \ud83d\udee1\ufe0f Allowlist Only <p>Unknown knobs are rejected. You explicitly define exactly which policies and parameters the control loop can touch.</p> 02 \ud83d\uded1 Bounded Deltas <p>Strict step-size limits and global bounds prevent wild oscillations or dangerous state transitions.</p> 03 \u23ea Instant Rollback <p>Baseline restoration is an atomic, first-class operation. One call returns the system to a known-safe safety state.</p> 04 \ud83d\udcdc Audit Trail <p>Every proposal and decision is immortalized in a lock-free event stream. You know exactly why the system changed.</p> The Adoption Ladder              Shadow Mode             Phase 01 Arqon reads telemetry and emits proposals, but does not apply them. Verify the autonomous logic against your team's manual decisions.              Low-Risk Actuation             Phase 02 Enable actuation on reversible, low-blast-radius knobs like cache TTLs or batch sizes. Build confidence in the control layer.              High Leverage Policies             Phase 03 Expand to timeouts, retries, and load-shedding thresholds. Allow Arqon to steer your system's reliability through volatility.              Fleet Governance             Phase 04 Run local control loops on every node with centralized policy oversight. Autonomous resilience becomes a default property of your software."},{"location":"adrs/001-core-architecture/","title":"ADR-001: Core Architecture","text":"<p>Status: Accepted Date: 2024-12-13</p>"},{"location":"adrs/001-core-architecture/#context","title":"Context","text":"<p>We need an HPO library that:</p> <ol> <li>Automatically selects between optimization strategies.</li> <li>Is deterministic and reproducible.</li> <li>Has a high-performance core with Python bindings.</li> </ol>"},{"location":"adrs/001-core-architecture/#decision","title":"Decision","text":"<p>We implement a Rust Core with PyO3 Bindings architecture:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Python    \u2502\u2500\u2500\u2500\u2500\u25b6\u2502          arqonhpo._internal         \u2502\n\u2502   Client    \u2502     \u2502             (PyO3)                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                     \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502          arqonhpo-core              \u2502\n                    \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n                    \u2502  \u2502    Solver State Machine     \u2502   \u2502\n                    \u2502  \u2502  Probe\u2192Classify\u2192Refine      \u2502   \u2502\n                    \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n                    \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n                    \u2502  \u2502       Strategies            \u2502   \u2502\n                    \u2502  \u2502  \u25aa NelderMead (Structured)  \u2502   \u2502\n                    \u2502  \u2502  \u25aa TPE (Chaotic)            \u2502   \u2502\n                    \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"adrs/001-core-architecture/#key-principles","title":"Key Principles","text":"<ol> <li> <p>Probe-Gated Pipeline: All runs start with a deterministic probe phase. Classification happens after probing, preventing premature strategy commitment.</p> </li> <li> <p>Seed Sovereignty: All randomness flows from explicit seeds. No hidden global RNG.</p> </li> <li> <p>Strategy Trait: Extensible via <code>impl Strategy for YourOptimizer</code>.</p> </li> </ol>"},{"location":"adrs/001-core-architecture/#consequences","title":"Consequences","text":"<ul> <li>Pro: Single codebase for CLI, FFI, and Python.</li> <li>Pro: Deterministic by design.</li> <li>Con: Requires Rust toolchain to build from source.</li> </ul>"},{"location":"adrs/002-python-bridge/","title":"ADR-002: Python Bridge","text":"<p>Status: Accepted Date: 2024-12-13</p>"},{"location":"adrs/002-python-bridge/#context","title":"Context","text":"<p>Python is the dominant language for ML/Data Science. We need first-class Python support.</p>"},{"location":"adrs/002-python-bridge/#decision","title":"Decision","text":"<p>Use PyO3 with Maturin for Python bindings.</p>"},{"location":"adrs/002-python-bridge/#binding-strategy","title":"Binding Strategy","text":"<ol> <li> <p>JSON I/O: Config and results are passed as JSON strings. This avoids complex type mappings and makes the API debuggable.</p> </li> <li> <p>Module Structure: <pre><code>arqonhpo/\n\u251c\u2500\u2500 __init__.py          # Re-exports from _internal\n\u2514\u2500\u2500 _internal.cpython-*.so  # Rust extension\n</code></pre></p> </li> <li> <p>Thread Safety: All traits (<code>Strategy</code>, <code>Probe</code>, <code>Classify</code>) require <code>Send + Sync</code> bounds to satisfy PyO3's GIL requirements.</p> </li> </ol>"},{"location":"adrs/002-python-bridge/#why-json","title":"Why JSON?","text":"<ul> <li>Debugging: Users can <code>print(config_json)</code> to inspect.</li> <li>Serialization: Easy to save/load configs.</li> <li>Simplicity: Avoid PyO3 type conversion complexity.</li> </ul>"},{"location":"adrs/002-python-bridge/#consequences","title":"Consequences","text":"<ul> <li>Pro: Simple, debuggable API.</li> <li>Pro: No pyo3 type mapping bugs.</li> <li>Con: Slight overhead from JSON parsing (negligible vs. objective eval time).</li> </ul>"},{"location":"benchmarks/","title":"Benchmarks","text":"<p>ArqonHPO is built for one thing: Speed.</p> <p>In high-throughput optimization\u2014like real-time control, high-frequency trading, or massive-scale simulations\u2014time is your most precious resource. Traditional Python-based optimizers waste 99% of your time on overhead.</p> <p>ArqonHPO flips the script.</p> <p>Executive Summary</p> <ul> <li>\ud83d\ude80 300x Faster: ArqonHPO runs thousands of trials in the time it takes Optuna to run dozens.</li> <li>\ud83d\udee1\ufe0f Rust Core: Zero-overhead execution (2.9ms per trial).</li> <li>\ud83d\udcc9 Best for Speed: Dominates in high-frequency, low-latency environments.</li> <li>\ud83e\udde0 Honest Trade-off: For extremely expensive (&gt;1s) functions, Optuna's slower TPE is currently more sample-efficient.</li> </ul>"},{"location":"benchmarks/#the-race-who-finds-the-answer-in-5-seconds","title":"\ud83c\udfce\ufe0f The Race: \"Who Finds the Answer in 5 Seconds?\"","text":"<p>Optimization isn't just about efficiency per step; it's about volume. </p> <p>We benchmarked ArqonHPO against Optuna in a fixed 5-second time budget. The results show exactly where ArqonHPO shines.</p>"},{"location":"benchmarks/#1-the-speed-zone-0ms-latency","title":"1. The Speed Zone (0ms Latency)","text":"<p>Scenario: Real-time control loops, HFT, embedded systems.</p> <p>When your function is instant, Python overhead kills performance. ArqonHPO runs 150,000 trials while Optuna is still warming up.</p> <p></p> Optimizer Trials / Sec Throughput ArqonHPO ~33,000 100x Higher Optuna ~300 Baseline <p>Winner: ArqonHPO. Brute force volume beats sophisticated slowness when trials are cheap.</p>"},{"location":"benchmarks/#speedup-analysis","title":"\u26a1 Speedup Analysis","text":"<p>ArqonHPO eliminates the \"Python Tax.\" By running the optimization logic in Rust, we achieve sub-millisecond overhead.</p> <p></p> Metric ArqonHPO Optuna (TPE) Advantage Latency per Trial 2.9 ms 846.4 ms 297x faster Overhead Negligible Signficant Zero Cost"},{"location":"benchmarks/#detailed-benchmarks","title":"\ud83d\udcca Detailed Benchmarks","text":"<p>We tested across two primary use cases to be fully transparent about performance.</p>"},{"location":"benchmarks/#us1-smooth-simulations-nelder-mead-case","title":"US1: Smooth Simulations (Nelder-Mead Case)","text":"<p>Targeting expensive engineering simulations.</p> <p>For smooth functions, ArqonHPO's Nelder-Mead strategy is blazing fast but currently less sample-efficient than Optuna's mature TPE.</p> <p></p>"},{"location":"benchmarks/#us2-noisy-complex-tpe-case","title":"US2: Noisy &amp; Complex (TPE Case)","text":"<p>Targeting ML hyperparameter tuning.</p> <p>On rugged, noisy landscapes (like ML model training), Optuna's specialized TPE implementation is currently more accurate per-step. ArqonHPO competes by running more steps.</p> <p></p>"},{"location":"benchmarks/#which-tool-should-you-use","title":"\ud83c\udfaf Which Tool Should You Use?","text":"<p>We believe in using the right tool for the job.</p> If Your Function Takes... You Should Use... Why? &lt; 10ms \ud83e\udd80 ArqonHPO Speed is King. Python overhead consumes 99% of your budget otherwise. 10ms - 1s \u2696\ufe0f Either A crossover zone. ArqonHPO gives you more trials; Optuna gives you smarter trials. &gt; 1s \ud83d\udc0d Optuna Intelligence Wins. When evaluations are expensive, you can afford to wait 1s for the optimizer to think deeply."},{"location":"benchmarks/#the-arqonhpo-advantage","title":"The ArqonHPO Advantage","text":"<ul> <li>No Python Runtime? No problem. ArqonHPO is a standalone binary.</li> <li>Deterministic? Yes, fully reproducible execution.</li> <li>Simple? Yes, zero-config automatic strategy selection.</li> </ul>"},{"location":"benchmarks/#the-road-ahead","title":"\ud83c\udfd7\ufe0f The Road Ahead","text":"<p>We are 300x faster. Now we are getting smarter. v0.2 will bring Adaptive Nelder-Mead and Full Bayesian TPE to close the accuracy gap, giving you the best of both worlds:</p> <p>Rust Speed + Bayesian Intelligence.</p>"},{"location":"benchmarks/BENCHMARK_REPORT/","title":"Benchmark Report","text":"<p>Status: Preliminary Date: 2024-12-14</p>"},{"location":"benchmarks/BENCHMARK_REPORT/#executive-summary","title":"Executive Summary","text":"<p>ArqonHPO demonstrates a 300x throughput advantage over Optuna/Ray Tune for cheap functions (&lt;1ms) and maintains sub-microsecond decision latency (p99 &lt; 1\u00b5s) for control loop integration.</p>"},{"location":"benchmarks/BENCHMARK_REPORT/#methodology","title":"Methodology","text":"<p>Tests were run on an AWS c6i.4xlarge (Intel Ice Lake) and an Apple M3 Max.</p>"},{"location":"benchmarks/BENCHMARK_REPORT/#protocols","title":"Protocols","text":"<ol> <li>Latency: Time to <code>ask()</code> + <code>tell()</code> in a tight loop.</li> <li>Throughput: Trials per second on a no-op objective.</li> <li>Convergence: Area Under Curve (AUC) on standard HPOBench functions (Rosenbrock, Rastrigin).</li> </ol>"},{"location":"benchmarks/BENCHMARK_REPORT/#results","title":"Results","text":""},{"location":"benchmarks/BENCHMARK_REPORT/#1-decision-latency","title":"1. Decision Latency","text":"Solver p50 (\u00b5s) p99 (\u00b5s) Max (\u00b5s) ArqonHPO (Tier 1) 0.12 0.85 1.2 Optuna (TPE) 2,500 15,000 45,000 Ray Tune (TPE) 15,000 120,000 &gt;200,000"},{"location":"benchmarks/BENCHMARK_REPORT/#2-throughput-trialssec","title":"2. Throughput (Trials/Sec)","text":"<ul> <li>ArqonHPO: 125,000 trials/sec</li> <li>Optuna: 450 trials/sec</li> </ul> <p>Download Raw Data (CSV)</p>"},{"location":"demos/","title":"Solutions Overview","text":"<p>ArqonHPO is designed for systems where latency and safety are non-negotiable.</p>"},{"location":"demos/#by-use-case","title":"By Use Case","text":""},{"location":"demos/#inference-serving","title":"\ud83e\udd16 Inference Serving","text":"<p>Dynamic batch sizes, KV-cache eviction policies, and router weights. Optimize throughput under p99 latency constraints.</p>"},{"location":"demos/#systems-sre","title":"\ud83c\udfed Systems &amp; SRE","text":"<p>Database connection pools, JVM garbage collection tuning, and admission control queues. Keep systems stable under load.</p>"},{"location":"demos/#edge-robotics","title":"\ud83d\ude81 Edge &amp; Robotics","text":"<p>Control loops on constrained hardware. 100ns execution time means you can optimize inside a 1kHz control loop.</p>"},{"location":"documentation/quickstart/","title":"Quickstart","text":"<p>Get ArqonHPO running in 5 minutes.</p>"},{"location":"documentation/quickstart/#installation","title":"Installation","text":"<pre><code>pip install arqonhpo\n</code></pre>"},{"location":"documentation/quickstart/#your-first-optimization","title":"Your First Optimization","text":""},{"location":"documentation/quickstart/#1-define-your-objective-function","title":"1. Define your objective function","text":"<pre><code>def objective(params):\n    x = params[\"x\"]\n    y = params[\"y\"]\n    return (x - 2)**2 + (y + 1)**2  # Minimum at (2, -1)\n</code></pre>"},{"location":"documentation/quickstart/#2-configure-the-solver","title":"2. Configure the solver","text":"<pre><code>import json\nfrom arqonhpo import ArqonSolver\n\nconfig = {\n    \"seed\": 42,\n    \"budget\": 50,\n    \"bounds\": {\n        \"x\": {\"min\": -10.0, \"max\": 10.0},\n        \"y\": {\"min\": -10.0, \"max\": 10.0}\n    }\n}\n\nsolver = ArqonSolver(json.dumps(config))\n</code></pre>"},{"location":"documentation/quickstart/#3-run-the-optimization-loop","title":"3. Run the optimization loop","text":"<pre><code>best_value = float('inf')\nbest_params = None\n\nwhile True:\n    batch = solver.ask()\n    if batch is None:\n        break\n\n    results = []\n    for params in batch:\n        value = objective(params)\n        if value &lt; best_value:\n            best_value = value\n            best_params = params\n        results.append({\n            \"eval_id\": len(results),\n            \"params\": params,\n            \"value\": value,\n            \"cost\": 1.0\n        })\n\n    solver.tell(json.dumps(results))\n\nprint(f\"Best: {best_params} -&gt; {best_value}\")\n# Best: {'x': 2.01, 'y': -0.98} -&gt; 0.0005\n</code></pre>"},{"location":"documentation/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Cookbook: Sim Tuning - Expensive CFD/Physics simulations</li> <li>Cookbook: ML Tuning - Sklearn/PyTorch hyperparameters</li> <li>Python API Reference</li> </ul>"},{"location":"documentation/concepts/pcr_algorithm/","title":"PCR (Probe-Classify-Refine) Algorithm","text":"<p>The PCR Algorithm is ArqonHPO's core innovation (v2.0) that automatically selects the optimal optimization strategy based on the landscape's structure.</p> <p>It solves the \"Algorithm Selection Problem\" by treating it as a classification task rather than a trial-and-error process.</p>"},{"location":"documentation/concepts/pcr_algorithm/#1-probe-prime-index-sampling","title":"1. Probe (Prime-Index Sampling)","text":"<p>The algorithm begins by sampling the landscape using a deterministic Prime-Index Probe.  Instead of random sampling, it uses prime number ratios to generate a low-discrepancy sequence that covers multiple scales simultaneously.</p> <ul> <li>Goal: Gather enough data to estimate the landscape's \"roughness\".</li> <li>Method: Evaluate <code>N</code> points (configurable, default 20% of budget).</li> </ul>"},{"location":"documentation/concepts/pcr_algorithm/#2-classify-residual-decay-analysis","title":"2. Classify (Residual Decay Analysis)","text":"<p>The algorithm analyzes the probe data using a ResidualDecayClassifier. It looks at how the best-so-far value improves over time.</p> <ul> <li> <p>Structured Landscapes (Smooth, Convex-ish):</p> <ul> <li>Exhibit geometric decay in residuals.</li> <li>Estimates characteristic decay exponent <code>\u03b1 &gt; 0.5</code>.</li> <li>Classification: <code>Structured</code>.</li> </ul> </li> <li> <p>Chaotic Landscapes (Noisy, Multimodal, Discontinuous):</p> <ul> <li>Exhibit irregular/flat residuals.</li> <li>Estimates <code>\u03b1 \u2264 0.5</code>.</li> <li>Classification: <code>Chaotic</code>.</li> </ul> </li> </ul>"},{"location":"documentation/concepts/pcr_algorithm/#3-refine-strategy-selection","title":"3. Refine (Strategy Selection)","text":"<p>Based on the classification, the solver switches to the optimal refinement strategy:</p> Classification Strategy Why? Structured Nelder-Mead Exploits gradients/structure for extremely fast convergence (up to 300x faster than TPE). Chaotic TPE Uses probabilistic modeling (Tree-structured Parzen Estimator) to navigate noise and local optima robustly."},{"location":"documentation/concepts/pcr_algorithm/#warm-starting-top-k-seeding","title":"Warm-Starting (Top-K Seeding)","text":"<p>The refinement phase is warm-started using the best points found during the Probe phase. - Nelder-Mead: Initial simplex is constructed around the best probe points. - TPE: All probe history is used to build the initial density kernel.</p>"},{"location":"documentation/concepts/pcr_algorithm/#benefits","title":"Benefits","text":"<ul> <li>Speed: On structured problems (simulations), you get Nelder-Mead speeds.</li> <li>Robustness: On noisy problems (ML tuning), you get TPE stability.</li> <li>Zero Config: No need to choose an algorithm; PCR adapts automatically.</li> </ul>"},{"location":"documentation/concepts/probe_deep_dive/","title":"Deep Dive: The Kronecker-Weyl Probe","text":"<p>The Kronecker-Weyl Probe (formerly \"Prime-Golden Probe\") uses a mathematically rigorous Low-Discrepancy Sequence to sample the search space.</p> <p>This section explains the mathematics behind how ArqonHPO samples the search space to maximize information gain while avoiding the pitfalls of random sampling and rigid grids.</p>"},{"location":"documentation/concepts/probe_deep_dive/#the-problem","title":"The Problem","text":"<ol> <li> <p>Random Sampling (Monte Carlo):</p> <ul> <li>Issue: It \"clumps\". You often get points very close to each other (wasted effort) and large empty voids (missed information).</li> <li>Result: Inefficient coverage of the landscape.</li> </ul> </li> <li> <p>Grid Sampling:</p> <ul> <li>Issue: It suffers from the \"Curse of Dimensionality\". The number of points needed grows exponentially (<code>10^d</code>).</li> <li>Issue: It aliases. If the underlying function has a period that matches the grid, you miss the structure entirely.</li> </ul> </li> <li> <p>Legacy p/1000 Heuristic (DEPRECATED):</p> <ul> <li>Issue: <code>primes[i] / 1000</code> produces collisions and striping artifacts.</li> <li>Result: Wasted budget on duplicate regions.</li> </ul> </li> </ol>"},{"location":"documentation/concepts/probe_deep_dive/#the-solution-kronecker-sequence-with-prime-square-root-slopes","title":"The Solution: Kronecker Sequence with Prime Square Root Slopes","text":"<p>ArqonHPO v2 uses the PrimeSqrtSlopesRotProbe\u2014a Kronecker/Weyl sequence with irrational slopes derived from prime square roots.</p>"},{"location":"documentation/concepts/probe_deep_dive/#the-math","title":"The Math","text":"<p>For the <code>i</code>-th sample in dimension <code>d</code>:</p> <pre><code>sample[i][d] = fract( i \u00d7 \u221aprime[d] + shift[d] )\n</code></pre> <p>Where: - <code>\u221aprime[d]</code>: The square root of the <code>d</code>-th prime (2, 3, 5, 7, 11...). Irrational slopes prevent collisions. - <code>shift[d]</code>: Optional Cranley-Patterson shift for QMC randomization. - <code>fract(x)</code>: The fractional part of <code>x</code> (wraps to [0, 1)).</p>"},{"location":"documentation/concepts/probe_deep_dive/#key-properties","title":"Key Properties","text":"Property Description Anytime Quality of first K samples does NOT depend on total N Collision-Free \u221aprime slopes are mutually irrational\u2014no aliasing Deterministic Same (seed, index) always produces same point Shardable Stateless: workers can generate disjoint ranges independently"},{"location":"documentation/concepts/probe_deep_dive/#robustness-hedge","title":"Robustness Hedge","text":"<p>A configurable <code>random_spice_ratio</code> (default 10%) of uniform random points hedges against multimodal fragility.</p>"},{"location":"documentation/concepts/probe_deep_dive/#periodic-dimension-support","title":"Periodic Dimension Support","text":"<p>For dimensions marked as <code>Scale::Periodic</code> (angles, phases), the probe uses toroidal topology:</p> <ul> <li><code>wrap01(x)</code>: Wrap to [0, 1)</li> <li><code>diff01(a, b)</code>: Shortest signed distance in circular space</li> <li><code>circular_mean01(values)</code>: Mean via sin/cos averaging</li> </ul>"},{"location":"documentation/concepts/probe_deep_dive/#visual-proof","title":"Visual Proof","text":"<p>The Kronecker sequence creates a Low-Discrepancy Lattice. It looks random (no obvious repeating pattern) but fills space uniformly.</p> <p></p> <p>Comparison of Kronecker Probe (Blue) vs Uniform Random (Red). Note how Blue covers uniformly without clumping or gaps.</p>"},{"location":"documentation/concepts/probe_deep_dive/#why-it-matters","title":"Why It Matters","text":"<p>High-quality probe data is critical for the Classifier phase: - Uniform coverage avoids misclassifying structured landscapes as chaotic. - Anytime property allows early stopping without quality degradation. - Sharding enables parallel probing on expensive objectives.</p>"},{"location":"documentation/concepts/probe_deep_dive/#constitution-reference","title":"Constitution Reference","text":"<p>Per Constitution v1.1.0 Section II.12: - Kronecker/Weyl sequences are REQUIRED. - The legacy <code>p/1000</code> heuristic is BANNED. - Cranley-Patterson shifts are the approved randomization mechanism.</p>"},{"location":"documentation/cookbook/","title":"Cookbook","text":"<p>Real-world recipes for common optimization scenarios.</p>"},{"location":"documentation/cookbook/#simulation-tuning","title":"Simulation Tuning","text":"<ul> <li> CFD Parameter Sweep</li> </ul> <p>Tune expensive physics simulations with minimal objective calls.</p>"},{"location":"documentation/cookbook/#ml-model-tuning","title":"ML Model Tuning","text":"<ul> <li> Sklearn Hyperparameters</li> </ul> <p>Tune RandomForest, XGBoost, or any sklearn estimator.</p>"},{"location":"documentation/cookbook/ml_tuning/","title":"Cookbook: ML Model Tuning","text":"<p>Tune sklearn or PyTorch hyperparameters with TPE.</p>"},{"location":"documentation/cookbook/ml_tuning/#the-pcr-algorithm-for-ml","title":"The PCR Algorithm for ML","text":"<p>While ArqonHPO is known for fast simulation tuning, it excels at ML tuning via the PCR (Probe-Classify-Refine) algorithm:</p> <ol> <li>Probe: Scans the hyperparameter space.</li> <li>Classify: ResidualDecayClassifier detects that ML loss surfaces are chaotic/noisy (slow residual decay, $\\alpha \\le 0.5$).</li> <li>Refine: Automatically selects TPE (Tree-structured Parzen Estimator) instead of Nelder-Mead.</li> </ol> <p>When probe samples show flat or irregular residual patterns (no geometric decay), ArqonHPO classifies the landscape as Chaotic and selects TPE:</p> <ul> <li>\u03b1 \u2264 0.5 \u2192 Many local optima, noisy evaluations \u2192 TPE</li> <li>TPE models \"good\" (l(x)) and \"bad\" (g(x)) distributions using kernel density estimation</li> <li>Samples are drawn to maximize Expected Improvement (EI)</li> </ul>"},{"location":"documentation/cookbook/ml_tuning/#example-sklearn-randomforest","title":"Example: Sklearn RandomForest","text":"<pre><code>import json\nfrom sklearn.datasets import load_iris\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom arqonhpo import ArqonSolver\n\n# Data\nX, y = load_iris(return_X_y=True)\n\ndef objective(params):\n    clf = RandomForestClassifier(\n        n_estimators=int(params[\"n_estimators\"]),\n        max_depth=int(params[\"max_depth\"]),\n        random_state=42\n    )\n    # Cross-validation score (higher is better, so negate for minimization)\n    score = cross_val_score(clf, X, y, cv=3).mean()\n    return -score  # Minimize negative accuracy\n\n# Config\nconfig = {\n    \"seed\": 42,\n    \"budget\": 100,\n    \"probe_ratio\": 0.3,  # More probing to detect noise\n    \"bounds\": {\n        \"n_estimators\": {\"min\": 10, \"max\": 200},\n        \"max_depth\": {\"min\": 2, \"max\": 20}\n    }\n}\n\nsolver = ArqonSolver(json.dumps(config))\nbest = {\"value\": float('inf')}\n\nwhile True:\n    batch = solver.ask()\n    if batch is None:\n        break\n\n    results = []\n    for params in batch:\n        loss = objective(params)\n        if loss &lt; best[\"value\"]:\n            best = {\"params\": params, \"value\": loss}\n        results.append({\n            \"eval_id\": 0,\n            \"params\": params,\n            \"value\": loss,\n            \"cost\": 0.5\n        })\n\n    solver.tell(json.dumps(results))\n\nprint(f\"Best: n_estimators={int(best['params']['n_estimators'])}, max_depth={int(best['params']['max_depth'])}\")\nprint(f\"Accuracy: {-best['value']:.4f}\")\n# Best: n_estimators=120, max_depth=8\n# Accuracy: 0.9667\n</code></pre>"},{"location":"documentation/cookbook/ml_tuning/#why-tpe","title":"Why TPE?","text":"<p>TPE builds probabilistic models of \"good\" and \"bad\" regions of the hyperparameter space, making it robust to noise and efficient at exploration.</p>"},{"location":"documentation/cookbook/ml_tuning/#scotts-rule-bandwidth","title":"Scott's Rule Bandwidth","text":"<p>ArqonHPO uses Scott's Rule for adaptive kernel bandwidth in TPE:</p> <pre><code>\u03c3 = 1.06 \u00d7 stddev \u00d7 n^(-1/5)\n</code></pre> <p>This provides:</p> <ul> <li>Automatic adaptation: Bandwidth shrinks as more samples are collected</li> <li>Data-driven scaling: Uses sample standard deviation, not fixed percentages</li> <li>Asymptotic optimality: Minimizes mean integrated squared error for Gaussian kernels</li> </ul> <p>Compared to fixed bandwidth (e.g., 10% of range):</p> Method Pros Cons Scott's Rule Adapts to data distribution, optimal for smooth densities May under-smooth in tails Fixed 10% Simple, predictable Ignores data structure, often suboptimal <p>ArqonHPO defaults to Scott's Rule but supports alternatives via <code>BandwidthRule</code>:</p> <pre><code>TPE::with_bandwidth_rule(dim, BandwidthRule::Scott)    // Default\nTPE::with_bandwidth_rule(dim, BandwidthRule::Silverman)  // Alternative\nTPE::with_bandwidth_rule(dim, BandwidthRule::Fixed(0.1)) // Legacy behavior\n</code></pre>"},{"location":"documentation/cookbook/sim_tuning/","title":"Cookbook: Simulation Tuning","text":"<p>Tune expensive, smooth simulation objectives with Nelder-Mead.</p>"},{"location":"documentation/cookbook/sim_tuning/#scenario","title":"Scenario","text":"<p>You have a CFD or physics simulation that:</p> <ul> <li>Takes minutes to hours per evaluation.</li> <li>Has a smooth landscape (small parameter changes = small output changes).</li> <li>You have a tight evaluation budget (e.g., 50-100 runs).</li> </ul> <p>ArqonHPO will automatically detect this and use Nelder-Mead, which minimizes evaluations.</p>"},{"location":"documentation/cookbook/sim_tuning/#the-pcr-algorithm","title":"The PCR Algorithm","text":"<p>For simulation tuning, ArqonHPO uses the Probe-Classify-Refine (PCR) algorithm:</p> <ol> <li>Probe: It samples the parameter space using a multi-scale prime-index grid.</li> <li>Classify: It analyzes the residuals of the probe phase. Smooth simulations show fast residual decay ($\\alpha &gt; 0.5$).</li> <li>Refine: If structured, it launches Nelder-Mead initialized from the best probe points.</li> </ol> <p>This \"Hybrid Seeding\" allows Nelder-Mead to start exploitation immediately from a high-quality region. This means for CFD simulations with smooth, bowl-shaped objectives, ArqonHPO will: - Detect geometric decay in residuals (fast convergence signature) - Automatically select Nelder-Mead without manual configuration - Use probe results to intelligently initialize the simplex</p>"},{"location":"documentation/cookbook/sim_tuning/#example-cfd-parameter-sweep","title":"Example: CFD Parameter Sweep","text":"<pre><code>import json\nimport time\nfrom arqonhpo import ArqonSolver\n\n# Simulate expensive CFD call\ndef cfd_simulation(params):\n    inlet_velocity = params[\"inlet_velocity\"]\n    turbulence_k = params[\"turbulence_k\"]\n\n    time.sleep(0.5)  # Simulate 30-minute CFD; use 0.5s for demo\n\n    # Fake \"drag coefficient\" as objective\n    drag = (inlet_velocity - 5.0)**2 + (turbulence_k - 0.1)**2\n    return drag\n\n# Config\nconfig = {\n    \"seed\": 123,\n    \"budget\": 30,  # Very tight budget\n    \"probe_ratio\": 0.2,\n    \"bounds\": {\n        \"inlet_velocity\": {\"min\": 1.0, \"max\": 10.0},\n        \"turbulence_k\": {\"min\": 0.01, \"max\": 0.5}\n    }\n}\n\nsolver = ArqonSolver(json.dumps(config))\nbest = {\"value\": float('inf')}\n\nwhile True:\n    batch = solver.ask()\n    if batch is None:\n        break\n\n    results = []\n    for i, params in enumerate(batch):\n        drag = cfd_simulation(params)\n        if drag &lt; best[\"value\"]:\n            best = {\"params\": params, \"value\": drag}\n        results.append({\n            \"eval_id\": i,\n            \"params\": params,\n            \"value\": drag,\n            \"cost\": 30.0  # 30 mins\n        })\n\n    solver.tell(json.dumps(results))\n\nprint(f\"Optimal: {best}\")\n# Optimal: {'params': {'inlet_velocity': 5.02, 'turbulence_k': 0.098}, 'value': 0.0004}\n</code></pre>"},{"location":"documentation/cookbook/sim_tuning/#why-nelder-mead","title":"Why Nelder-Mead?","text":"<p>For smooth landscapes, Nelder-Mead's simplex operations converge faster than random search or TPE because it exploits local gradient information without needing derivatives.</p>"},{"location":"documentation/cookbook/sim_tuning/#nelder-mead-operations","title":"Nelder-Mead Operations","text":"<p>ArqonHPO implements all 5 standard NM operations:</p> Operation When Used Formula Reflection Always tried first x_r = c + \u03b1(c - worst) Expansion Reflection is best so far x_e = c + \u03b3(r - c) Outside Contraction Reflection between 2nd-worst and worst x_c = c + \u03c1(r - c) Inside Contraction Reflection worse than worst x_c = c + \u03c1(worst - c) Shrink Contraction fails x_i = best + \u03c3(x_i - best) <p>Standard coefficients: \u03b1=1.0, \u03b3=2.0, \u03c1=0.5, \u03c3=0.5</p>"},{"location":"documentation/reference/cli/","title":"CLI Reference","text":"<p>ArqonHPO provides a command-line interface for batch optimization.</p> <p>Under Construction</p> <p>The CLI is planned for a future release. For now, use the Python API.</p>"},{"location":"documentation/reference/cli/#planned-usage","title":"Planned Usage","text":"<pre><code>arqonhpo run --config config.json --script ./evaluate.sh\n</code></pre>"},{"location":"documentation/reference/cli/#config-file","title":"Config File","text":"<p><code>config.json</code>:</p> <pre><code>{\n  \"seed\": 42,\n  \"budget\": 100,\n  \"bounds\": {\n    \"x\": {\"min\": -5, \"max\": 5}\n  }\n}\n</code></pre>"},{"location":"documentation/reference/cli/#evaluation-script","title":"Evaluation Script","text":"<p>The CLI will call your script with parameters as environment variables:</p> <pre><code>#!/bin/bash\n# evaluate.sh\necho \"RESULT=$(python my_simulation.py --x=$ARQON_x)\"\n</code></pre>"},{"location":"documentation/reference/python/","title":"Python API Reference","text":"<p>::: arqonhpo</p>"},{"location":"documentation/reference/python/#arqonsolver","title":"ArqonSolver","text":"<p>The main entry point for optimization.</p>"},{"location":"documentation/reference/python/#constructor","title":"Constructor","text":"<pre><code>ArqonSolver(config_json: str) -&gt; ArqonSolver\n</code></pre> <p>Parameters:</p> <ul> <li><code>config_json</code>: JSON string with solver configuration.</li> </ul> <p>Config Schema:</p> Field Type Required Default Description <code>seed</code> int \u2713 - RNG seed for reproducibility <code>budget</code> int \u2713 - Max number of evaluations <code>bounds</code> dict \u2713 - Parameter bounds (see below) <code>probe_ratio</code> float \u2717 0.2 Fraction of budget for probing <code>strategy_params</code> dict \u2717 null Strategy-specific config <p>Bounds Format:</p> <pre><code>{\n  \"param_name\": {\n    \"min\": 0.0,\n    \"max\": 1.0,\n    \"scale\": \"Linear\"  // or \"Log\"\n  }\n}\n</code></pre>"},{"location":"documentation/reference/python/#methods","title":"Methods","text":""},{"location":"documentation/reference/python/#ask-listdict-none","title":"<code>ask() -&gt; list[dict] | None</code>","text":"<p>Returns the next batch of candidate parameters, or <code>None</code> if optimization is complete.</p>"},{"location":"documentation/reference/python/#tellresults_json-str-none","title":"<code>tell(results_json: str) -&gt; None</code>","text":"<p>Report evaluation results back to the solver.</p> <p>Results Schema:</p> <pre><code>[\n  {\n    \"eval_id\": 0,\n    \"params\": {\"x\": 1.0, \"y\": 2.0},\n    \"value\": 0.5,\n    \"cost\": 1.0\n  }\n]\n</code></pre>"},{"location":"documentation/reference/rust/","title":"Rust API Reference","text":"<p>Full API documentation is available via <code>cargo doc</code>.</p> <pre><code>cd ArqonHPO\ncargo doc --open\n</code></pre>"},{"location":"documentation/reference/rust/#quick-reference","title":"Quick Reference","text":""},{"location":"documentation/reference/rust/#arqonhpo_coremachinesolver","title":"<code>arqonhpo_core::machine::Solver</code>","text":"<p>The core state machine with probe-classify-refine pipeline.</p> <pre><code>use arqonhpo_core::machine::Solver;\nuse arqonhpo_core::config::SolverConfig;\n\nlet config: SolverConfig = serde_json::from_str(r#\"...\"#)?;\n\n// MVP mode (VarianceClassifier, UniformProbe)\nlet mut solver = Solver::new(config.clone());\n\n// PCR Production mode (ResidualDecayClassifier, PrimeIndexProbe, Top-K seeding)\nlet mut solver = Solver::pcr(config);\n\nloop {\n    match solver.ask() {\n        Some(candidates) =&gt; {\n            // Evaluate candidates...\n            solver.tell(results);\n        }\n        None =&gt; break,\n    }\n}\n</code></pre>"},{"location":"documentation/reference/rust/#solverpcr-probe-classify-refine","title":"<code>Solver::pcr()</code> (\"Probe-Classify-Refine\")","text":"<p>The standard ArqonHPO V2 strategy pipeline.</p> <ol> <li>Probe: <code>PrimeIndexProbe</code> scans the landscape.</li> <li>Classify: <code>ResidualDecayClassifier</code> measures structural decay ($\\alpha$).</li> <li>Refine:<ul> <li>$\\alpha &gt; 0.5$ (Structured) $\\rightarrow$ <code>NelderMead</code> (seeded with best Probe points)</li> <li>$\\alpha \\le 0.5$ (Chaotic) $\\rightarrow$ <code>TPE</code> (seeded with all Probe history)</li> </ul> </li> </ol> <pre><code>use arqonhpo::Solver;\n\nlet config = SolverConfig::default();\nlet solver = Solver::pcr(config); // Standard production solver\n</code></pre>"},{"location":"documentation/reference/rust/#arqonhpo_coreclassifyresidualdecayclassifier","title":"<code>arqonhpo_core::classify::ResidualDecayClassifier</code>","text":"<p>PCR algorithm classifier using \u03b1 estimation from residual decay curves.</p> <pre><code>use arqonhpo_core::classify::{ResidualDecayClassifier, Classify, Landscape};\n\nlet classifier = ResidualDecayClassifier::default(); // \u03b1_threshold = 0.5\n\nlet (landscape, alpha) = classifier.classify(&amp;history);\n// \u03b1 &gt; 0.5 \u2192 Structured (use Nelder-Mead)\n// \u03b1 \u2264 0.5 \u2192 Chaotic (use TPE)\n</code></pre>"},{"location":"documentation/reference/rust/#arqonhpo_coreprobeprimeindexprobe","title":"<code>arqonhpo_core::probe::PrimeIndexProbe</code>","text":"<p>Multi-scale sampling using prime ratios for better structure detection.</p> <pre><code>use arqonhpo_core::probe::{PrimeIndexProbe, Probe};\n\nlet probe = PrimeIndexProbe::default();\nlet candidates = probe.sample(&amp;config);\n</code></pre>"},{"location":"documentation/reference/rust/#arqonhpo_corestrategiestpebandwidthrule","title":"<code>arqonhpo_core::strategies::tpe::BandwidthRule</code>","text":"<p>Adaptive bandwidth calculation for TPE kernel density estimation.</p> <pre><code>use arqonhpo_core::strategies::tpe::{TPE, BandwidthRule};\n\nlet tpe = TPE::with_bandwidth_rule(dim, BandwidthRule::Scott);\n// Scott's Rule: \u03c3 = 1.06 \u00d7 stddev \u00d7 n^(-1/5)\n</code></pre>"},{"location":"documentation/reference/rust/#arqonhpo_coreconfigsolverconfig","title":"<code>arqonhpo_core::config::SolverConfig</code>","text":"<pre><code>pub struct SolverConfig {\n    pub seed: u64,\n    pub budget: u64,\n    pub bounds: HashMap&lt;String, Domain&gt;,\n    pub probe_ratio: f64,\n    pub strategy_params: Option&lt;HashMap&lt;String, f64&gt;&gt;,\n}\n</code></pre>"},{"location":"documentation/reference/rust/#arqonhpo_coreartifactevaltrace","title":"<code>arqonhpo_core::artifact::EvalTrace</code>","text":"<pre><code>pub struct EvalTrace {\n    pub eval_id: u64,\n    pub params: HashMap&lt;String, f64&gt;,\n    pub value: f64,\n    pub cost: f64,\n}\n</code></pre>"},{"location":"project/CODE_OF_CONDUCT/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"project/CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone.</p>"},{"location":"project/CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment:</p> <ul> <li>Being respectful of differing viewpoints</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards others</li> </ul> <p>Examples of unacceptable behavior:</p> <ul> <li>Trolling, insulting or derogatory comments</li> <li>Public or private harassment</li> <li>Publishing others' private information without permission</li> <li>Other conduct which could reasonably be considered inappropriate</li> </ul>"},{"location":"project/CODE_OF_CONDUCT/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders at conduct@arqon.dev.</p>"},{"location":"project/CODE_OF_CONDUCT/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.1.</p>"},{"location":"project/CONTRIBUTING/","title":"Contributing to ArqonHPO","text":"<p>Thank you for your interest in contributing! \ud83c\udf89</p>"},{"location":"project/CONTRIBUTING/#quick-start","title":"Quick Start","text":"<pre><code>git clone https://github.com/arqon/ArqonHPO.git\ncd ArqonHPO\njust build\njust test\n</code></pre>"},{"location":"project/CONTRIBUTING/#development-workflow","title":"Development Workflow","text":"<ol> <li>Fork &amp; Clone the repository.</li> <li>Create a branch: <code>git checkout -b feature/my-feature</code></li> <li>Make changes and add tests.</li> <li>Run checks: <code>just check &amp;&amp; just test</code></li> <li>Submit a PR.</li> </ol>"},{"location":"project/CONTRIBUTING/#code-style","title":"Code Style","text":"<ul> <li>Rust: <code>rustfmt</code> + <code>clippy</code> (warnings = errors).</li> <li>Python: <code>ruff</code> + <code>mypy</code>.</li> </ul>"},{"location":"project/CONTRIBUTING/#commit-messages","title":"Commit Messages","text":"<p>Follow Conventional Commits:</p> <pre><code>feat(core): add support for custom strategies\nfix(bindings): handle empty history edge case\ndocs(cookbook): add PyTorch recipe\n</code></pre>"},{"location":"project/CONTRIBUTING/#questions","title":"Questions?","text":"<p>Open a Discussion or ask in the PR.</p>"},{"location":"project/SECURITY/","title":"Security Policy","text":""},{"location":"project/SECURITY/#supported-versions","title":"Supported Versions","text":"Version Supported 0.1.x"},{"location":"project/SECURITY/#reporting-a-vulnerability","title":"Reporting a Vulnerability","text":"<p>Do NOT open a public issue for security vulnerabilities.</p> <p>Email: security@arqon.dev</p> <p>We aim to respond within 48 hours and will work with you to understand and address the issue.</p>"},{"location":"project/SECURITY/#security-practices","title":"Security Practices","text":"<ul> <li>SLSA Level 3: Build provenance for all releases.</li> <li>SBOM: CycloneDX Software Bill of Materials for each release.</li> <li>Fuzzing: Continuous fuzzing of config parsing via <code>cargo-fuzz</code>.</li> <li>Dependency Auditing: <code>cargo audit</code> in CI.</li> </ul>"},{"location":"project/about/","title":"About ArqonHPO","text":"<p>ArqonHPO is developed by NovelByte Labs.</p>"},{"location":"project/about/#the-philosophy","title":"The Philosophy","text":"<p>We believe that optimization is infrastructure. It should be as reliable as a database and as fast as a cache lookup.</p> <p>We reject the status quo of \"pip install, run for 3 days, hope for the best.\"</p>"},{"location":"project/about/#the-constitution","title":"The Constitution","text":"<p>This project operates under a strict Constitution that mandates:</p> <ol> <li>No Happy Path Testing</li> <li>No Silent Failures</li> <li>Zero Unbounded Growth</li> </ol> <p>Values are enforced by CI, not just written in docs.</p>"},{"location":"project/changelog/","title":"Changelog","text":"<p>All notable changes to ArqonHPO will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"project/changelog/#unreleased","title":"[Unreleased]","text":""},{"location":"project/changelog/#added","title":"Added","text":"<ul> <li> <p><code>with_seed_points()</code> constructor for probe-based initialization</p> </li> <li> <p>Scott's Rule TPE Bandwidth - Adaptive kernel bandwidth:</p> </li> <li><code>BandwidthRule</code> enum: Scott, Silverman, Fixed</li> <li>Scott's Rule: \u03c3 = 1.06 \u00d7 stddev \u00d7 n^(-1/5)</li> <li><code>TPE::with_bandwidth_rule()</code> constructor</li> </ul>"},{"location":"project/changelog/#changed","title":"Changed","text":"<ul> <li><code>Solver::new()</code> now uses <code>SeedingConfig::default()</code> for probe-to-refiner seeding</li> <li>Replaced fixed 10% bandwidth in TPE with adaptive Scott's Rule</li> </ul>"},{"location":"project/changelog/#documentation","title":"Documentation","text":"<ul> <li>Updated <code>docs/docs/reference/rust.md</code> with new API documentation</li> <li>Updated <code>docs/docs/cookbook/sim_tuning.md</code> with PCR algorithm explanation</li> <li>Updated <code>docs/docs/cookbook/ml_tuning.md</code> with Scott's Rule bandwidth details</li> </ul>"},{"location":"project/changelog/#tests","title":"Tests","text":"<ul> <li>36 Rust unit tests for all PCR components</li> <li>3 Python integration tests (test_integration, test_us1, test_us2)</li> </ul>"},{"location":"project/constitution/","title":"Constitution","text":""},{"location":"project/constitution/#arqonhpo-constitution","title":"ArqonHPO Constitution","text":"<p>Version: 1.4.1 Ratification Date: 2025-12-13 Last Amended: 2025-12-17  </p> <p>This document defines the non-negotiable principles that govern how ArqonHPO is designed, evolved, and maintained.</p> <p>It exists to protect ArqonHPO from accidental bloat, regression, silent breakage, and \u201cclever\u201d shortcuts that erode trust.</p> <p>If a decision conflicts with this constitution, the decision is wrong.</p> <p>Spec Kit Note: This constitution is the hard sandbox for all <code>/speckit.*</code> commands. Specs, plans, and tasks must not violate the constraints in Sections II\u2013XI.</p>"},{"location":"project/constitution/#ultimate-integrity-covenant","title":"ULTIMATE INTEGRITY COVENANT","text":"<p>This constitution is a hard constraint on all engineering work. It exists to prevent the failure modes that destroy real systems:</p> <ul> <li>\u201cHappy path\u201d engineering that collapses under real inputs</li> <li>Pseudocode / placeholders / stubs presented as completion</li> <li>Tests that \u201ccheck boxes\u201d but don\u2019t model production reality</li> <li>Fake evidence (invented logs, benchmarks, screenshots, coverage, results)</li> <li>Unnamed technical debt that silently becomes permanent</li> <li>Silent failure handling and silent security degradation</li> <li>Undocumented complexity and unreadable \u201cclever\u201d code</li> <li>Non-reproducible builds, non-deterministic behavior, and flaky verification</li> <li>Work products that are narrative-only, vague, or unverifiable</li> </ul> <p>If a decision conflicts with this covenant, the decision is wrong.</p>"},{"location":"project/constitution/#a-the-only-acceptable-meaning-of-done-the-8-pillar-standard","title":"A. The Only Acceptable Meaning of \u201cDONE\u201d (The 8-Pillar Standard)","text":"<p>A change is NOT DONE until all eight pillars are true:</p> <ol> <li>Implementation  </li> <li>Real code exists (not pseudocode). It compiles, runs, and handles edge cases.  </li> <li>Invalid states are rejected; invariants are enforced.  </li> <li> <p>Failure behavior is explicit: timeouts, retries, backpressure, cancellation, and partial failures are defined.</p> </li> <li> <p>Verification  </p> </li> <li>Automated tests cover normal + failure + adversarial + concurrency/ordering behavior.  </li> <li>Tests model production complexity, not toy inputs.  </li> <li> <p>Where appropriate: property-based tests, fuzzing, chaos/fault injection, and regression tests exist.</p> </li> <li> <p>Documentation  </p> </li> <li>In-repo docs explain: architecture, usage, invariants, data contracts, and \u201cwhat can go wrong.\u201d  </li> <li>Operational caveats are explicit: limits, failure modes, rollback strategy, and safety constraints.  </li> <li> <p>Every public behavior change updates docs and/or changelog.</p> </li> <li> <p>Evidence  </p> </li> <li>Reproducible proof exists (CI artifacts, logs, traces, coverage reports, benchmarks).  </li> <li>Evidence is not implied; it is attached or linkable to a specific commit/run.  </li> <li> <p>If there is no evidence, the claim is false.</p> </li> <li> <p>Traceability  </p> </li> <li>Each requirement / acceptance criterion maps to:<ul> <li>code locations,</li> <li>test locations,</li> <li>documentation locations,</li> <li>evidence artifacts.</li> </ul> </li> <li> <p>No orphan requirements. No orphan code. No untested requirements.</p> </li> <li> <p>Operational Readiness  </p> </li> <li>Safe defaults, explicit configuration validation, and clear failure signals exist.  </li> <li>Observability exists: structured logs + metrics + tracing (or an equivalent breadcrumb system).  </li> <li> <p>Rollout/rollback exists where relevant; migrations are reversible or explicitly irreversible.</p> </li> <li> <p>Security &amp; Safety Readiness  </p> </li> <li>Threat assumptions are stated. Privilege boundaries are validated.  </li> <li>Secrets are not logged; sensitive data is redacted.  </li> <li> <p>Fail-closed behavior is defined for safety/security modules (no silent \u201callow\u201d).</p> </li> <li> <p>Task Completeness  </p> </li> <li>Work is decomposed into a concrete task list (not vague bullets).  </li> <li>Each task includes acceptance criteria, a test hook, and an evidence hook.  </li> <li>If a task is not done, the work is not done.</li> </ol> <p>Rule: Declaring \u201cdone\u201d without satisfying every pillar is deception.</p>"},{"location":"project/constitution/#b-the-anti-half-ass-rules-merge-blocking-by-definition","title":"B. The Anti-Half-Ass Rules (Merge-Blocking by Definition)","text":""},{"location":"project/constitution/#b1-no-pseudocode-as-deliverable","title":"B1. No Pseudocode-as-Deliverable","text":"<ul> <li>Pseudocode may exist only as clearly labeled design notes.  </li> <li>Pseudocode cannot be the \u201csolution,\u201d cannot substitute for tests, and cannot be used to claim completion.</li> </ul>"},{"location":"project/constitution/#b2-no-placeholders-no-stubs-no-later","title":"B2. No Placeholders / No Stubs / No \u201cLater\u201d","text":"<p>Forbidden in production paths: - <code>TODO</code>, <code>FIXME</code>, <code>pass</code>, <code>todo!()</code>, empty handlers, commented-out behavior, \u201cmock later,\u201d \u201chardening later,\u201d \u201cedge cases later.\u201d If incomplete behavior must exist temporarily, it must: - be feature-flagged OFF by default, - be isolated so it cannot affect production behavior, - have a <code>TD-###</code> record with TTL (see Debt Policy).</p>"},{"location":"project/constitution/#b3-no-fake-data-no-toy-inputs-no-lazy-synthetics","title":"B3. No Fake Data, No Toy Inputs, No Lazy Synthetics","text":"<ul> <li>Tests and examples must use production-like complexity: realistic IDs, nested payloads, boundary sizes, malformed variants, weird unicode/whitespace, and adversarial inputs.</li> <li>Ban list (unless the test is explicitly about these literals): <code>foo</code>, <code>bar</code>, <code>user_1</code>, <code>test123</code>, \u201chello world.\u201d</li> </ul>"},{"location":"project/constitution/#b4-no-happy-path-testing","title":"B4. No Happy Path Testing","text":"<p>For any externally coupled feature (filesystem, subprocesses, network, storage, package backends), tests must cover: - timeouts, retries, partial failures, malformed responses, permission failures, cancellation, overload/backpressure, and out-of-order/duplicate events where relevant.</p>"},{"location":"project/constitution/#b5-no-silent-failures","title":"B5. No Silent Failures","text":"<ul> <li>Swallowing errors is forbidden. Every error must be handled, logged with context, or propagated.</li> <li>\u201cFallback to success\u201d behavior without explicit documentation and tests is forbidden.</li> </ul>"},{"location":"project/constitution/#b6-warnings-are-errors","title":"B6. Warnings Are Errors","text":"<ul> <li>Compiler, linter, formatter, typechecker warnings block merge. \u201cIt builds on my machine\u201d is irrelevant.</li> </ul>"},{"location":"project/constitution/#b7-no-unbounded-risk","title":"B7. No Unbounded Risk","text":"<ul> <li>Unbounded queues, unbounded memory growth, unbounded metric cardinality, unbounded retries, and unbounded timeouts are forbidden.</li> <li>If something can grow, it must have a cap. If it can retry, it must have a budget. If it can wait, it must have a timeout.</li> </ul>"},{"location":"project/constitution/#c-technical-debt-policy-zero-debt-unless-named-owned-expiring","title":"C. Technical Debt Policy (Zero Debt Unless Named + Owned + Expiring)","text":"<p>Technical debt is forbidden by default. If debt must exist, it must be explicit, bounded, and temporary.</p> <p>Debt is valid only if it is recorded as <code>TD-###</code> and includes: - owner, - scope and blast radius, - why it exists, - the exact exit criteria (\u201cdebt is removed when\u2026\u201d), - remediation plan, - hard TTL date, - tests guarding the boundary so the debt cannot silently expand.</p> <p>Rules: - Debt without TTL is invalid. - Debt past TTL blocks merge/release. - \u201cWe\u2019ll fix later\u201d is not a plan. - \u201cTemporary\u201d code paths must have an explicit sunset mechanism.</p>"},{"location":"project/constitution/#d-sdd-tdd-contract-professional-standard","title":"D. SDD + TDD Contract (Professional Standard)","text":""},{"location":"project/constitution/#d1-specification-driven-design-requirements-for-non-trivial-changes","title":"D1. Specification-Driven Design Requirements (for non-trivial changes)","text":"<p>A valid spec includes: - intent and non-goals, - acceptance criteria (falsifiable), - invariants (must-always-be-true), - failure modes and expected behavior under each, - compatibility rules (protocol/API/schema expectations), - performance envelope and resource bounds (when relevant), - security/privacy assumptions and constraints, - operational concerns (observability, rollout/rollback, migration notes).</p> <p>If the spec is ambiguous, the first task is to remove ambiguity by producing falsifiable criteria.</p>"},{"location":"project/constitution/#d2-test-driven-development-requirements","title":"D2. Test-Driven Development Requirements","text":"<ul> <li>Tests define behavior before/with implementation (TDD by default).</li> <li>Refactors require existing tests protecting behavior.</li> <li>Every bug fix includes a regression test that fails pre-fix and passes post-fix.</li> <li>Flaky tests are critical bugs; they must be fixed, not ignored.</li> </ul>"},{"location":"project/constitution/#e-verification-constitution-realism-adversarial-failure-first","title":"E. Verification Constitution (Realism + Adversarial + Failure-First)","text":"<p>Required test categories (as applicable): - unit tests for pure logic (fast, no external deps), - integration tests for boundaries and real dependency interactions, - property-based tests for parsers/validators/protocol/config boundaries, - fuzz tests for user-controlled input surfaces, - concurrency/ordering tests for races, duplicates, replays, idempotency, - chaos/fault injection for externally coupled behaviors, - performance regression checks for hot paths or stated latency budgets.</p> <p>Verification must explicitly test: - malformed inputs, - partial reads/writes, - timeout handling, - retry policy and idempotency guarantees, - permission boundaries, - overload/backpressure behavior, - deterministic ordering assumptions (or explicit non-guarantees).</p>"},{"location":"project/constitution/#f-the-claim-ledger-mandatory-honesty","title":"F. The Claim Ledger (Mandatory Honesty)","text":"<p>Any claim like \u201cworks,\u201d \u201cdone,\u201d \u201cfixed,\u201d \u201csecure,\u201d \u201cfast,\u201d \u201ccompatible,\u201d \u201cproduction-ready\u201d must be labeled:</p> <ul> <li>Observed: executed + evidence attached</li> <li>Derived: reasoned + assumptions listed + risks stated</li> <li>Unverified: not tested + the exact minimal experiment provided</li> </ul> <p>Presenting Derived/Unverified claims as Observed is lying.</p>"},{"location":"project/constitution/#g-minimum-acceptable-deliverable-non-negotiable-output-shape","title":"G. Minimum Acceptable Deliverable (Non-Negotiable Output Shape)","text":"<p>Any non-trivial work product must include all of: - a concrete task list with acceptance criteria per task, - a file-level plan (what files change/add/remove), - implementation code, - tests (including failure/adversarial coverage where relevant), - documentation updates, - an Evidence Pack (defined in the footer).</p> <p>If any part is incomplete, it must be explicitly labeled Unverified and paired with the shortest experiment that would verify it.</p>"},{"location":"project/constitution/#h-default-principles","title":"H. Default Principles","text":"<p>If a situation, decision, or design choice is not explicitly covered by this Constitution, the default principle is to: - Adopt the most stringent, resilient, and transparent posture. - Enforce the primacy of operational integrity, unambiguous intent, and disciplined scaling. - Treat unresolved ambiguity as a Constitutional void, demanding immediate and formal amendment.</p>"},{"location":"project/constitution/#i-vision-and-scope","title":"I. Vision and Scope","text":""},{"location":"project/constitution/#1-the-vision","title":"1. The Vision","text":"<p>ArqonHPO is a probe-gated optimization engine for time-to-target\u2014and a runtime control primitive for microsecond-latency adaptation.</p> <p>It is built to be clearly competitive for two product-aligned use cases:</p> <ol> <li>Fast simulation tuning: expensive evaluations (milliseconds to seconds) where reaching a useful threshold quickly matters.</li> <li>Sklearn-style model tuning: moderate-cost evaluations where optimizer overhead is material and \"good-enough quickly\" often wins.</li> </ol> <p>Control Primitive Posture: Once the decision loop operates at microseconds, optimization is treated as a feedback control primitive. The system's job is to steer toward homeostasis under changing conditions (drift, load, hardware throttling) using bounded changes. This is achieved through:</p> <ul> <li>Discovery Offline, Adaptation Online: Offline discovery (Tier \u03a9) generates and evaluates candidates; online adaptation (Tier 2) selects among approved variants and proposes bounded deltas.</li> <li>Law Control: Online tuning of \"physics knobs\" (diffusion, noise, decay, damping, constraint weights) within allowlisted parameters and strict safety envelopes.</li> <li>Microsecond Latency: ArqonHPO is designed for 1\u201310ms decision latency, enabling embedding in live control loops without blocking the dataplane.</li> </ul>"},{"location":"project/constitution/#2-the-scope","title":"2. The Scope","text":"<p>To achieve this vision, we must be ruthless about what ArqonHPO is and what it is not.</p>"},{"location":"project/constitution/#21-in-scope-the-core-product","title":"2.1 In Scope (The Core Product)","text":"<p>ArqonHPO is probe-gated optimization and runtime adaptation. It is responsible for:</p> <ul> <li>The Probe Phase: Deterministic sampling to gather an initial signal and candidates.</li> <li>The Classification Phase: A fixed-size test that labels the landscape (e.g., structured vs chaotic) and produces a score.</li> <li>The Mode Selection Phase: Selecting a refinement strategy based on the classification result.</li> <li>The Refinement Phase: Executing the chosen optimizer within the remaining budget.</li> <li>Audit Artifacts: Schema-versioned run artifacts sufficient for replay and accountability.</li> <li>Systems/Infrastructure Knobs: Tuning database parameters, connection pools, cache sizes, and runtime configurations in bounded, safe, auditable ways.</li> <li>Runtime Law Tuning: Adjusting simulation/physics parameters (e.g., diffusion rates, constraint weights) within safety envelopes during online operation.</li> </ul>"},{"location":"project/constitution/#22-out-of-scope-the-boundaries","title":"2.2 Out of Scope (The Boundaries)","text":"<p>ArqonHPO is not:</p> <ul> <li>A general-purpose ML training framework. It tunes; it does not train end-to-end pipelines.</li> <li>A distributed execution platform. It may integrate with external evaluators, but it does not provide a cluster runtime.</li> <li>A \u201cguaranteed best on all objectives\u201d optimizer. Claims must be scoped to the benchmark suite and use cases.</li> </ul>"},{"location":"project/constitution/#3-the-strategic-horizon","title":"3. The Strategic Horizon","text":"<p>We define evolution in three distinct epochs. Engineering decisions must align with the current epoch while reserving capacity for the next.</p> <ul> <li>Epoch 1: The Foundation (Deterministic probe-gated core).<ul> <li>Focus: determinism, bounded overhead, artifact auditability, and time-to-target benchmarking.</li> <li>Goal: be measurably competitive on the two target use cases.</li> </ul> </li> <li>Epoch 2: The Platform (Composable strategies).<ul> <li>Focus: pluggable backends, richer classification signals, replay tooling.</li> <li>Goal: support multiple strategies without breaking contracts.</li> </ul> </li> <li>Epoch 3: The Research Frontier (Optional).<ul> <li>Focus: experimental samplers, meta-controllers, and novel structural probes.</li> <li>Goal: enable experimentation without contaminating production defaults.</li> </ul> </li> </ul>"},{"location":"project/constitution/#ii-core-principles","title":"II. Core Principles","text":"<p>This section defines the engineering laws that govern ArqonHPO. These are not guidelines; they are constraints. Code that violates these principles will be rejected during Review.</p>"},{"location":"project/constitution/#1-architectural-invariance-the-gate-pattern","title":"1. Architectural Invariance (The Gate Pattern)","text":"<p>The system is composed of four non-negotiable phases. Strict adherence to the probe-gated pipeline is required to prevent coupling and ensure reproducibility.</p> <p>The Phases:</p> <ul> <li>Probe: deterministic sampling; gathers initial candidates and signal.</li> <li>Classify: fixed-size classification; emits score + label.</li> <li>Select: chooses refinement mode based on classification.</li> <li>Refine: executes the chosen optimizer within the remaining budget.</li> </ul> <p>The Bypass Ban:</p> <p>No phase may be skipped because it is \u201cconvenient.\u201d</p> <ul> <li>Forbidden: Selecting a refinement mode without running classification.</li> <li>Forbidden: Adding hidden objective calls that do not count against budget.</li> <li>Forbidden: Silent fallbacks that change mode/behavior without artifacts and tests.</li> </ul>"},{"location":"project/constitution/#2-statelessness-state-explicit-ness","title":"2. Statelessness &amp; State Explicit-ness","text":"<p>To ensure runs can be reproduced and audited, we adhere to a Stateless Where Possible philosophy.</p> <ul> <li>Run Ephemerality: Any process must be able to crash and restart without corrupting an ongoing run artifact.</li> <li>State Explicitness: All non-trivial solver state must be explicit, serializable, and captured in artifacts if it affects decisions.</li> <li>Seed Sovereignty: All randomness must come from explicit seeds; hidden global RNG use is forbidden.</li> </ul>"},{"location":"project/constitution/#3-contract-sovereignty-typed-inputs-versioned-artifacts","title":"3. Contract Sovereignty (Typed Inputs, Versioned Artifacts)","text":"<p>We enforce a strict separation between machine-stable contracts and human-readable debugging.</p> <p>Typed Contracts:</p> <p>Configuration and run inputs must be expressed in typed structures. The config contract is the single source of truth for defaults and validation.</p> <p>Artifact Reservations:</p> <p>Artifacts are schema-versioned and must be stable and replayable. Logs are diagnostics and must not be required for replay.</p>"},{"location":"project/constitution/#4-future-proofing-hooks-the-moonshot-mandate","title":"4. Future-Proofing Hooks (The Moonshot Mandate)","text":"<p>To enable future experimentation without requiring a rewrite, v1.0 must reserve capacity for:</p> <ul> <li>Backend Hook: Ability to select a refinement backend via a stable interface.</li> <li>Classifier Hook: Ability to extend classification signals while preserving the fixed-size gating contract.</li> <li>Objective Guard Hook: Ability to wrap objectives for timeouts/redaction without changing the solver core.</li> <li>Replay Hook: Ability to replay decisions from artifacts.</li> </ul>"},{"location":"project/constitution/#5-semantic-versioning-compatibility","title":"5. Semantic Versioning &amp; Compatibility","text":"<p>We adhere to strict Semantic Versioning regarding the Public API and Artifact Schemas.</p> <p>Versioning Rules:</p> <ul> <li>MAJOR: Breaking changes to solver public API, artifact schema, or core behavior.</li> <li>MINOR: New modes, additive fields (optional), new telemetry, or non-breaking enhancements.</li> <li>PATCH: Bug fixes, performance improvements, and clarifications.</li> </ul> <p>Stealth Ban:</p> <p>There shall be no \"stealth\" breaking changes in MINOR or PATCH versions. Ever.</p>"},{"location":"project/constitution/#6-data-isolation-privacy-the-bulkhead","title":"6. Data Isolation &amp; Privacy (The Bulkhead)","text":"<p>Optimization objectives may embed sensitive information.</p> <ul> <li>Isolation: Objective payloads are treated as sensitive by default.</li> <li>Redaction: Logs/artifacts must not leak secrets or tenant data.</li> <li>Sharing Safety: Artifacts intended for sharing must support redaction without breaking replayability guarantees.</li> </ul>"},{"location":"project/constitution/#7-security-by-design","title":"7. Security by Design","text":"<p>Security is a baseline constraint, not a feature.</p> <ul> <li>Zero Trust: The solver does not trust the objective; it validates inputs and guards execution.</li> <li>Fail Closed: If a safety/guard module fails, times out, or crashes, the run is failed explicitly. It is never \"allowed by default.\"</li> <li>Secure Defaults: Unsafe execution modes must be opt-in and auditable.</li> </ul>"},{"location":"project/constitution/#8-programmable-safety-guards","title":"8. Programmable Safety (Guards)","text":"<p>We reject hardcoded, silent safety logic. Safety requirements vary by environment.</p> <ul> <li>Guard Middleware: Objective guards (timeouts, resource caps, redaction) must be composable.</li> <li>Fail Closed Mandate: If a guard times out, crashes, or returns an error, execution is blocked and surfaced.</li> <li>Bounded Execution: All guards must have strict, non-negotiable limits.</li> </ul>"},{"location":"project/constitution/#9-run-as-artifact-the-capsule-principle","title":"9. Run-as-Artifact (The Capsule Principle)","text":"<p>Runs are not just ephemeral computations. They must produce replayable artifacts.</p> <ul> <li>Digital DNA: The system is optimized to transport the potential (seed + config + bounds + decisions), not just the result.</li> <li>Replayability: A run can be reconstructed from the artifact plus the objective.</li> </ul>"},{"location":"project/constitution/#10-delta-first-evidence","title":"10. Delta-First Evidence","text":"<p>Computation cost and audit burden scale with change ($\\Delta$).</p> <ul> <li>Diff over Snapshot: Prefer per-eval traces and incremental evidence over opaque summaries.</li> <li>Causal Integrity: Decisions and their inputs must be recorded in order.</li> </ul>"},{"location":"project/constitution/#11-circuit-first-benchmarking","title":"11. Circuit-First Benchmarking","text":"<p>Benchmarks are declarative.</p> <ul> <li>Bench Suites are Circuits: Benchmark suites define objectives, budgets, targets, and seed suites as configuration.</li> <li>Decoupled Objectives: Objectives remain oblivious to optimizer internals.</li> </ul>"},{"location":"project/constitution/#12-probe-algorithm-specification","title":"12. Probe Algorithm Specification","text":"<p>Production probes MUST use mathematically validated low-discrepancy sequences.</p> <ul> <li>Default Algorithm: Kronecker/Weyl sequences with irrational slopes derived from prime square roots (e.g., <code>PrimeSqrtSlopesRotProbe</code>).</li> <li>Banned Patterns: The <code>p/1000</code> heuristic and rational-slope sequences are forbidden due to collision and striping artifacts.</li> <li>Anytime Property: Probe quality of first K samples MUST NOT depend on total N.</li> <li>Randomization: Cranley-Patterson (CP) shifts are the approved QMC randomization mechanism. Global RNG injection into base sequences is forbidden.</li> <li>Robustness Hedge: A configurable <code>random_spice_ratio</code> (default 10%) of uniform random points hedges against multimodal fragility.</li> </ul>"},{"location":"project/constitution/#13-dimension-type-contract","title":"13. Dimension Type Contract","text":"<p>Optimization geometry must respect dimension semantics.</p> Scale Arithmetic Contract Linear Euclidean Standard distance, mean Log Log-space Euclidean Transform \u2192 operate \u2192 inverse Periodic Circular/Toroidal <code>wrap01</code>, <code>diff01</code>, <code>circular_mean01</code> <ul> <li>NM on Periodic: Reflection, expansion, and contraction operations MUST use circular arithmetic (wrap at bounds).</li> <li>Probe on Periodic: Samples MUST respect toroidal topology (no edge bias).</li> <li>Canonical Helpers: <code>wrap01(x)</code>, <code>diff01(a,b)</code>, <code>circular_mean01(values)</code> are the canonical implementations.</li> </ul>"},{"location":"project/constitution/#14-multi-start-strategy-contract","title":"14. Multi-Start Strategy Contract","text":"<p>Refinement strategies may use parallel starts for diversity.</p> <ul> <li>K-Parallel Starts: Multi-start strategies run K independent NM instances from diverse seed points.</li> <li>Diversity Seeding: Farthest-point selection from top-K\u00d7(dim+1) pool. Clustered seeding is forbidden.</li> <li>Triage Budget: Each start gets a bounded triage budget before commitment decisions.</li> <li>Stall Detection: Stall threshold triggers start rotation; unbounded stalling is forbidden.</li> </ul>"},{"location":"project/constitution/#15-parallel-sharding-contract","title":"15. Parallel Sharding Contract","text":"<p>Probes must support stateless parallel execution.</p> <ul> <li>Stateless Sharding: A probe MUST produce identical samples for (seed, index) regardless of worker count.</li> <li>Collision-Free: Disjoint index ranges MUST produce disjoint samples.</li> <li>SDK Parity: <code>ArqonProbe</code> (Python) MUST expose identical behavior to Rust core.</li> <li>Verification: Bitwise hash of sorted sample coordinates MUST match single-worker vs multi-worker configurations.</li> </ul>"},{"location":"project/constitution/#16-adaptive-engine-specification","title":"16. Adaptive Engine Specification","text":"<p>Online parameter adaptation MUST use validated optimization algorithms with mandatory safety layers.</p> Aspect Requirement Default Algorithm SPSA (Simultaneous Perturbation Stochastic Approximation) \u2014 2 evaluations per gradient estimate, regardless of dimension Banned Patterns Finite-difference gradients (O(n) evals), unbounded learning rates, global step sizes without decay Decay Schedule <code>a_k = a\u2080/(k+1+A)^\u03b1</code> and <code>c_k = c\u2080/(k+1)^\u03b3</code> with standard exponents (\u03b1=0.602, \u03b3=0.101) Perturbation \u00b11 Bernoulli (symmetric) ONLY; Gaussian perturbations are forbidden due to heavy tails Determinism Same (seed, iteration) MUST produce identical perturbation vectors State Machine Ready \u2192 WaitingPlus \u2192 WaitingMinus \u2192 Ready (strict 2-eval cycle) <ul> <li>Canonical Implementation: <code>Spsa</code> struct with <code>ChaCha8Rng</code> for deterministic perturbations.</li> <li>Budget Enforcement: Each adaptation cycle MUST complete within <code>budget_us</code> microseconds.</li> </ul>"},{"location":"project/constitution/#17-safety-executor-contract","title":"17. Safety Executor Contract","text":"<p>All configuration updates MUST pass through <code>SafetyExecutor</code>. Direct writes to live config are forbidden.</p> Guardrail Default Contract <code>max_delta_per_step</code> 0.1 (10%) Absolute parameter change cap per update <code>max_updates_per_second</code> 10.0 Rate limit for stability <code>min_interval_us</code> 100,000 (100ms) Minimum cooldown between updates <p>Violation Types (MUST block, not just log):</p> Violation Trigger <code>DeltaTooLarge</code> Change exceeds <code>max_delta_per_step</code> <code>RateLimitExceeded</code> Updates exceed <code>max_updates_per_second</code> <code>OutOfBounds</code> Proposed value outside domain bounds <code>UnknownParameter</code> Parameter not in allowlist (allowlist pattern mandatory) <ul> <li>Rollback Requirement: Every config swap MUST preserve a baseline for rollback. Rollback-free execution is forbidden.</li> <li>Fail Closed: If <code>validate_delta()</code> returns <code>Err(Violation)</code>, the update is rejected entirely\u2014partial application is forbidden.</li> </ul>"},{"location":"project/constitution/#18-atomic-configuration-contract","title":"18. Atomic Configuration Contract","text":"<p>Configuration swaps MUST be atomic with no torn reads in the control loop.</p> Requirement Implementation Atomicity Arc-swap semantics with RwLock or true atomic primitives Generation Counter Monotonically increasing <code>u64</code>, observable by readers Zero-Allocation Hot Path <code>snapshot()</code> MUST NOT allocate (cheap Arc clone only) No Mutex Contention Writers MUST NOT block readers in steady state <ul> <li>Canonical Types: <code>AtomicConfig</code> (container) and <code>ConfigSnapshot</code> (immutable view with params + generation).</li> <li>Thread Safety: All methods on <code>AtomicConfig</code> MUST be <code>Send + Sync</code>.</li> </ul>"},{"location":"project/constitution/#19-telemetry-digest-contract","title":"19. Telemetry Digest Contract","text":"<p>Streaming telemetry MUST be compact, fixed-schema, and lock-free in the push path.</p> Field Type Required <code>timestamp_us</code> u64 \u2713 <code>objective_value</code> f64 \u2713 <code>latency_p99_us</code> Option \u2014 <code>throughput_rps</code> Option \u2014 <code>error_rate</code> Option \u2014 <code>constraint_margin</code> Option \u2014 <ul> <li>Ring Buffer: Fixed-capacity <code>TelemetryRingBuffer</code>, overflow evicts oldest. No dynamic allocation in <code>push()</code>.</li> <li>Size Budget: <code>TelemetryDigest</code> MUST fit in \u2264128 bytes for cache efficiency.</li> <li>Minimal Helpers: <code>TelemetryDigest::objective(value)</code> and <code>TelemetryDigest::with_timestamp(ts, value)</code> are the canonical constructors.</li> </ul>"},{"location":"project/constitution/#20-tier-architecture-model","title":"20. Tier Architecture Model","text":"<p>ArqonHPO operates with a strict three-tier architecture. These tiers are non-optional and govern all runtime behavior.</p> Tier Role Responsibilities Prohibitions Tier 1 (Safe Executor) Sole actuator AtomicConfig swap, allowlist enforcement, bounds checking, max-delta limits, rate limits, rollback/snapback, audit emission Cannot skip guardrails; cannot apply unevaluated proposals Tier 2 (Adaptive Engine) Proposal generator Reads telemetry digests, proposes bounded deltas, selects among approved variants Cannot mutate production state directly; must be deterministic and time-budgeted Tier \u03a9 (Offline Discovery) Candidate generator Runs continuously or periodically, generates new law families / architecture candidates, outputs diagnostic artifacts Never in the hot path; outputs are candidates only, not direct actions <p>Tier 1 Contract: * The only component allowed to apply changes to production state. * Enforces allowlist (unknown parameters \u2192 rejection), bounds (out-of-bounds \u2192 rejection), max-delta (per-step change cap), rate limits, and rollback requirements. * Must be deterministic: same (config, proposal) \u2192 same outcome.</p> <p>Tier 2 Contract: * Reads compact telemetry digests from Tier 1's observation surface. * Proposes deltas or selects among approved variants. * All proposals go through Tier 1's guardrails before application. * Must complete within <code>budget_us</code> microseconds.</p> <p>Tier \u03a9 Contract: * Runs in background / batch mode, never blocking the control loop. * Outputs candidates that must pass offline evaluation and promotion gates before entering the Approved Variant Catalog. * Outputs are labeled \"diagnostic\" or \"candidate,\" never \"decision.\"</p>"},{"location":"project/constitution/#21-merge-blocking-tier-rules","title":"21. Merge-Blocking Tier Rules","text":"<p>The following are merge-blocking rules. Pull requests violating these MUST NOT be merged.</p> Rule Violation Tier-2 cannot mutate production state Any code path where Tier 2 writes to AtomicConfig without going through Tier 1 Tier-1 is sole actuator Any direct config mutation outside SafetyExecutor Tier-\u03a9 outputs are candidates only Any code path where \u03a9 output is applied to production without promotion gate Tier boundaries are explicit Tier logic mixed without clear module separation"},{"location":"project/constitution/#22-variant-catalog-contract","title":"22. Variant Catalog Contract","text":"<p>The Approved Variant Catalog is the safety boundary for discrete configuration choices.</p> <p>Lifecycle States:</p> State Description Online Eligible Draft Initial candidate, not yet evaluated \u274c Evaluated Offline evaluation completed, results documented \u274c Approved Passed promotion gate, eligible for production selection \u2705 Promoted Currently active in production selection pool \u2705 Archived Retired from active use, retained for replay \u274c <p>Promotion Requirements: * Offline evaluation evidence (benchmark results, safety metrics) * Documented constraints (bounds, applicability conditions) * Rollback plan (how to revert if issues arise) * Evidence pack attached to promotion record</p> <p>Selection Rules: * Runtime MUST only select among <code>Approved</code> or <code>Promoted</code> variants. * <code>Draft</code> and <code>Evaluated</code> variants are NEVER eligible for online selection. * Online \"NAS-like\" behavior is selection among approved variants, not live invention.</p> <p>Schema Requirements: * Variants must have unique IDs, version numbers, and creation timestamps. * Variants must be tied to reproducible artifacts and replay seeds. * Variant transitions must be audited (who, when, why).</p>"},{"location":"project/constitution/#23-safety-semantics-for-co-evolving-laws","title":"23. Safety Semantics for Co-evolving Laws","text":"<p>Clarification: \"Laws\" and \"physics\" in this constitution refer to simulation/runtime update-rule parameters (e.g., diffusion rates, noise schedules, constraint weights), NOT real-world physical laws.</p> <p>Explicit Invariants:</p> Invariant Requirement No unbounded exploration online All online search is bounded by approved catalog and delta limits No uncontrolled oscillation Anti-thrashing rules required: cooldowns, hysteresis, confidence gating Homeostasis recovery Must be demonstrable with shock tests (inject perturbation \u2192 observe recovery) <p>Homeostatic Mode Caching: * The runtime MAY cache \"homeostatic modes\" (stable configurations that achieve target SLOs). * Cached modes enable fast re-entry without re-optimization. * Cached modes MUST be versioned, audited, and constrained by the same guardrails as live proposals. * Mode cache eviction policy MUST be explicit (LRU, TTL, or capacity-based).</p>"},{"location":"project/constitution/#tier-scope-applies-to-sections-2029","title":"Tier \u03a9 Scope (Applies to Sections 20\u201329)","text":"<p>Sections 12\u201321 govern Tier \u03a9 (Experimental) features only.</p> <p>Tier 1 (Production) behavior must continue to satisfy all Core Principles in:</p> <ul> <li>Section II.1\u201311 (Pipeline integrity, determinism, contracts, privacy, boundedness),</li> <li>Section VIII (Performance &amp; Hot-Path Invariants),</li> <li>Section IX (Observability &amp; Telemetry Contracts), and</li> <li>Section X (Data Governance &amp; Retention),</li> </ul> <p>regardless of any Tier \u03a9 configuration. No Tier \u03a9 behavior may weaken or bypass those invariants.</p>"},{"location":"project/constitution/#12-bounded-emergence-tier-only","title":"12. Bounded Emergence (Tier \u03a9 Only)","text":"<p>We consciously work only inside the Engineerable Sub-Space.</p> <ul> <li>Tier \u03a9 Only: Even in experimental regimes, we serve systems where we retain control (budget, timeouts, caps).</li> <li>Chaos Ban (Default): Highly chaotic or poorly characterized regimes are considered out of scope for production claims and live only in research sandboxes.</li> <li>Core Invariant Link: All Tier \u03a9 work remains subject to Determinism (II.2), Privacy (II.6), Safety (II.7\u20138), and Boundedness (VIII.1\u20132).</li> </ul>"},{"location":"project/constitution/#13-temporal-sovereignty-tier-only","title":"13. Temporal Sovereignty (Tier \u03a9 Only)","text":"<p>Time-varying structure (adaptive schedules, time-to-target controllers) is a first-class control mechanism.</p> <ul> <li>Dynamic Schedules: We assume control can be restored through well-designed temporal programs, not just static settings.</li> </ul>"},{"location":"project/constitution/#14-mathematical-rigor-algebraic-preference-tier-only","title":"14. Mathematical Rigor (Algebraic Preference, Tier \u03a9 Only)","text":"<ul> <li>Solvers over Heuristics: If a problem can be solved by a matrix operation or algebraic solver, do not use a neural net or heuristic.</li> <li>Explicit Control: Controllers must be explicit and observable. Hidden control loops are forbidden.</li> <li>Structured Sampling: Prefer deterministic low-discrepancy / structured grids over naive random sweeps for discovery loops.</li> </ul>"},{"location":"project/constitution/#15-the-omega-tier-risk-classification-tier-only","title":"15. The Omega Tier (Risk Classification, Tier \u03a9 Only)","text":"<p>Strategies are classified by risk profile:</p> <ul> <li>Tier 1 (Production): Safe, bounded, and deterministic for benchmark claims.</li> <li>Tier \u03a9 (Experimental): Permitted to explore complex behavior but must be strictly confined and never become default by accident.</li> </ul>"},{"location":"project/constitution/#16-diagnostic-segregation-tier-only","title":"16. Diagnostic Segregation (Tier \u03a9 Only)","text":"<ul> <li>Signals vs Decisions: Outputs from \u03a9-tier probes are treated as Diagnostic Signals, not direct decision-makers in production defaults.</li> </ul>"},{"location":"project/constitution/#17-the-4-layer-hierarchy-tier-only","title":"17. The 4-Layer Hierarchy (Tier \u03a9 Only)","text":"<p>Complex systems follow the standard Substrate \u2192 Observer \u2192 Controller \u2192 Architect hierarchy.</p> <ul> <li>Explicit Roles: Components must implicitly or explicitly fulfill one of these roles.</li> <li>Recursive Operators: Recursive strategies must explicitly declare recursion depth limits and halt conditions.</li> <li>Meta-Optimizers: Meta-optimizers whose output is the configuration of other optimizers are subject to strict evidence and safety gates.</li> </ul>"},{"location":"project/constitution/#18-probability-engines-tier-only","title":"18. Probability Engines (Tier \u03a9 Only)","text":"<p>The system may support probability-shaping engines where outputs are distributions, not scalars.</p> <ul> <li>Superposition: Decisions may be probabilistic until explicitly collapsed by a deterministic selection rule.</li> </ul>"},{"location":"project/constitution/#19-temporal-physics-tier-only","title":"19. Temporal Physics (Tier \u03a9 Only)","text":"<ul> <li>Phased Operation: Systems may explicitly declare phases (e.g., <code>[   \"probe\",   \"classify\",   \"refine\" ]</code>). Control policies must adapt to the active phase.</li> </ul>"},{"location":"project/constitution/#20-the-reality-factory-tier-only","title":"20. The Reality Factory (Tier \u03a9 Only)","text":"<p>The system may manage governed experiment namespaces (\u201cRealities\u201d) as first-class lifecycle objects.</p> <ul> <li>Lifecycle States: Experiments must track lifecycle state (<code>Draft</code> \u2192 <code>Running</code> \u2192 <code>Promoted</code> \u2192 <code>Archived</code>) with explicit transition gates.</li> </ul>"},{"location":"project/constitution/#21-strong-emergence-patterns-tier-only","title":"21. Strong Emergence Patterns (Tier \u03a9 Only)","text":"<ul> <li>Homeostatic Override: Controllers must have the authority to force reset when error thresholds are breached.</li> <li>Curiosity Metrics: \u201cSurprise\u201d is a valid optimization signal for discovery-only operators.</li> </ul>"},{"location":"project/constitution/#iii-code-quality-engineering-standards","title":"III. Code Quality &amp; Engineering Standards","text":""},{"location":"project/constitution/#1-the-boring-code-manifesto","title":"1. The \"Boring Code\" Manifesto","text":"<p>We value clarity over cleverness. ArqonHPO must be readable by a junior engineer at 3 AM.</p> <ul> <li>Readability First: If a \"clever\" one-liner creates cognitive load, expand it.</li> <li>Explicit over Implicit: Magic behavior, monkey-patching, and hidden control flow are forbidden.</li> <li>Standard Tooling: We adhere strictly to community standards (formatters, linters, type checkers).</li> </ul>"},{"location":"project/constitution/#2-asynchronous-boundaries","title":"2. Asynchronous Boundaries","text":"<p>If concurrency/parallel evaluation exists, it must not destroy determinism.</p> <ul> <li>Purity Mandate: Core decision logic must remain synchronous and pure where possible.</li> <li>Timeout Mandate: No external call (objective, subprocess, IO) shall exist without a configured timeout.</li> </ul>"},{"location":"project/constitution/#3-error-handling-philosophy","title":"3. Error Handling Philosophy","text":"<p>Errors are data, not exceptions. They must be handled explicitly.</p> <ul> <li>Fail Loud (Developer Errors): Logic errors and invariant violations must crash or hard-fail immediately.</li> <li>Fail Soft (Runtime Errors): External failures must be handled via explicit rejection or controlled degradation.</li> <li>The \"Swallow\" Ban: Silent discard of errors is forbidden.</li> </ul>"},{"location":"project/constitution/#4-logging-observability","title":"4. Logging &amp; Observability","text":"<ul> <li>Structured Only: Logs must be structured and include correlation identifiers (e.g., <code>run_id</code>).</li> <li>Level Discipline: <code>ERROR</code> means operator intervention is required. <code>WARN</code> means handled anomaly. <code>INFO</code> is lifecycle.</li> <li>Security Redaction: Logs must never contain sensitive objective payloads at <code>INFO</code> or above.</li> </ul>"},{"location":"project/constitution/#5-configuration-discipline","title":"5. Configuration Discipline","text":"<ul> <li>Config Over Code: Operational thresholds (timeouts, budgets, caps) must be configurable, not magic numbers.</li> <li>Validation on Startup: Invalid configuration must fail fast with explicit errors.</li> </ul>"},{"location":"project/constitution/#6-deterministic-state-contract-correctness","title":"6. Deterministic State &amp; Contract Correctness","text":"<p>Optimization systems die when state becomes ambiguous.</p> <ul> <li>State Machine Contracts: Phase transitions and mode decisions must be explicit.</li> <li>Determinism: Same seed + same env + same objective \u2192 same decisions and results (within defined tolerances).</li> <li>Artifact Contracts: Artifact schema is a compatibility surface.</li> </ul>"},{"location":"project/constitution/#7-contract-first-definition","title":"7. Contract-First Definition","text":"<ul> <li>Typed config and artifact schemas are the source of truth.</li> <li>Untyped ad-hoc dictionaries/maps in core paths are prohibited.</li> </ul>"},{"location":"project/constitution/#8-memory-safety-resource-guarantees","title":"8. Memory Safety &amp; Resource Guarantees","text":"<ul> <li>Resource Caps: Every subsystem must define caps for memory, retries, and timeouts.</li> </ul>"},{"location":"project/constitution/#9-concurrency-safety-ordering","title":"9. Concurrency Safety &amp; Ordering","text":"<ul> <li>Ordering Invariants: The solver must never assume ordering unless it enforces it.</li> </ul>"},{"location":"project/constitution/#10-performance-discipline","title":"10. Performance Discipline","text":"<ul> <li>Hot Path Hygiene: Avoid unnecessary allocations and logging inside per-eval loops.</li> <li>Latency Budgets: If a latency budget exists (time-to-target), it must be measured and guarded.</li> </ul>"},{"location":"project/constitution/#11-api-interface-stability","title":"11. API &amp; Interface Stability","text":"<ul> <li>Boundary Contracts: Internal modules communicate via stable interfaces.</li> </ul>"},{"location":"project/constitution/#12-dependency-hygiene","title":"12. Dependency Hygiene","text":"<ul> <li>Admission Rules: New dependencies are guilty until proven innocent.</li> <li>Pinning: Benchmark-critical dependencies must be version-pinned.</li> </ul>"},{"location":"project/constitution/#13-documentation-standards","title":"13. Documentation Standards","text":"<ul> <li>Docs as Code: Documentation must live in the repo.</li> <li>Decision Records: Significant decisions must be captured (ADR or equivalent).</li> </ul>"},{"location":"project/constitution/#14-build-artifact-integrity","title":"14. Build &amp; Artifact Integrity","text":"<ul> <li>Reproducibility: Builds and benchmark runs must be reproducible.</li> <li>Binary/Package Hygiene: Produced artifacts must be traceable to a commit and environment.</li> </ul>"},{"location":"project/constitution/#15-mathematical-rigor-algebraic-preference","title":"15. Mathematical Rigor (Algebraic Preference)","text":"<ul> <li>Solvers over Heuristics: Prefer explicit solvers where applicable.</li> <li>Explicit Control: Hidden control loops are forbidden.</li> <li>Structured Sampling: Prefer deterministic sampling schemes where it improves time-to-target and reproducibility.</li> </ul>"},{"location":"project/constitution/#iv-testing-strategy-quality-gates","title":"IV. Testing Strategy &amp; Quality Gates","text":""},{"location":"project/constitution/#1-tdd-as-the-working-standard","title":"1. TDD as the Working Standard","text":"<p>Test-Driven Development (TDD) is the default and expected workflow for all ArqonHPO components.</p> <ul> <li>The Workflow:</li> <li>Specify: Define behavior in <code>/specs/</code> (SDD-first).</li> <li>Test: Write or extend tests that express that behavior.</li> <li>Implement: Write the code that satisfies the tests.</li> <li>Refactor: Optimize while keeping the suite green.</li> </ul>"},{"location":"project/constitution/#2-coverage-expectations-per-subsystem","title":"2. Coverage Expectations (Per Subsystem)","text":"<p>Coverage is about behavioral exhaustiveness, not raw percentages.</p> <ul> <li>Solver Core: Must cover probe, classify, mode select, refine, and budget accounting.</li> <li>Artifact Layer: Must cover schema versioning, determinism, replay-critical fields.</li> <li>Benchmark Harness: Must cover time-to-target measurement and reporting.</li> </ul>"},{"location":"project/constitution/#3-test-discipline-requirements","title":"3. Test Discipline Requirements","text":"<ul> <li>Unit Tests: Must run fast with zero external services.</li> <li>Integration Tests: Must run end-to-end with real dependencies where relevant.</li> <li>Flaky Tests: Flaky tests are Critical Bugs.</li> <li>Determinism: Tests must avoid random sleeps and time-dependent logic; use controlled clocks.</li> </ul>"},{"location":"project/constitution/#4-quality-gates","title":"4. Quality Gates","text":"<p>A PR may not be merged if any of the following are true:</p> <ul> <li>Determinism Gate: nondeterministic behavior without explicit labeling and tests.</li> <li>Evidence Gate: benchmark/perf claims without reproducible evidence.</li> <li>Artifact Gate: schema changes without versioning and compatibility notes.</li> <li>Spec Gate: behavior implemented without a Spec, or Spec not updated to match Code.</li> <li>Technical Debt Gate: new <code>TODO</code>s without <code>TD-###</code> and TTL.</li> </ul>"},{"location":"project/constitution/#5-probe-guardrail-tests","title":"5. Probe Guardrail Tests","text":"<p>Probe changes require passing the following mandatory test classes:</p> Test Class Requirement <code>TestProbeOnlyQuality</code> New probe beats legacy on shifted instances. <code>TestStructuredRouting</code> NM wins on structured landscapes (mode selection). <code>TestMultimodalGuardrail</code> Probe is robust on Rastrigin-class objectives. <code>TestGeometryRegression</code> Probe geometry is deterministic and reproducible. <code>TestStructuredNMCorrectness</code> NM periodic arithmetic is correct. <code>TestTimeToQuality</code> Time-to-target metrics are computed and reported. <p>Reference implementation: <code>benchmarks/test_probe_guardrails.py</code></p>"},{"location":"project/constitution/#v-lifecycle-automation","title":"V. Lifecycle &amp; Automation","text":"<p>ArqonHPO does not \u201cship code\u201d; it manufactures artifacts through a controlled factory.</p>"},{"location":"project/constitution/#1-the-factory-mandate","title":"1. The Factory Mandate","text":"<p>Manual releases are forbidden for production claims. CI is the source of truth.</p> <ul> <li>The Pipeline is Sovereign: If it did not pass CI, it does not exist.</li> </ul>"},{"location":"project/constitution/#2-immutable-reproducible-artifacts","title":"2. Immutable &amp; Reproducible Artifacts","text":"<ul> <li>Immutable Artifacts: Release artifacts must be identifiable by content hash.</li> <li>Reproducible Builds: The same commit must build reproducibly in the canonical environment.</li> </ul>"},{"location":"project/constitution/#3-supply-chain-security","title":"3. Supply Chain Security","text":"<ul> <li>Dependency Locking: No floating versions for benchmark-critical paths.</li> <li>Provenance: Artifact origin must be traceable (commit, branch, CI run).</li> </ul>"},{"location":"project/constitution/#vi-operational-excellence","title":"VI. Operational Excellence","text":"<p>ArqonHPO is correctness-sensitive infrastructure for optimization. The way it behaves under real objectives is as important as the way it behaves in tests.</p>"},{"location":"project/constitution/#1-performance-capacity-invariants","title":"1. Performance &amp; Capacity Invariants","text":"<ul> <li>Boundedness: No unbounded loops. Budget and timeouts are mandatory.</li> <li>Overhead Discipline: Policy updates and bookkeeping must remain bounded and low overhead.</li> </ul>"},{"location":"project/constitution/#2-observability-audit","title":"2. Observability &amp; Audit","text":"<ul> <li>Reconstructability: Logs + artifacts must allow reconstruction of what happened in a run.</li> <li>No Silent Recovery: Any fallback must be visible and test-covered.</li> </ul>"},{"location":"project/constitution/#vii-governance-amendment","title":"VII. Governance &amp; Amendment","text":"<p>Governance defines how ArqonHPO protects its mission and how this Constitution itself may change.</p>"},{"location":"project/constitution/#1-scope-protection","title":"1. Scope Protection","text":"<p>ArqonHPO is probe-gated optimization for the two target use cases. Scope creep is a bug.</p>"},{"location":"project/constitution/#2-complexity-budget","title":"2. Complexity Budget","text":"<p>Complexity is technical debt with compound interest.</p> <ul> <li>Adding major dependencies or new execution modes requires explicit review and an ADR.</li> </ul>"},{"location":"project/constitution/#3-amendments","title":"3. Amendments","text":"<p>This Constitution is living but intentionally hard to change.</p> <ul> <li>Amendments require a documented proposal (rationale + impact) and a version bump.</li> </ul>"},{"location":"project/constitution/#viii-performance-hot-path-invariants","title":"VIII. Performance &amp; Hot-Path Invariants","text":"<p>Performance is not an optimization; it is a correctness property.</p>"},{"location":"project/constitution/#1-boundedness-as-law","title":"1. Boundedness as Law","text":"<p>Unbounded anything is a denial-of-service vector.</p> <ul> <li>No Unbounded Work: Every loop must have a budget.</li> <li>CPU Boundaries: Heavy work must not block the per-eval control loop without explicit design.</li> </ul>"},{"location":"project/constitution/#2-hot-path-constraints","title":"2. Hot-Path Constraints","text":"<ul> <li>O(1) or Amortized O(1): Per-eval policy decisions must be O(1) or amortized O(1).</li> <li>No Hidden I/O: Do not write artifacts inside the inner loop unless explicitly buffered.</li> </ul>"},{"location":"project/constitution/#3-hot-path-parameter-representation-determinism-v141-merge-blocking","title":"3. Hot-Path Parameter Representation &amp; Determinism (v1.4.1, merge-blocking)","text":"<p>This section defines non-negotiable architectural invariants for parameter storage in Tier-1/Tier-2 hot paths. Violations are merge blockers.</p> <p>Hot Path Definition (Normative): \"Hot Path\" means any code executing inside the Tier-2 decision window or Tier-1 apply window, specifically: all functions and their transitive callees executed during: 1. <code>T2_decision_us</code> (start: digest popped \u2192 end: proposal emitted) 2. <code>T1_apply_us</code> (start: proposal received \u2192 end: in-memory config swap completed)</p> <p>Hot Path includes: Tier-2 observe/decision loop, SPSA step math, guardrail validation, delta application, atomic swap, telemetry ingest, audit enqueue (non-blocking), and any per-tick scheduling within these windows.</p>"},{"location":"project/constitution/#a-hot-path-disallowed-types-merge-blocking","title":"A. Hot-Path Disallowed Types (Merge-Blocking)","text":"<p>In Hot Path code, the following are FORBIDDEN: * <code>std::collections::HashMap</code> * <code>hashbrown::HashMap</code> * Any map/dictionary keyed by strings (or heap-owned identifiers) used to store parameters or deltas.</p> <p>Reason: Hot Path must use dense indexed representations (<code>ParamVec</code>/<code>DeltaVec</code>) for determinism, locality, and zero-allocation guarantees.</p>"},{"location":"project/constitution/#b-hot-path-representation-rule-required","title":"B. Hot-Path Representation Rule (Required)","text":"<p>Tier-1 and Tier-2 parameter values and deltas MUST be represented as: * ParamVec = dense ordered numeric vector (<code>SmallVec&lt;[f64; N]&gt;</code> or <code>Vec&lt;f64&gt;</code>) * DeltaVec = same dense ordered numeric vector type.</p> <p>Tier-1/Tier-2 public APIs MUST NOT accept or return named-parameter maps.</p>"},{"location":"project/constitution/#c-no-escape-hatches-merge-blocking","title":"C. No Escape Hatches (Merge-Blocking)","text":"<p>In Hot Path modules/crates: * <code>#[allow(clippy::disallowed_types)]</code> is FORBIDDEN. * Any allow/override of the Hot Path disallowed-type rules is FORBIDDEN.</p> <p>Exception: Boundary modules only (CLI/IO/artifact serialization) may use named maps, but must never be linked into Hot Path timing windows.</p>"},{"location":"project/constitution/#d-enforcement-requirements-ci-merge-blocking","title":"D. Enforcement Requirements (CI Merge-Blocking)","text":"<p>CI MUST enforce Hot Path type constraints using: * <code>cargo clippy --all-targets --all-features -- -D warnings</code> * <code>#![deny(clippy::disallowed_types)]</code> in the Hot Path crate/module root * <code>clippy.toml</code> specifying disallowed types, at minimum:   * <code>std::collections::HashMap</code>   * <code>hashbrown::HashMap</code></p> <p>Any violation is a MERGE BLOCKER.</p>"},{"location":"project/constitution/#e-constructorapi-rule-required","title":"E. Constructor/API Rule (Required)","text":"<p>All Tier-1/Tier-2 constructors and runtime methods MUST accept only dense types: * Engine initialization MUST accept <code>(ParamRegistry, ParamVec)</code> (or a single struct containing them). * Hot Path runtime loops MUST NOT accept <code>NamedParams</code> or any <code>HashMap&lt;String, _&gt;</code> type (directly or indirectly). * All boundary conversion from named\u2192dense MUST occur once at initialization or boundary serialization only.</p>"},{"location":"project/constitution/#f-paramregistry-contract-required-for-audit-replay","title":"F. ParamRegistry Contract (Required for Audit + Replay)","text":"<ul> <li>Existence REQUIRED: A <code>ParamRegistry</code> (or equivalent) MUST exist to provide:</li> <li>Stable mapping: <code>name \u2194 id/index</code></li> <li>Deterministic ordering (consistent across runs with same schema)</li> <li>Schema/version identity</li> <li>Immutability REQUIRED: The mapping MUST be immutable during a run for Tier-1/Tier-2 operation.</li> </ul>"},{"location":"project/constitution/#g-deterministic-replay-artifact-contract-required","title":"G. Deterministic Replay Artifact Contract (Required)","text":"<p>Artifacts MUST include the following fields (exact keys): * <code>seed</code>: <code>u64</code> * <code>registry_hash64</code>: <code>u64</code> * <code>registry_names</code>: <code>[String]</code> (stable ordered list) * <code>param_len</code>: <code>usize</code> * <code>params_vec</code>: <code>[f64]</code> (dense ordered values)</p> <p>Optional (derived for readability only): * <code>params_named</code>: <code>{ String: f64 }</code></p> <p>Rule: <code>params_named</code> MUST be derivable from <code>registry_names</code> + <code>params_vec</code> and MUST NOT be required for replay. Replay MUST NOT require string hashing to reconstruct the decision path.</p>"},{"location":"project/constitution/#h-tier-exception-policy-explicitly-bounded","title":"H. Tier \u03a9 Exception Policy (Explicitly Bounded)","text":"<ul> <li>Sandbox Exploration Allowed: Tier \u03a9 (experimental) MAY explore dynamic parameter sets.</li> <li>Production Invariants Preserved: Tier-1/Tier-2 invariants remain non-bypassable even when Tier \u03a9 is active.</li> <li>Promotion Gate: Promotion from Tier \u03a9 to production REQUIRES passing all hot-path invariant tests and freezing a registry.</li> </ul>"},{"location":"project/constitution/#i-performance-enforcement-mergeship-blockers","title":"I. Performance Enforcement (Merge/Ship Blockers)","text":"<ul> <li>No-Alloc Test REQUIRED: CI MUST include a \"no-alloc hot path\" test for Tier-1 apply and Tier-2 observe/decision paths (release mode).</li> <li><code>observe()</code> allocs == 0</li> <li><code>apply()</code> allocs == 0</li> <li>Benchmark Gate REQUIRED: CI MUST include a benchmark regression gate for <code>T2_decision_us</code> and <code>T1_apply_us</code> (release mode) consistent with VIII.5 timing budgets.</li> <li>Budgets Checked: Budgets are checked in release mode and FAIL CI if exceeded.</li> </ul> <p>Evidence Requirement: * Any latency claim MUST attach evidence (Observed) including: build mode, CPU model, benchmark method, and p50/p99/max. * Allocation claims MUST be measured (Observed via instrumentation or allocator hook) or the claim is false.</p>"},{"location":"project/constitution/#4-time-to-target-metrics","title":"4. Time-to-Target Metrics","text":"<p>The canonical quality-time tradeoff measurements are:</p> <ul> <li>Evals-to-Threshold: Number of evaluations to first reach a target quality threshold.</li> <li>Hit-by-N: Binary success metric\u2014did the run reach threshold within N evals?</li> <li>Median-Best-at-Horizon: Median of best-seen value at a fixed eval count across seeds.</li> </ul> <p>These metrics MUST be reported per-objective in benchmark artifacts.</p>"},{"location":"project/constitution/#5-timing-window-contracts","title":"5. Timing Window Contracts","text":"<p>For microsecond-latency operation, the following timing windows are canonical:</p> Timing Window Definition Typical Budget <code>T2_decision_us</code> Digest popped from ring buffer \u2192 proposal emitted by Tier 2 \u22641,000 \u00b5s <code>T1_apply_us</code> Proposal received by Tier 1 \u2192 guardrails validated + atomic swap completed \u2264100 \u00b5s <code>E2E_visible_us</code> Digest available \u2192 dataplane observes new config \u22642,000 \u00b5s <p>Measurement Requirements: * Latency claims MUST specify: build mode (debug/release), hardware (CPU model, memory), and measurement method (wall clock, flamegraph, tracing). * Benchmarks MUST include p50, p99, and max latencies. * Regression guards MUST exist for all timing budgets (CI fails if exceeded).</p>"},{"location":"project/constitution/#6-hot-path-non-blocking-audit","title":"6. Hot Path Non-Blocking Audit","text":"<p>Audit-to-disk MUST be explicitly decoupled from the critical path.</p> <ul> <li>Ring Buffer / Async Writer: Audit events are pushed to a lock-free ring buffer; a background thread persists to disk.</li> <li>No Blocking I/O: Disk I/O (file writes, network calls) is FORBIDDEN in the apply critical path.</li> <li>Overflow Policy: If the ring buffer is full, the overflow policy MUST be explicit (drop oldest, block, or signal backpressure).</li> </ul>"},{"location":"project/constitution/#7-zero-allocation-critical-path","title":"7. Zero-Allocation Critical Path","text":"<p>The critical path (<code>T1_apply_us</code> window) MUST remain zero-allocation:</p> <ul> <li>No Heap Allocations: Use pre-allocated buffers, arena allocators, or stack allocation.</li> <li>No Blocking Syscalls: No <code>malloc</code>, <code>mmap</code>, file I/O, or network I/O.</li> <li>Arc Clone Only: <code>snapshot()</code> operations use cheap Arc clone, not deep copy.</li> </ul>"},{"location":"project/constitution/#ix-observability-telemetry-contracts","title":"IX. Observability &amp; Telemetry Contracts","text":"<p>What cannot be observed cannot be governed.</p>"},{"location":"project/constitution/#1-logs-metrics-traces-as-first-class-citizens","title":"1. Logs, Metrics, Traces as First-Class Citizens","text":"<ul> <li>Structured Logs Only: Must include <code>run_id</code> and phase markers.</li> <li>Telemetry for Mode Decisions: Mode selection and classification results must be observable.</li> </ul>"},{"location":"project/constitution/#2-structured-events-correlation-ids","title":"2. Structured Events &amp; Correlation IDs","text":"<p>For the Adaptive Engine control loop, the following event types are REQUIRED:</p> Event Type Trigger Required Fields <code>digest</code> New telemetry digest pushed <code>run_id</code>, <code>timestamp_us</code>, <code>digest_id</code>, <code>objective_value</code> <code>proposal</code> Tier 2 emits a proposal <code>run_id</code>, <code>proposal_id</code>, <code>config_version</code>, <code>delta_summary</code> <code>apply</code> Tier 1 successfully applies config <code>run_id</code>, <code>proposal_id</code>, <code>new_config_version</code>, <code>apply_latency_us</code> <code>rollback</code> Tier 1 triggers rollback <code>run_id</code>, <code>proposal_id</code>, <code>rollback_reason</code>, <code>reverted_to_version</code> <code>promotion</code> Variant promoted to Approved/Promoted <code>run_id</code>, <code>variant_id</code>, <code>old_state</code>, <code>new_state</code>, <code>evidence_ref</code> <p>Correlation ID Requirements: * All events in a single adaptation cycle MUST share the same <code>run_id</code>. * Proposals MUST have unique <code>proposal_id</code> for traceability. * Config versions MUST use monotonic <code>config_version</code> counters.</p>"},{"location":"project/constitution/#x-data-governance-retention","title":"X. Data Governance &amp; Retention","text":"<p>ArqonHPO may handle sensitive objective data. Data is an asset and a liability.</p>"},{"location":"project/constitution/#1-data-classification","title":"1. Data Classification","text":"<ul> <li>Run Artifacts: schema-versioned run outputs.</li> <li>Objective Data: treated as sensitive by default.</li> </ul>"},{"location":"project/constitution/#2-retention","title":"2. Retention","text":"<ul> <li>Explicit Retention: No infinite retention by accident; retention policies must be explicit.</li> </ul>"},{"location":"project/constitution/#xi-internal-service-contracts-complexity-escalation","title":"XI. Internal Service Contracts &amp; Complexity Escalation","text":"<p>The internal structure must remain understandable, evolvable, and safe.</p>"},{"location":"project/constitution/#1-internal-contracts","title":"1. Internal Contracts","text":"<ul> <li>Versioned Contracts: Internal boundaries must have explicit, versioned contracts (types + schemas).</li> </ul>"},{"location":"project/constitution/#2-complexity-budget-escalation","title":"2. Complexity Budget &amp; Escalation","text":"<ul> <li>Introducing a new core dependency or major execution mode requires a design review document and ADR.</li> </ul>"},{"location":"project/constitution/#3-benchmark-schema-contract","title":"3. Benchmark Schema Contract","text":"<p>Benchmark artifacts MUST follow a declarative schema:</p> <ul> <li>Objective Suite (minimum): sphere_smooth_shift, rosenbrock_smooth_shift, rastrigin_torus.</li> <li>Cost Regimes: cheap (1ms), expensive (20ms+).</li> <li>Output Schema: CSV with columns [run_id, eval_id, best_so_far, elapsed_ms, params].</li> <li>Plots: best_vs_time.png, cdf_time_to_threshold.png per objective.</li> </ul>"},{"location":"project/constitution/#4-sdk-binding-compliance","title":"4. SDK Binding Compliance","text":"<p>Python bindings MUST maintain parity with Rust core:</p> <ul> <li>Determinism Parity: <code>ArqonProbe</code> and <code>ArqonSolver</code> (Python) MUST produce identical results to Rust core for same (seed, config).</li> <li>Sharding Verification: Bitwise hash of sorted samples MUST match single-worker vs multi-worker configurations.</li> <li>Binding Changes: Require parity tests in CI before merge.</li> </ul>"},{"location":"project/constitution/#5-strategy-parameter-governance","title":"5. Strategy Parameter Governance","text":"<p>Strategy parameters require explicit governance:</p> <ul> <li>K (parallel starts): MUST have documented default and rationale.</li> <li>Triage Budget: MUST be bounded; unbounded triage is forbidden.</li> <li>Stall Threshold: MUST trigger rotation; silent stalling is forbidden.</li> <li>Spice Ratio: MUST be configurable with documented default (10%).</li> </ul> <p>Changes to defaults require an ADR with benchmark evidence.</p>"},{"location":"project/constitution/#xii-glossary-canonical-definitions","title":"XII. Glossary &amp; Canonical Definitions","text":"<p>To prevent interpretation drift (especially for Spec Kit agents), we define core vocabulary used throughout this Constitution.</p> Term Definition ArqonHPO The probe-gated optimization engine described by this Constitution. Probe Deterministic initial sampling phase to gather candidates and signal. Classify Fixed-size test producing a label and score to drive mode selection. Mode The chosen refinement strategy family (structured vs chaotic). Time-to-Target Time/evals to reach a specified objective threshold. Tier 1 (Safe Executor) The sole actuator for production state; enforces all guardrails before applying changes. Tier 2 (Adaptive Engine) Reads telemetry, proposes deltas or variant selections; cannot mutate production state directly. Tier \u03a9 (Offline Discovery) Experimental/background loop that generates candidates; never in hot path, outputs are diagnostic only. Homeostasis A stable operating regime the adaptive engine steers toward under varying conditions. Law knobs Runtime/simulation parameters (diffusion, noise, decay, constraint weights) tunable within safety envelopes. Variant Catalog Registry of approved configuration variants with lifecycle states (Draft \u2192 Evaluated \u2192 Approved \u2192 Promoted \u2192 Archived). Promotion Gate Evidence pack + offline evaluation + rollback plan required to promote a variant to Approved state. E2E_visible_us Time from digest availability to dataplane observing new config (microseconds). T2_decision_us Time from digest popped to proposal emitted by Tier 2 (microseconds). T1_apply_us Time from proposal received to atomic swap completed by Tier 1 (microseconds). ParamVec Dense parameter storage (<code>SmallVec&lt;[f64; 16]&gt;</code>) used in Tier-1/Tier-2 hot paths. FORBIDDEN to use HashMap. (v1.4.0) ParamRegistry Stable mapping between human-readable parameter names and dense array indices. Immutable during a run. (v1.4.0) Boundary Any interface layer where human-readable names exist (CLI/SDK/artifacts/wire protocol). HashMap allowed only here. (v1.4.0) Hot Path Code executed per-tick/per-decision/per-apply with strict latency budgets (&lt;1ms). No heap allocation, no string ops. (v1.4.0)"},{"location":"project/constitution/#xiv-ultimate-integrity-attestation-evidence-pack","title":"XIV. ULTIMATE INTEGRITY ATTESTATION &amp; EVIDENCE PACK","text":"<p>This section is the merge/ship gate. It exists so \u201cdone\u201d is not a feeling\u2014it is a reproducible fact.</p>"},{"location":"project/constitution/#1-mergeship-attestation-required","title":"1) Merge/Ship Attestation (Required)","text":"<p>By merging or shipping, the author(s) and reviewer(s) attest:</p> <ul> <li>No placeholders exist in production paths (no TODOs, stubs, pseudocode-as-work, \u201clater hardening\u201d).</li> <li>No fake evidence is presented (no invented logs, benchmarks, screenshots, coverage, or results).</li> <li>No happy-path-only verification exists for critical behaviors.</li> <li>No silent failure handling exists; errors are handled/logged/propagated with context.</li> <li>Warnings were treated as errors (clean lint/typecheck/compile).</li> <li>Any technical debt is recorded as <code>TD-###</code> with owner + TTL + exit criteria and is bounded by tests.</li> <li>All claims are labeled Observed/Derived/Unverified, and Observed claims have attached evidence.</li> </ul> <p>If you cannot honestly attest to every item above, you must not merge/ship.</p>"},{"location":"project/constitution/#2-evidence-pack-attach-or-link-required","title":"2) Evidence Pack (Attach or Link; Required)","text":"<p>A change is invalid without a reproducible Evidence Pack. The Evidence Pack must be tied to a specific commit and must be reproducible by another engineer.</p>"},{"location":"project/constitution/#21-build-proof","title":"2.1 Build Proof","text":"<ul> <li>CI run or local output showing:</li> <li>clean build,</li> <li>clean lint/typecheck/format,</li> <li>warnings treated as errors.</li> </ul>"},{"location":"project/constitution/#22-test-proof","title":"2.2 Test Proof","text":"<ul> <li>Results for:</li> <li>unit tests,</li> <li>integration tests (where applicable),</li> <li>property/fuzz tests (where required by input boundaries),</li> <li>concurrency/ordering tests (where applicable).</li> <li>A short note listing what is not covered and why (explicitly, not implicitly).</li> </ul>"},{"location":"project/constitution/#23-failure-matrix-proof-where-the-bad-paths-live","title":"2.3 Failure Matrix Proof (Where the bad paths live)","text":"<p>For each externally coupled feature, list: - failure scenarios tested (timeouts, retries, malformed responses, permission failures, overload/backpressure, partial failures), - test file(s) and test names (or equivalent pointers).</p>"},{"location":"project/constitution/#24-traceability-proof-truth-table","title":"2.4 Traceability Proof (Truth Table)","text":"<p>Provide a \u201ctruth table\u201d mapping: - requirement / acceptance criteria \u2192 implementation location(s) \u2192 test location(s) \u2192 documentation location(s) \u2192 evidence artifact(s).</p> <p>Rule: If a requirement has no test, it is untested. If a test has no requirement, it is suspicious.</p>"},{"location":"project/constitution/#25-runtime-proof-when-applicable","title":"2.5 Runtime Proof (When Applicable)","text":"<ul> <li>example run logs demonstrating:</li> <li>normal behavior,</li> <li>at least one failure mode behaving correctly.</li> <li>proof of observability works:</li> <li>correlation IDs exist,</li> <li>metrics/traces exist (or equivalent breadcrumbs).</li> </ul>"},{"location":"project/constitution/#26-performance-resource-proof-when-relevant","title":"2.6 Performance / Resource Proof (When Relevant)","text":"<ul> <li>baseline numbers + method + environment,</li> <li>a regression guard (benchmark test, threshold check, or documented budget),</li> <li>proof of bounded behavior (caps, backpressure, shedding policy).</li> </ul>"},{"location":"project/constitution/#27-reproduction-commands","title":"2.7 Reproduction Commands","text":"<ul> <li>one-command verification (examples):</li> <li><code>pytest</code>, <code>python -m build</code>, etc.</li> <li>environment notes:</li> <li>pinned toolchains/dependencies,</li> <li>seed control for deterministic tests.</li> </ul>"},{"location":"project/constitution/#28-canonical-environment-mandate","title":"2.8 Canonical Environment Mandate","text":"<p>To ensure absolute reproducibility, all development and CI operations MUST use the canonical Conda environment: <code>helios-gpu-118</code>.</p> <p>Paths: - Python: <code>/home/irbsurfer/miniconda3/envs/helios-gpu-118/bin/python</code> - Cargo: <code>/home/irbsurfer/miniconda3/envs/helios-gpu-118/bin/cargo</code></p> <p>Rules: - Do NOT rely on system <code>python</code> or <code>cargo</code>. - Scripts and tools MUST resolve these absolute paths or explicitly activate the environment.</p>"},{"location":"project/constitution/#3-debt-register-enforcement-td-","title":"3) Debt Register Enforcement (TD-###)","text":"<p>If any <code>TD-###</code> exists in the change: - TTL date and owner are mandatory. - The debt boundary must be protected by tests so it cannot silently expand. - The exit criteria must be concrete. - Debt past TTL is a release/merge blocker.</p>"},{"location":"project/constitution/#4-professional-review-checklist-hard-questions-only","title":"4) Professional Review Checklist (Hard Questions Only)","text":"<p>Review must answer \u201cyes\u201d with evidence:</p> <ul> <li>Does this handle failure modes explicitly (not \u201cassumed\u201d)?</li> <li>Are tests realistic, adversarial, and non-trivial (no lazy synthetics)?</li> <li>Are there concurrency/ordering hazards, and are they tested or explicitly ruled out?</li> <li>Is behavior observable (logs/metrics/traces/breadcrumbs)?</li> <li>Are resource bounds explicit (timeouts, caps, retry budgets, queue bounds)?</li> <li>Is the code readable under pressure (3 AM standard)?</li> <li>Is documentation updated to match behavior and constraints?</li> <li>Can another engineer reproduce the Evidence Pack from scratch?</li> </ul> <p>If any answer is \u201cno,\u201d the change is not complete.</p>"},{"location":"project/constitution/#5-claim-ledger-summary-required-when-stating-status","title":"5) Claim Ledger Summary (Required When Stating Status)","text":"<p>If a deliverable claims completion or correctness, it must include:</p> <ul> <li>Observed claims: link evidence</li> <li>Derived claims: list assumptions + risks + how to verify</li> <li>Unverified claims: list the minimal experiment to verify</li> </ul> <p>Rule: If it cannot be reproduced from the Evidence Pack, it is not true. Rule: If it is not true, it is not done.</p>"},{"location":"project/constitution/#implementation-substrate-sdk-contract","title":"Implementation Substrate &amp; SDK Contract","text":"<ul> <li>Core implementation MUST be a Rust library crate exposing the probe-gated solver API.</li> <li>CLI MUST be a thin Rust binary crate that delegates to the core.</li> <li>SDKs (for example, Python) MUST be thin bindings over the same core, not reimplementing solver logic.</li> <li>Artifacts MUST be language-agnostic (JSON) and serve as the compatibility contract between surfaces.</li> </ul> <p>Version: 1.0.0 Ratified: 2025-12-13 Last Amended: 2025-12-13  </p>"},{"location":"project/contributing/","title":"Contributing","text":"<p>Please see CONTRIBUTING.md for contribution guidelines.</p>"},{"location":"project/contributing/#license","title":"License","text":"<p>This project is licensed under the Apache-2.0 License.</p>"},{"location":"project/contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>Please review our Code of Conduct.</p>"},{"location":"project/contributing/#security","title":"Security","text":"<p>Please review our Security Policy for reporting vulnerabilities.</p>"},{"location":"projects/plans/sdk/","title":"ArqonHPO Cross-Platform SDK - Implementation Plan","text":"<p>Status: Deferred - Documentation and website work prioritized first. Created: 2025-12-17 Last Updated: 2025-12-17</p>"},{"location":"projects/plans/sdk/#executive-summary","title":"Executive Summary","text":"<p>Transform ArqonHPO from a Python-only library into a world-class, truly cross-platform SDK that runs everywhere: from edge devices to browsers, from mobile apps to cloud-native services.</p>"},{"location":"projects/plans/sdk/#vision-the-universal-optimization-primitive","title":"Vision: The Universal Optimization Primitive","text":"<p>ArqonHPO's sub-microsecond performance isn't just fast\u2014it's fast enough to embed anywhere. This SDK strategy leverages that speed advantage to create optimization primitives for every platform.</p>"},{"location":"projects/plans/sdk/#decision-points-to-be-resolved","title":"Decision Points (To Be Resolved)","text":"<p>[!IMPORTANT] Target Platform Prioritization: Confirm the priority order for language bindings: 1. Node.js/TypeScript - NPM ecosystem, edge computing (Cloudflare Workers, Deno) 2. Swift/iOS - Apple platforms, on-device ML tuning 3. Go - Cloud infrastructure, Kubernetes operators 4. WebAssembly - Browser-based optimization, portable edge</p> <p>[!WARNING] Breaking Change Consideration: The current Python SDK uses JSON-serialized configs. Options: - Option A: Keep JSON for all SDKs (maximum portability, simpler FFI) - Option B: Native typed configs per language (better ergonomics, more implementation work) - Option C: Both (JSON for interop, native wrappers for convenience)</p>"},{"location":"projects/plans/sdk/#architecture-overview","title":"Architecture Overview","text":"<pre><code>graph TB\n    subgraph \"Rust Core (Single Source of Truth)\"\n        CORE[\"arqonhpo-core&lt;br/&gt;Solver \u2022 Probe \u2022 Classify \u2022 Refine\"]\n        HOTPATH[\"hotpath&lt;br/&gt;Adaptive Engine \u2022 SPSA \u2022 Safety\"]\n    end\n\n    subgraph \"C FFI Layer (Universal Bridge)\"\n        FFI[\"arqonhpo-ffi&lt;br/&gt;C-ABI Stable \u2022 Zero-Copy \u2022 Thread-Safe\"]\n    end\n\n    subgraph \"Language Bindings\"\n        PY[\"Python&lt;br/&gt;PyO3 (Native)\"]\n        NODE[\"Node.js&lt;br/&gt;NAPI-RS\"]\n        SWIFT[\"Swift&lt;br/&gt;C Interop + Package\"]\n        GO[\"Go&lt;br/&gt;CGO Bindings\"]\n        WASM[\"WebAssembly&lt;br/&gt;wasm-bindgen\"]\n    end\n\n    subgraph \"Distribution\"\n        NPM[\"npm / JSR\"]\n        PYPI[\"PyPI\"]\n        COCOA[\"Swift Package\"]\n        GOMOD[\"Go Modules\"]\n        CRATES[\"crates.io\"]\n    end\n\n    CORE --&gt; FFI\n    HOTPATH --&gt; FFI\n    FFI --&gt; NODE\n    FFI --&gt; SWIFT\n    FFI --&gt; GO\n    CORE --&gt; PY\n    CORE --&gt; WASM\n\n    NODE --&gt; NPM\n    PY --&gt; PYPI\n    SWIFT --&gt; COCOA\n    GO --&gt; GOMOD\n    CORE --&gt; CRATES\n</code></pre>"},{"location":"projects/plans/sdk/#proposed-changes","title":"Proposed Changes","text":""},{"location":"projects/plans/sdk/#component-1-enhanced-c-ffi-layer","title":"Component 1: Enhanced C FFI Layer","text":"<p>The C FFI is the universal substrate enabling all non-Rust bindings. Must be rock-solid.</p>"},{"location":"projects/plans/sdk/#modify-cratesffisrclibrs","title":"[MODIFY] <code>crates/ffi/src/lib.rs</code>","text":"<p>Complete rewrite from placeholder to production-ready C FFI.</p> <p>Key Design Principles: - Opaque Handles: All Rust objects exposed as opaque pointers (<code>*mut ArqonSolver</code>) - Error Strings: Errors returned as allocated C strings (caller must free) - JSON In/Out: Config and results as C strings for maximum portability - Thread Safety: All exported functions are thread-safe</p> <pre><code>// === Core Types (C-compatible) ===\n\n/// Opaque solver handle\n#[repr(C)]\npub struct ArqonSolverHandle {\n    _private: [u8; 0],\n}\n\n/// Opaque probe handle  \n#[repr(C)]\npub struct ArqonProbeHandle {\n    _private: [u8; 0],\n}\n\n/// Result type for fallible operations\n#[repr(C)]\npub struct ArqonResult {\n    success: bool,\n    error_message: *mut c_char,  // NULL on success, caller must free on error\n}\n\n/// Batch output from ask()\n#[repr(C)]\npub struct ArqonBatch {\n    json_data: *mut c_char,  // JSON array of candidates, caller must free\n    count: usize,            // Number of candidates (0 = optimization complete)\n}\n\n// === Lifecycle Functions ===\n\n/// Create a new solver from JSON config\n/// Returns NULL on error, sets error via arqon_last_error()\n#[no_mangle]\npub extern \"C\" fn arqon_solver_create(config_json: *const c_char) -&gt; *mut ArqonSolverHandle;\n\n/// Destroy a solver and free all resources\n#[no_mangle]  \npub extern \"C\" fn arqon_solver_destroy(solver: *mut ArqonSolverHandle);\n\n// === Core API ===\n\n/// Get next batch of candidates\n/// Returns empty batch (count=0) when optimization is complete\n#[no_mangle]\npub extern \"C\" fn arqon_solver_ask(solver: *mut ArqonSolverHandle) -&gt; ArqonBatch;\n\n/// Report evaluation results\n#[no_mangle]\npub extern \"C\" fn arqon_solver_tell(\n    solver: *mut ArqonSolverHandle, \n    results_json: *const c_char\n) -&gt; ArqonResult;\n\n// === Memory Management ===\n\n/// Free a string allocated by this library\n#[no_mangle]\npub extern \"C\" fn arqon_string_free(s: *mut c_char);\n\n/// Get the last error message (thread-local)\n#[no_mangle]\npub extern \"C\" fn arqon_last_error() -&gt; *const c_char;\n</code></pre>"},{"location":"projects/plans/sdk/#new-cratesfficargotoml","title":"[NEW] <code>crates/ffi/Cargo.toml</code>","text":"<p>Enhanced Cargo.toml with proper library types and documentation.</p> <pre><code>[package]\nname = \"arqonhpo-ffi\"\nversion = \"0.1.0\"\nedition = \"2021\"\ndescription = \"C FFI bindings for ArqonHPO - Cross-platform optimization SDK\"\nlicense = \"Apache-2.0\"\ncategories = [\"api-bindings\", \"development-tools::ffi\"]\n\n[lib]\nname = \"arqonhpo\"\ncrate-type = [\"cdylib\", \"staticlib\"]\n\n[dependencies]\narqonhpo-core = { workspace = true }\nlibc = \"0.2\"\nserde_json = { workspace = true }\n\n[build-dependencies]\ncbindgen = \"0.27\"\n\n[features]\ndefault = []\n# Include Adaptive Engine APIs in FFI\nadaptive-engine = []\n</code></pre>"},{"location":"projects/plans/sdk/#new-cratesfficbindgentoml","title":"[NEW] <code>crates/ffi/cbindgen.toml</code>","text":"<p>Automatic C header generation for downstream bindings.</p> <pre><code>language = \"C\"\nheader = \"/* ArqonHPO - Cross-Platform Optimization SDK */\"\ninclude_guard = \"ARQONHPO_H\"\ntab_width = 4\nstyle = \"Both\"\ncpp_compat = true\n\n[export]\nprefix = \"Arqon\"\n\n[defines]\n\"feature = adaptive-engine\" = \"ARQONHPO_ADAPTIVE_ENGINE\"\n</code></pre>"},{"location":"projects/plans/sdk/#component-2-nodejs-typescript-bindings","title":"Component 2: Node.js / TypeScript Bindings","text":"<p>Using NAPI-RS for native Node.js bindings with full TypeScript support.</p>"},{"location":"projects/plans/sdk/#new-bindingsnode","title":"[NEW] <code>bindings/node/</code>","text":"<p>Complete Node.js/TypeScript SDK package.</p> <p>Directory Structure: <pre><code>bindings/node/\n\u251c\u2500\u2500 Cargo.toml           # NAPI-RS Rust bindings\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 lib.rs           # NAPI wrappers\n\u251c\u2500\u2500 package.json         # NPM package config\n\u251c\u2500\u2500 index.d.ts           # TypeScript declarations\n\u251c\u2500\u2500 index.js             # ESM exports\n\u2514\u2500\u2500 npm/                 # Pre-built binaries per platform\n    \u251c\u2500\u2500 darwin-arm64/\n    \u251c\u2500\u2500 darwin-x64/\n    \u251c\u2500\u2500 linux-arm64/\n    \u251c\u2500\u2500 linux-x64/\n    \u2514\u2500\u2500 win32-x64/\n</code></pre></p> <p>TypeScript API Design (index.d.ts):</p> <pre><code>/**\n * ArqonHPO - Adaptive Hyperparameter Optimization\n * \n * @example\n * ```typescript\n * import { ArqonSolver } from '@arqon/hpo';\n * \n * const solver = new ArqonSolver({\n *   seed: 42,\n *   budget: 100,\n *   bounds: {\n *     learning_rate: { min: 1e-5, max: 1e-1, scale: 'log' },\n *     batch_size: { min: 8, max: 256, scale: 'linear' }\n *   }\n * });\n * \n * while (true) {\n *   const batch = solver.ask();\n *   if (!batch) break;\n *   \n *   const results = await Promise.all(\n *     batch.map(async (params) =&gt; ({\n *       params,\n *       value: await evaluate(params),\n *       cost: 1.0\n *     }))\n *   );\n *   \n *   solver.tell(results);\n * }\n * ```\n */\n\nexport interface Bounds {\n  min: number;\n  max: number;\n  scale?: 'linear' | 'log' | 'periodic';\n}\n\nexport interface SolverConfig {\n  seed: number;\n  budget: number;\n  bounds: Record&lt;string, Bounds&gt;;\n  probeRatio?: number;\n  strategyParams?: Record&lt;string, number&gt;;\n}\n\nexport interface EvalResult {\n  params: Record&lt;string, number&gt;;\n  value: number;\n  cost?: number;\n}\n\nexport class ArqonSolver {\n  constructor(config: SolverConfig);\n\n  /** Get next batch of candidates, or null if complete */\n  ask(): Record&lt;string, number&gt;[] | null;\n\n  /** Report evaluation results */\n  tell(results: EvalResult[]): void;\n\n  /** Current evaluation count */\n  get historyLength(): number;\n}\n\nexport class ArqonProbe {\n  constructor(config: SolverConfig, seed?: number);\n\n  /** Generate a single sample at the given index (stateless) */\n  sampleAt(index: number): Record&lt;string, number&gt;;\n\n  /** Generate a range of samples (stateless, enables sharding) */\n  sampleRange(start: number, count: number): Record&lt;string, number&gt;[];\n}\n</code></pre>"},{"location":"projects/plans/sdk/#component-3-swift-apple-platforms","title":"Component 3: Swift / Apple Platforms","text":"<p>Native Swift package wrapping the C FFI for iOS, macOS, watchOS, tvOS.</p>"},{"location":"projects/plans/sdk/#new-bindingsswift","title":"[NEW] <code>bindings/swift/</code>","text":"<p>Directory Structure: <pre><code>bindings/swift/\n\u251c\u2500\u2500 Package.swift                    # Swift Package Manager manifest\n\u251c\u2500\u2500 Sources/\n\u2502   \u2514\u2500\u2500 ArqonHPO/\n\u2502       \u251c\u2500\u2500 ArqonHPO.swift           # High-level Swift API\n\u2502       \u251c\u2500\u2500 FFIBridge.swift          # C FFI interop layer\n\u2502       \u2514\u2500\u2500 Types.swift              # Swift-native types\n\u251c\u2500\u2500 Tests/\n\u2502   \u2514\u2500\u2500 ArqonHPOTests/\n\u2502       \u2514\u2500\u2500 ArqonHPOTests.swift\n\u2514\u2500\u2500 XCFramework/                     # Pre-built universal frameworks\n    \u251c\u2500\u2500 ios-arm64/\n    \u251c\u2500\u2500 ios-arm64-simulator/\n    \u2514\u2500\u2500 macos-arm64-x86_64/\n</code></pre></p> <p>Swift API Design:</p> <pre><code>import Foundation\n\n/// Solver configuration for ArqonHPO optimization\npublic struct SolverConfig: Codable {\n    public let seed: UInt64\n    public let budget: UInt64\n    public let bounds: [String: ParameterBounds]\n    public var probeRatio: Double = 0.2\n\n    public struct ParameterBounds: Codable {\n        public let min: Double\n        public let max: Double\n        public var scale: Scale = .linear\n\n        public enum Scale: String, Codable {\n            case linear = \"Linear\"\n            case log = \"Log\"\n            case periodic = \"Periodic\"\n        }\n    }\n}\n\n/// Evaluation result to report back to the solver\npublic struct EvalResult: Codable {\n    public let params: [String: Double]\n    public let value: Double\n    public var cost: Double = 1.0\n}\n\n/// ArqonHPO Solver - Adaptive hyperparameter optimization\n///\n/// Example:\n/// ```swift\n/// let config = SolverConfig(\n///     seed: 42,\n///     budget: 100,\n///     bounds: [\n///         \"x\": .init(min: -10, max: 10),\n///         \"y\": .init(min: -10, max: 10)\n///     ]\n/// )\n///\n/// let solver = try ArqonSolver(config: config)\n///\n/// while let batch = try solver.ask() {\n///     let results = batch.map { params in\n///         EvalResult(params: params, value: objective(params))\n///     }\n///     try solver.tell(results: results)\n/// }\n/// ```\npublic final class ArqonSolver: @unchecked Sendable {\n    private let handle: UnsafeMutableRawPointer\n\n    public init(config: SolverConfig) throws { ... }\n\n    deinit { ... }\n\n    /// Get the next batch of candidate parameters\n    /// - Returns: Array of parameter dictionaries, or nil if optimization complete\n    public func ask() throws -&gt; [[String: Double]]? { ... }\n\n    /// Report evaluation results back to the solver\n    public func tell(results: [EvalResult]) throws { ... }\n}\n\n/// Thread-safe probe for stateless sampling\npublic final class ArqonProbe: @unchecked Sendable {\n    public init(config: SolverConfig, seed: UInt64 = 42) throws { ... }\n\n    /// Generate a sample at the given index (completely stateless)\n    public func sample(at index: Int) -&gt; [String: Double] { ... }\n\n    /// Generate a range of samples (enables parallel sharding)\n    public func sampleRange(start: Int, count: Int) -&gt; [[String: Double]] { ... }\n}\n</code></pre>"},{"location":"projects/plans/sdk/#component-4-go-bindings","title":"Component 4: Go Bindings","text":"<p>Go module using CGO for seamless integration with Go services.</p>"},{"location":"projects/plans/sdk/#new-bindingsgo","title":"[NEW] <code>bindings/go/</code>","text":"<p>Directory Structure: <pre><code>bindings/go/\n\u251c\u2500\u2500 go.mod                    # Go module definition\n\u251c\u2500\u2500 arqonhpo.go               # Main package with CGO bindings\n\u251c\u2500\u2500 arqonhpo_test.go          # Tests\n\u251c\u2500\u2500 examples/\n\u2502   \u2514\u2500\u2500 basic_optimization/\n\u2502       \u2514\u2500\u2500 main.go\n\u2514\u2500\u2500 lib/                      # Pre-built shared libraries\n    \u251c\u2500\u2500 linux_amd64/\n    \u251c\u2500\u2500 linux_arm64/\n    \u251c\u2500\u2500 darwin_amd64/\n    \u251c\u2500\u2500 darwin_arm64/\n    \u2514\u2500\u2500 windows_amd64/\n</code></pre></p> <p>Go API Design:</p> <pre><code>package arqonhpo\n\n/*\n#cgo LDFLAGS: -L${SRCDIR}/lib/${GOOS}_${GOARCH} -larqonhpo\n#include \"arqonhpo.h\"\n*/\nimport \"C\"\nimport (\n    \"encoding/json\"\n    \"fmt\"\n    \"unsafe\"\n)\n\n// SolverConfig configures an ArqonHPO optimization run\ntype SolverConfig struct {\n    Seed       uint64                   `json:\"seed\"`\n    Budget     uint64                   `json:\"budget\"`\n    Bounds     map[string]ParamBounds   `json:\"bounds\"`\n    ProbeRatio float64                  `json:\"probe_ratio,omitempty\"`\n}\n\ntype ParamBounds struct {\n    Min   float64 `json:\"min\"`\n    Max   float64 `json:\"max\"`\n    Scale string  `json:\"scale,omitempty\"` // \"Linear\", \"Log\", \"Periodic\"\n}\n\n// EvalResult represents an evaluation result\ntype EvalResult struct {\n    Params map[string]float64 `json:\"params\"`\n    Value  float64            `json:\"value\"`\n    Cost   float64            `json:\"cost,omitempty\"`\n}\n\n// Solver is the main ArqonHPO optimization driver\ntype Solver struct {\n    handle *C.ArqonSolverHandle\n}\n\n// NewSolver creates a new solver with the given configuration\nfunc NewSolver(config SolverConfig) (*Solver, error) { ... }\n\n// Close releases all resources held by the solver\nfunc (s *Solver) Close() { ... }\n\n// Ask returns the next batch of candidates, or nil if complete\nfunc (s *Solver) Ask() ([]map[string]float64, error) { ... }\n\n// Tell reports evaluation results back to the solver\nfunc (s *Solver) Tell(results []EvalResult) error { ... }\n\n// Probe provides stateless sampling for parallel workloads\ntype Probe struct {\n    handle *C.ArqonProbeHandle\n}\n\n// NewProbe creates a stateless probe\nfunc NewProbe(config SolverConfig, seed uint64) (*Probe, error) { ... }\n\n// SampleAt generates a sample at the given index\nfunc (p *Probe) SampleAt(index int) map[string]float64 { ... }\n\n// SampleRange generates samples for [start, start+count)\nfunc (p *Probe) SampleRange(start, count int) []map[string]float64 { ... }\n</code></pre>"},{"location":"projects/plans/sdk/#component-5-webassembly-target","title":"Component 5: WebAssembly Target","text":"<p>Browser-compatible WASM build for client-side optimization.</p>"},{"location":"projects/plans/sdk/#new-bindingswasm","title":"[NEW] <code>bindings/wasm/</code>","text":"<p>Directory Structure: <pre><code>bindings/wasm/\n\u251c\u2500\u2500 Cargo.toml                     # wasm-bindgen setup\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 lib.rs                     # WASM bindings\n\u251c\u2500\u2500 package.json                   # NPM package for WASM\n\u251c\u2500\u2500 index.d.ts                     # TypeScript types\n\u2514\u2500\u2500 examples/\n    \u2514\u2500\u2500 browser-demo/\n        \u251c\u2500\u2500 index.html\n        \u2514\u2500\u2500 main.js\n</code></pre></p> <p>WASM API (Rust side):</p> <pre><code>use wasm_bindgen::prelude::*;\nuse arqonhpo_core::{config::SolverConfig, machine::Solver};\nuse serde::{Deserialize, Serialize};\n\n#[wasm_bindgen]\npub struct WasmSolver {\n    inner: Solver,\n}\n\n#[wasm_bindgen]\nimpl WasmSolver {\n    #[wasm_bindgen(constructor)]\n    pub fn new(config_json: &amp;str) -&gt; Result&lt;WasmSolver, JsValue&gt; {\n        let config: SolverConfig = serde_json::from_str(config_json)\n            .map_err(|e| JsValue::from_str(&amp;e.to_string()))?;\n        Ok(WasmSolver {\n            inner: Solver::pcr(config),\n        })\n    }\n\n    /// Returns JSON array of candidates or null\n    pub fn ask(&amp;mut self) -&gt; Option&lt;String&gt; {\n        self.inner.ask()\n            .map(|batch| serde_json::to_string(&amp;batch).unwrap())\n    }\n\n    /// Accepts JSON array of results\n    pub fn tell(&amp;mut self, results_json: &amp;str) -&gt; Result&lt;(), JsValue&gt; {\n        let results = serde_json::from_str(results_json)\n            .map_err(|e| JsValue::from_str(&amp;e.to_string()))?;\n        self.inner.tell(results);\n        Ok(())\n    }\n}\n</code></pre>"},{"location":"projects/plans/sdk/#component-6-cicd-enhancements","title":"Component 6: CI/CD Enhancements","text":"<p>Extend the existing CI to build and publish all SDK targets.</p>"},{"location":"projects/plans/sdk/#modify-githubworkflowsciyml","title":"[MODIFY] <code>.github/workflows/ci.yml</code>","text":"<p>Add jobs for building and testing all SDK platforms.</p> <p>New CI Jobs: - <code>build-ffi</code>: Build C library + header for all platforms - <code>build-node</code>: Build and test Node.js bindings - <code>build-swift</code>: Build XCFramework and run Swift tests - <code>build-go</code>: Build and test Go bindings - <code>build-wasm</code>: Build and test WASM package</p>"},{"location":"projects/plans/sdk/#new-githubworkflowsrelease-sdkyml","title":"[NEW] <code>.github/workflows/release-sdk.yml</code>","text":"<p>Automated SDK releases on version tags.</p> <p>Release Artifacts: - NPM: <code>@arqon/hpo</code> (Node.js native) and <code>@arqon/hpo-wasm</code> (browser) - PyPI: <code>arqonhpo</code> (existing) - Swift Package Registry / GitHub Releases (XCFramework) - Go Module: Published automatically via GitHub</p>"},{"location":"projects/plans/sdk/#implementation-order","title":"Implementation Order","text":"<ol> <li>C FFI Layer (Week 1)</li> <li>Production-ready FFI with full Solver + Probe APIs</li> <li>Automatic header generation with cbindgen</li> <li> <p>Thread-safety and error handling</p> </li> <li> <p>Node.js Bindings (Week 2)</p> </li> <li>NAPI-RS implementation</li> <li>TypeScript declarations</li> <li> <p>NPM package structure with pre-built binaries</p> </li> <li> <p>Swift Package (Week 3)</p> </li> <li>C FFI wrapper with Swift idioms</li> <li>Swift Package Manager setup</li> <li> <p>XCFramework builds for all Apple platforms</p> </li> <li> <p>Go Bindings (Week 4)</p> </li> <li>CGO wrapper</li> <li>Go module with vendored libraries</li> <li> <p>Integration tests</p> </li> <li> <p>WebAssembly (Week 5)</p> </li> <li>wasm-bindgen implementation</li> <li>NPM package for browser</li> <li> <p>Browser demo</p> </li> <li> <p>CI/CD &amp; Release (Week 6)</p> </li> <li>Unified build pipeline</li> <li>Automated publishing</li> <li>Documentation site updates</li> </ol>"},{"location":"projects/plans/sdk/#verification-plan","title":"Verification Plan","text":""},{"location":"projects/plans/sdk/#automated-tests","title":"Automated Tests","text":"<p>Each binding includes: - Unit tests: Basic API functionality - Integration tests: Full optimization loops - Determinism tests: Same seed \u2192 same results across platforms - Thread-safety tests: Concurrent access patterns</p> <p>Commands:</p> <pre><code># Rust core\ncargo test --workspace\n\n# C FFI\ncargo build --release -p arqonhpo-ffi\n./target/release/arqonhpo_ffi_test\n\n# Node.js\ncd bindings/node &amp;&amp; npm test\n\n# Swift\ncd bindings/swift &amp;&amp; swift test\n\n# Go\ncd bindings/go &amp;&amp; go test ./...\n\n# WASM\ncd bindings/wasm &amp;&amp; wasm-pack test --node\n</code></pre>"},{"location":"projects/plans/sdk/#cross-platform-verification","title":"Cross-Platform Verification","text":"<ul> <li>CI Matrix: Linux (x64, arm64), macOS (x64, arm64), Windows (x64)</li> <li>Bitwise Determinism: Hash of optimization trace must match across platforms</li> <li>Performance Baseline: T1 apply &lt; 1\u00b5s, T2 decision &lt; 10\u00b5s on all platforms</li> </ul>"},{"location":"projects/plans/sdk/#manual-verification","title":"Manual Verification","text":"<ul> <li>Browser demo running optimization in real-time</li> <li>iOS demo app with on-device ML tuning</li> <li>Go microservice example with Kubernetes deployment</li> </ul>"},{"location":"projects/plans/sdk/#success-criteria","title":"Success Criteria","text":"Metric Target Platform Coverage Linux, macOS, Windows, iOS, Browser Language SDKs Python, TypeScript, Swift, Go, WASM API Parity 100% feature parity across all SDKs Performance Overhead &lt; 5% vs native Rust Package Availability npm, PyPI, Swift Package, Go modules Documentation Full API docs + examples per language"},{"location":"reports/TDD_ASSESSMENT_REPORT/","title":"TDD Adherence Assessment Report","text":"<p>Assessment Date: 2025-12-14 Assessment Scope: ArqonHPO Core Implementation Constitutional Basis: ArqonHPO Constitution Section IV (Testing Strategy) and Section D2 (TDD Requirements)</p>"},{"location":"reports/TDD_ASSESSMENT_REPORT/#executive-summary","title":"Executive Summary","text":"<p>VERDICT: \u2705 STRONG TDD ADHERENCE</p> <p>ArqonHPO demonstrates excellent adherence to Test Driven Development methodology as defined in the Constitution. The project exhibits clear evidence of test-first development with comprehensive test coverage, proper failure handling, and constitutional compliance.</p> <p>Key Strengths:</p> <ul> <li>\u2705 Clear test-first workflow with documented task breakdown  </li> <li>\u2705 Comprehensive failing test suite for unimplemented features   </li> <li>\u2705 Realistic test data and adversarial scenarios  </li> <li>\u2705 Proper test organization and structure  </li> <li>\u2705 Evidence of TDD in implementation order  </li> </ul> <p>Areas for Enhancement:</p> <ul> <li>\ud83d\udd27 Complete remaining failing tests (T014-T052 tasks)</li> <li>\ud83d\udd27 Add property-based tests for mathematical functions</li> <li>\ud83d\udd27 Implement chaos/fault injection testing for robustness</li> </ul>"},{"location":"reports/TDD_ASSESSMENT_REPORT/#detailed-analysis","title":"Detailed Analysis","text":""},{"location":"reports/TDD_ASSESSMENT_REPORT/#1-test-structure-and-organization","title":"1. Test Structure and Organization \u2705","text":"<p>Finding: Excellent test organization following constitutional standards.</p> <p>Evidence:</p> <ul> <li>Clean separation: <code>crates/core/src/tests/</code> with component-specific modules</li> <li>Test organization matches implementation structure</li> <li>Proper use of <code>#[cfg(test)]</code> modules</li> <li>Integration tests in Python bindings with realistic fixtures</li> </ul> <p>Files Examined:</p> <ul> <li><code>crates/core/src/tests/mod.rs</code> - Test module organization</li> <li><code>crates/core/src/tests/test_classify.rs</code> - 147 lines, 9 tests</li> <li><code>crates/core/src/tests/test_probe.rs</code> - 102 lines, 7 tests  </li> <li><code>crates/core/src/tests/test_nelder_mead.rs</code> - 175 lines, 13 tests</li> <li><code>crates/core/src/tests/test_tpe.rs</code> - 120 lines, 6 tests</li> <li><code>bindings/python/tests/</code> - Integration tests with realistic fixtures</li> </ul> <p>Constitutional Compliance: \u2705 Meets Section IV.1 (TDD as Working Standard)</p>"},{"location":"reports/TDD_ASSESSMENT_REPORT/#2-test-first-development-evidence","title":"2. Test-First Development Evidence \u2705","text":"<p>Finding: Strong evidence of test-first development methodology.</p> <p>Evidence from Code:</p> <pre><code>// test_classify.rs - Lines 91-93\n#[test]\n#[ignore = \"ResidualDecayClassifier not yet implemented - T010-T012\"]\nfn test_residual_decay_alpha_estimation() {\n    todo!(\"Implement ResidualDecayClassifier\");\n}\n</code></pre> <p>Evidence from Task Management:</p> <ul> <li><code>specs/002-two-use-cases/tasks.md</code> shows clear TDD workflow</li> <li>Tasks T007-T009: \"Write failing test for...\" \u2192 T010-T013: \"Implement...\"</li> <li>Multiple parallel test-writing opportunities documented</li> <li>Task dependencies properly mapped</li> </ul> <p>Implementation Correlation:</p> <ul> <li><code>ResidualDecayClassifier</code> tests exist and pass (implemented)</li> <li>Multiple <code>#[ignore]</code> tests waiting for implementation</li> <li>Implementation matches test expectations exactly</li> </ul> <p>Constitutional Compliance: \u2705 Meets Section D2.2 (Tests define behavior before implementation)</p>"},{"location":"reports/TDD_ASSESSMENT_REPORT/#3-test-quality-against-constitutional-standards","title":"3. Test Quality Against Constitutional Standards \u2705","text":"<p>Finding: High-quality tests with realistic data and proper coverage.</p> <p>Test Data Quality:</p> <pre><code>// Realistic test data - test_classify.rs Lines 24-46\nfn sphere_samples() -&gt; Vec&lt;EvalTrace&gt; {\n    // Sphere: f(x) = sum(x_i^2), very smooth\n    (0..20)\n        .map(|i| {\n            let x = -5.0 + (i as f64) * 0.5;\n            trace(x * x) // Simple 1D sphere\n        })\n        .collect()\n}\n</code></pre> <p>Coverage Areas:</p> <ul> <li>\u2705 Determinism testing (same seed \u2192 same results)</li> <li>\u2705 Boundary condition testing (bounds checking)</li> <li>\u2705 Mathematical correctness (geometric decay, coefficient of variation)</li> <li>\u2705 Edge case handling (empty history, insufficient samples)</li> <li>\u2705 Integration scenarios (full solver pipeline)</li> </ul> <p>Adversarial Testing:</p> <ul> <li>\u2705 Malformed input handling</li> <li>\u2705 Boundary value analysis</li> <li>\u2705 Noise/chaos scenarios (Rastrigin function testing)</li> <li>\u2705 Performance regression prevention</li> </ul> <p>Constitutional Compliance: \u2705 Meets Section E (Verification Constitution)</p>"},{"location":"reports/TDD_ASSESSMENT_REPORT/#4-failure-mode-and-edge-case-coverage","title":"4. Failure Mode and Edge Case Coverage \u2705","text":"<p>Finding: Comprehensive failure mode testing with proper error handling.</p> <p>Evidence:</p> <pre><code>// classify.rs - Lines 32-34, 167-170\nfn classify(&amp;self, history: &amp;[EvalTrace]) -&gt; (Landscape, f64) {\n    if history.is_empty() {\n        return (Landscape::Chaotic, 1.0); // Safe fallback\n    }\n    // ... proper error handling throughout\n}\n</code></pre> <p>Failure Scenarios Tested:</p> <ul> <li>\u2705 Empty history handling</li> <li>\u2705 Insufficient samples for classification</li> <li>\u2705 Degenerate mathematical cases (division by zero)</li> <li>\u2705 Boundary violations</li> <li>\u2705 Convergence detection</li> <li>\u2705 Strategy selection edge cases</li> </ul> <p>Error Handling Philosophy:</p> <ul> <li>\u2705 \"Fail loud\" for logic errors (panics in tests)</li> <li>\u2705 \"Fail soft\" for runtime errors (safe fallbacks)</li> <li>\u2705 No silent error swallowing</li> </ul> <p>Constitutional Compliance: \u2705 Meets Section III.3 (Error Handling Philosophy)</p>"},{"location":"reports/TDD_ASSESSMENT_REPORT/#5-tdd-workflow-in-implementation-order","title":"5. TDD Workflow in Implementation Order \u2705","text":"<p>Finding: Clear evidence of test-driven implementation sequence.</p> <p>Evidence from ResidualDecayClassifier:</p> <ol> <li>Tests Written First: Lines 91-114 in test_classify.rs show ignored tests</li> <li>Implementation Follows: Lines 67-188 in classify.rs implement the tested behavior</li> <li>Tests Now Pass: Lines 204-261 show working tests with realistic data</li> </ol> <p>Task-Driven TDD:</p> <ul> <li>Phase 1: T001-T006 (Test infrastructure setup)</li> <li>Phase 2: T007-T039 (Failing tests \u2192 Implementation)</li> <li>Clear parallel opportunities documented</li> <li>Dependencies properly mapped</li> </ul> <p>Constitutional Compliance: \u2705 Meets Section D2.2 (Refactors require existing tests)</p>"},{"location":"reports/TDD_ASSESSMENT_REPORT/#6-integration-and-end-to-end-testing","title":"6. Integration and End-to-End Testing \u2705","text":"<p>Finding: Strong integration testing with Python bindings and realistic scenarios.</p> <p>Evidence:</p> <ul> <li><code>bindings/python/tests/test_us1.py</code> - User Story 1 acceptance testing</li> <li><code>bindings/python/tests/test_us2.py</code> - User Story 2 acceptance testing  </li> <li>Realistic fixtures: <code>smooth.py</code>, <code>noisy.py</code></li> <li>End-to-end solver validation with actual optimization objectives</li> </ul> <p>Realistic Test Scenarios:</p> <ul> <li>\u2705 Fast simulation tuning (Sphere, Rosenbrock functions)</li> <li>\u2705 Noisy/chaotic optimization (Rastrigin with noise)</li> <li>\u2705 Time-to-target benchmarking</li> <li>\u2705 Determinism verification across language boundaries</li> </ul> <p>Constitutional Compliance: \u2705 Meets Section IV.2 (Integration Tests)</p>"},{"location":"reports/TDD_ASSESSMENT_REPORT/#recommendations","title":"Recommendations","text":""},{"location":"reports/TDD_ASSESSMENT_REPORT/#immediate-actions-high-priority","title":"Immediate Actions (High Priority)","text":"<ol> <li> <p>Complete TDD Task Pipeline</p> <ul> <li>Implement remaining failing tests: T014-T052</li> <li>Focus on Scott's Rule bandwidth (T014-T018)</li> <li>Complete Nelder-Mead operations (T019-T028)</li> <li>Implement Prime-Index Probe (T029-T034)</li> </ul> </li> <li> <p>Enhanced Property-Based Testing</p> <ul> <li>Add property-based tests for mathematical functions</li> <li>Implement fuzz testing for input validation</li> <li>Add chaos engineering for robustness</li> </ul> </li> </ol>"},{"location":"reports/TDD_ASSESSMENT_REPORT/#medium-term-enhancements","title":"Medium-Term Enhancements","text":"<ol> <li> <p>Performance Regression Testing</p> <ul> <li>Add benchmark tests for hot paths</li> <li>Implement latency budget verification</li> <li>Add memory usage monitoring tests</li> </ul> </li> <li> <p>Cross-Language Consistency Testing</p> <ul> <li>Verify Rust/Python binding behavior consistency</li> <li>Add serialization/deserialization test coverage</li> <li>Implement artifact replay testing</li> </ul> </li> </ol>"},{"location":"reports/TDD_ASSESSMENT_REPORT/#long-term-improvements","title":"Long-Term Improvements","text":"<ol> <li>Advanced Testing Strategies<ul> <li>Mutation testing for test quality verification</li> <li>Concurrency testing for parallel evaluation scenarios</li> <li>Property-based testing for all mathematical operations</li> </ul> </li> </ol>"},{"location":"reports/TDD_ASSESSMENT_REPORT/#constitutional-compliance-matrix","title":"Constitutional Compliance Matrix","text":"Constitutional Requirement Status Evidence Section IV.1: TDD as Working Standard \u2705 COMPLIANT Clear test-first workflow, failing tests for unimplemented features Section D2.2: Tests Define Behavior \u2705 COMPLIANT Implementation follows test specifications exactly Section E: Verification Constitution \u2705 COMPLIANT Comprehensive test coverage with adversarial scenarios Section III.3: Error Handling \u2705 COMPLIANT Proper failure modes, no silent errors Section IV.2: Integration Testing \u2705 COMPLIANT End-to-end tests with realistic scenarios Section IV.3: Flaky Test Discipline \u2705 COMPLIANT Deterministic tests, controlled randomness"},{"location":"reports/TDD_ASSESSMENT_REPORT/#conclusion","title":"Conclusion","text":"<p>ArqonHPO demonstrates exemplary TDD adherence that exceeds constitutional requirements. The project shows:</p> <ul> <li>Strong test-first culture with documented workflows</li> <li>High-quality test suite with realistic scenarios and proper coverage</li> <li>Clear implementation traceability from failing tests to working code</li> <li>Proper error handling and failure mode coverage</li> <li>Integration testing that validates real-world usage scenarios</li> </ul> <p>The codebase demonstrates that TDD is not just a methodology but a core engineering principle embedded in the project architecture and development process.</p> <p>Recommendation: Continue current TDD practices and complete the remaining test-driven implementation tasks to achieve full feature parity.</p> <p>Assessment Confidence: HIGH Reviewer: Architecture Review Board Next Review: Upon completion of T014-T052 task pipeline</p>"},{"location":"why/","title":"Product Overview","text":"<p>ArqonHPO is built on a radical premise: optimization is a control problem, not a search problem.</p>"},{"location":"why/#the-architecture-of-speed","title":"The Architecture of Speed","text":"<p>Standard HPO libraries treat your system as a black box function $f(x) \\rightarrow y$. They pause the world, run the function, and wait.</p> <p>ArqonHPO treats your system as a flow:</p> <ol> <li>Probe (Tier 0): Low-discrepancy sampling scans the landscape.</li> <li>Classify (Tier $\\Omega$): Is the signal structured (physics) or chaotic (noise)?</li> <li>Refine (Tier 2): The Adaptive Engine proposes safe deltas.</li> <li>Enforce (Tier 1): The Safety Executor applies changes atomically.</li> </ol> <p>Read about the Architecture</p>"},{"location":"why/#core-components","title":"Core Components","text":"<ul> <li>Safety Executor: The gatekeeper. Enforces rate limits, rollback contracts, and value bounds.</li> <li>Adaptive Engine: The brain. Uses SPSA or Nelder-Mead to steer parameters.</li> <li>Telemetry Ring: Lock-free, allocation-free circular buffer for observation.</li> </ul>"}]}